Fri Nov 12 20:47:14 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   23C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   23C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   22C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   65C    P0   200W / 250W |   7149MiB / 32480MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   50C    P0   126W / 250W |  13668MiB / 32480MiB |     90%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   59C    P0   145W / 250W |  13672MiB / 32480MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   59C    P0   136W / 250W |  13570MiB / 32480MiB |     91%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   55C    P0   131W / 250W |  13670MiB / 32480MiB |     89%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    3     16900      C   python                                      7137MiB |
|    4     35353      C   python                                     13657MiB |
|    5     43774      C   python                                     13661MiB |
|    6     29577      C   python                                     13559MiB |
|    7     48235      C   python                                     13659MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/PEMS08_rdw.conf
total training epoch, fine tune epoch: 50 , 25
batch_size: 8
attention_top_k: 5
folder_dir: MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/PEMS08/PEMS08_r1_d1_w1.npz
ori length: 9497 , percent: 1.0 , scale: 9497
train: torch.Size([9497, 170, 1, 36]) torch.Size([9497, 170, 12]) torch.Size([9497, 170, 12])
val: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
test: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
TemporalPositionalEncoding max_len: 2016
w_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
d_index: [1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739]
h_index: [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 2016, 64])
src_embed.2.embedding.weight 	 torch.Size([170, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([170, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 591977
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 25, loss: 2.77
validation cost time: 150.8410s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:286.94s
epoch: 0, total time:437.80s
validation batch 1 / 25, loss: 0.10
validation cost time: 150.0471s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:286.87s
epoch: 1, total time:874.73s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0121s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:286.95s
epoch: 2, total time:1311.71s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9710s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:287.10s
epoch: 3, total time:1748.80s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9638s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_4.params
epoch: 4, train time every whole data:287.14s
epoch: 4, total time:2185.91s
validation batch 1 / 25, loss: 0.06
validation cost time: 149.9954s
epoch: 5, train time every whole data:287.39s
epoch: 5, total time:2623.31s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0329s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:287.16s
epoch: 6, total time:3060.51s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0229s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_7.params
epoch: 7, train time every whole data:287.16s
epoch: 7, total time:3497.71s
validation batch 1 / 25, loss: 0.04
validation cost time: 150.0473s
epoch: 8, train time every whole data:287.07s
epoch: 8, total time:3934.83s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0339s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:287.07s
epoch: 9, total time:4371.95s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9780s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_10.params
epoch: 10, train time every whole data:287.04s
epoch: 10, total time:4808.98s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9748s
epoch: 11, train time every whole data:284.60s
epoch: 11, total time:5243.55s
validation batch 1 / 25, loss: 0.05
validation cost time: 150.0389s
epoch: 12, train time every whole data:285.15s
epoch: 12, total time:5678.74s
validation batch 1 / 25, loss: 0.04
validation cost time: 150.0202s
epoch: 13, train time every whole data:286.88s
epoch: 13, total time:6115.65s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9868s
epoch: 14, train time every whole data:286.89s
epoch: 14, total time:6552.53s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0242s
epoch: 15, train time every whole data:286.78s
epoch: 15, total time:6989.33s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0066s
epoch: 16, train time every whole data:286.97s
epoch: 16, total time:7426.31s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9587s
epoch: 17, train time every whole data:287.21s
epoch: 17, total time:7863.48s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9292s
epoch: 18, train time every whole data:286.94s
epoch: 18, total time:8300.35s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9853s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_19.params
epoch: 19, train time every whole data:287.01s
epoch: 19, total time:8737.37s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9949s
epoch: 20, train time every whole data:286.70s
epoch: 20, total time:9174.06s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0171s
epoch: 21, train time every whole data:286.84s
epoch: 21, total time:9610.92s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9969s
epoch: 22, train time every whole data:286.86s
epoch: 22, total time:10047.77s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9253s
epoch: 23, train time every whole data:286.99s
epoch: 23, total time:10484.69s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9850s
epoch: 24, train time every whole data:286.15s
epoch: 24, total time:10920.83s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0357s
epoch: 25, train time every whole data:284.30s
epoch: 25, total time:11355.17s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9738s
epoch: 26, train time every whole data:286.08s
epoch: 26, total time:11791.23s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9932s
epoch: 27, train time every whole data:286.77s
epoch: 27, total time:12228.00s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9961s
epoch: 28, train time every whole data:286.77s
epoch: 28, total time:12664.76s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9933s
epoch: 29, train time every whole data:286.68s
epoch: 29, total time:13101.44s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0072s
epoch: 30, train time every whole data:286.70s
epoch: 30, total time:13538.15s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9964s
epoch: 31, train time every whole data:286.77s
epoch: 31, total time:13974.91s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0015s
epoch: 32, train time every whole data:286.82s
epoch: 32, total time:14411.74s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9610s
epoch: 33, train time every whole data:286.78s
epoch: 33, total time:14848.48s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9898s
epoch: 34, train time every whole data:286.68s
epoch: 34, total time:15285.15s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9822s
epoch: 35, train time every whole data:286.79s
epoch: 35, total time:15721.93s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9899s
epoch: 36, train time every whole data:286.90s
epoch: 36, total time:16158.82s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0121s
epoch: 37, train time every whole data:286.66s
epoch: 37, total time:16595.49s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9667s
epoch: 38, train time every whole data:284.81s
epoch: 38, total time:17030.28s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9875s
epoch: 39, train time every whole data:284.20s
epoch: 39, total time:17464.47s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0283s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_40.params
epoch: 40, train time every whole data:286.80s
epoch: 40, total time:17901.31s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0028s
epoch: 41, train time every whole data:286.73s
epoch: 41, total time:18338.04s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0098s
epoch: 42, train time every whole data:286.65s
epoch: 42, total time:18774.70s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0073s
epoch: 43, train time every whole data:286.66s
epoch: 43, total time:19211.37s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9749s
epoch: 44, train time every whole data:286.71s
epoch: 44, total time:19648.06s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9370s
epoch: 45, train time every whole data:286.77s
epoch: 45, total time:20084.76s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9853s
epoch: 46, train time every whole data:286.72s
epoch: 46, total time:20521.47s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9870s
epoch: 47, train time every whole data:286.80s
epoch: 47, total time:20958.26s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9896s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_48.params
epoch: 48, train time every whole data:286.74s
epoch: 48, total time:21395.01s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0006s
epoch: 49, train time every whole data:286.68s
epoch: 49, total time:21831.69s
best epoch: 48
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_48.params
predicting testing set batch 1 / 25, time: 6.06s
test time on whole data:150.05s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 48, predict 0 points
MAE: 11.17
RMSE: 18.88
MAPE: 7.63
current epoch: 48, predict 1 points
MAE: 11.85
RMSE: 20.27
MAPE: 8.11
current epoch: 48, predict 2 points
MAE: 12.28
RMSE: 21.10
MAPE: 8.34
current epoch: 48, predict 3 points
MAE: 12.58
RMSE: 21.75
MAPE: 8.50
current epoch: 48, predict 4 points
MAE: 12.80
RMSE: 22.25
MAPE: 8.65
current epoch: 48, predict 5 points
MAE: 13.02
RMSE: 22.77
MAPE: 8.81
current epoch: 48, predict 6 points
MAE: 13.26
RMSE: 23.19
MAPE: 8.94
current epoch: 48, predict 7 points
MAE: 13.53
RMSE: 23.59
MAPE: 9.06
current epoch: 48, predict 8 points
MAE: 13.74
RMSE: 23.90
MAPE: 9.21
current epoch: 48, predict 9 points
MAE: 13.90
RMSE: 24.19
MAPE: 9.32
current epoch: 48, predict 10 points
MAE: 14.07
RMSE: 24.49
MAPE: 9.41
current epoch: 48, predict 11 points
MAE: 14.38
RMSE: 24.91
MAPE: 9.53
all MAE: 13.05
all RMSE: 22.67
all MAPE: 8.79
[11.173681, 18.877444481609526, 7.627151161432266, 11.854393, 20.27219107440119, 8.105174452066422, 12.284291, 21.098227244749587, 8.336132019758224, 12.582749, 21.745795183306058, 8.495453000068665, 12.803697, 22.2501433292873, 8.65350291132927, 13.0201645, 22.765775136773293, 8.808988332748413, 13.256283, 23.19206649357033, 8.941642194986343, 13.527605, 23.58776051873222, 9.06105563044548, 13.735894, 23.897952246626303, 9.209203720092773, 13.90338, 24.192541262429934, 9.319925308227539, 14.072584, 24.487338784404226, 9.413821995258331, 14.383462, 24.90621691693223, 9.531126916408539, 13.049846, 22.67392225637817, 8.791932463645935]
fine tune the model ... 
epoch: 50, train time every whole data:727.96s
epoch: 50, total time:22711.21s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0115s
epoch: 51, train time every whole data:722.88s
epoch: 51, total time:23584.11s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0342s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_51.params
epoch: 52, train time every whole data:727.51s
epoch: 52, total time:24461.67s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9781s
epoch: 53, train time every whole data:727.15s
epoch: 53, total time:25338.80s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9884s
epoch: 54, train time every whole data:727.71s
epoch: 54, total time:26216.50s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0103s
epoch: 55, train time every whole data:727.47s
epoch: 55, total time:27093.98s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9804s
epoch: 56, train time every whole data:727.59s
epoch: 56, total time:27971.55s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9769s
epoch: 57, train time every whole data:727.03s
epoch: 57, total time:28848.57s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0395s
epoch: 58, train time every whole data:724.21s
epoch: 58, total time:29722.82s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0336s
epoch: 59, train time every whole data:727.61s
epoch: 59, total time:30600.46s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0284s
epoch: 60, train time every whole data:727.98s
epoch: 60, total time:31478.47s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0367s
epoch: 61, train time every whole data:728.07s
epoch: 61, total time:32356.57s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0111s
epoch: 62, train time every whole data:727.72s
epoch: 62, total time:33234.31s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0247s
epoch: 63, train time every whole data:727.55s
epoch: 63, total time:34111.89s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0100s
epoch: 64, train time every whole data:725.32s
epoch: 64, total time:34987.22s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0162s
epoch: 65, train time every whole data:725.45s
epoch: 65, total time:35862.69s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0087s
epoch: 66, train time every whole data:727.40s
epoch: 66, total time:36740.10s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9858s
epoch: 67, train time every whole data:727.79s
epoch: 67, total time:37617.88s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0129s
epoch: 68, train time every whole data:727.40s
epoch: 68, total time:38495.29s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9924s
epoch: 69, train time every whole data:727.86s
epoch: 69, total time:39373.14s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9690s
epoch: 70, train time every whole data:727.84s
epoch: 70, total time:40250.96s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0297s
epoch: 71, train time every whole data:724.35s
epoch: 71, total time:41125.34s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0312s
epoch: 72, train time every whole data:726.86s
epoch: 72, total time:42002.23s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0450s
epoch: 73, train time every whole data:727.17s
epoch: 73, total time:42879.45s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0291s
epoch: 74, train time every whole data:727.19s
epoch: 74, total time:43756.68s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0011s
best epoch: 51
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_51.params
predicting testing set batch 1 / 25, time: 6.07s
test time on whole data:150.08s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 51, predict 0 points
MAE: 10.99
RMSE: 18.82
MAPE: 7.46
current epoch: 51, predict 1 points
MAE: 11.65
RMSE: 20.20
MAPE: 7.98
current epoch: 51, predict 2 points
MAE: 12.03
RMSE: 21.00
MAPE: 8.18
current epoch: 51, predict 3 points
MAE: 12.28
RMSE: 21.63
MAPE: 8.33
current epoch: 51, predict 4 points
MAE: 12.49
RMSE: 22.12
MAPE: 8.46
current epoch: 51, predict 5 points
MAE: 12.68
RMSE: 22.60
MAPE: 8.60
current epoch: 51, predict 6 points
MAE: 12.85
RMSE: 22.98
MAPE: 8.73
current epoch: 51, predict 7 points
MAE: 13.01
RMSE: 23.31
MAPE: 8.83
current epoch: 51, predict 8 points
MAE: 13.16
RMSE: 23.57
MAPE: 8.95
current epoch: 51, predict 9 points
MAE: 13.29
RMSE: 23.81
MAPE: 9.04
current epoch: 51, predict 10 points
MAE: 13.44
RMSE: 24.07
MAPE: 9.18
current epoch: 51, predict 11 points
MAE: 13.66
RMSE: 24.43
MAPE: 9.32
all MAE: 12.63
all RMSE: 22.44
all MAPE: 8.59
[10.98676, 18.817069173629463, 7.463746517896652, 11.653929, 20.204915662861833, 7.977696508169174, 12.030204, 20.995552681981845, 8.180984109640121, 12.280813, 21.629135882946613, 8.326757699251175, 12.488672, 22.11989383720321, 8.455103635787964, 12.681995, 22.59778555764646, 8.595804870128632, 12.854854, 22.98007002086944, 8.730940520763397, 13.012849, 23.30996420315449, 8.83452594280243, 13.16377, 23.573392500537018, 8.948159962892532, 13.285537, 23.813052353748013, 9.044137597084045, 13.444821, 24.06701078864555, 9.182444214820862, 13.663609, 24.429385191605697, 9.315811842679977, 12.628993, 22.437176970385348, 8.58801081776619]
