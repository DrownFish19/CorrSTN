Fri Nov 12 20:28:44 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   55C    P0   141W / 250W |  13670MiB / 32480MiB |     95%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   57C    P0   168W / 250W |  14530MiB / 32480MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   44C    P0    25W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   65C    P0   225W / 250W |   7149MiB / 32480MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   49C    P0   131W / 250W |  13668MiB / 32480MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   56C    P0   143W / 250W |  13672MiB / 32480MiB |     83%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   26C    P0    23W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   53C    P0   136W / 250W |  13670MiB / 32480MiB |     96%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     56174      C   python                                     13659MiB |
|    1     55410      C   python                                     14519MiB |
|    3     16900      C   python                                      7137MiB |
|    4     35353      C   python                                     13657MiB |
|    5     43774      C   python                                     13661MiB |
|    7     48235      C   python                                     13659MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN-nA/configurations/PEMS08_rdw.conf
total training epoch, fine tune epoch: 50 , 25
batch_size: 8
attention_top_k: 5
folder_dir: MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN-nA/data/PEMS08/PEMS08_r1_d1_w1.npz
ori length: 9497 , percent: 1.0 , scale: 9497
train: torch.Size([9497, 170, 1, 36]) torch.Size([9497, 170, 12]) torch.Size([9497, 170, 12])
val: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
test: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
TemporalPositionalEncoding max_len: 2016
w_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
d_index: [1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739]
h_index: [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 2016, 64])
src_embed.2.embedding.weight 	 torch.Size([170, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([170, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 591977
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 25, loss: 2.00
validation cost time: 150.3136s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:283.49s
epoch: 0, total time:433.82s
validation batch 1 / 25, loss: 0.07
validation cost time: 149.9444s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:283.44s
epoch: 1, total time:867.22s
validation batch 1 / 25, loss: 0.15
validation cost time: 149.9997s
epoch: 2, train time every whole data:283.36s
epoch: 2, total time:1300.59s
validation batch 1 / 25, loss: 0.17
validation cost time: 149.9416s
epoch: 3, train time every whole data:283.29s
epoch: 3, total time:1733.82s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9346s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_4.params
epoch: 4, train time every whole data:283.06s
epoch: 4, total time:2166.83s
validation batch 1 / 25, loss: 0.08
validation cost time: 149.9340s
epoch: 5, train time every whole data:283.18s
epoch: 5, total time:2599.94s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9468s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:283.15s
epoch: 6, total time:3033.05s
validation batch 1 / 25, loss: 0.08
validation cost time: 149.9390s
epoch: 7, train time every whole data:283.16s
epoch: 7, total time:3466.16s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9311s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_8.params
epoch: 8, train time every whole data:283.14s
epoch: 8, total time:3899.24s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9525s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:283.15s
epoch: 9, total time:4332.36s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9333s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_10.params
epoch: 10, train time every whole data:283.15s
epoch: 10, total time:4765.46s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9878s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_11.params
epoch: 11, train time every whole data:283.20s
epoch: 11, total time:5198.67s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9614s
epoch: 12, train time every whole data:283.21s
epoch: 12, total time:5631.84s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9336s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_13.params
epoch: 13, train time every whole data:283.29s
epoch: 13, total time:6065.08s
validation batch 1 / 25, loss: 0.07
validation cost time: 150.0460s
epoch: 14, train time every whole data:283.40s
epoch: 14, total time:6498.53s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9647s
epoch: 15, train time every whole data:283.35s
epoch: 15, total time:6931.85s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9311s
epoch: 16, train time every whole data:283.15s
epoch: 16, total time:7364.93s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9297s
epoch: 17, train time every whole data:283.16s
epoch: 17, total time:7798.02s
validation batch 1 / 25, loss: 0.06
validation cost time: 149.9300s
epoch: 18, train time every whole data:283.09s
epoch: 18, total time:8231.05s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9508s
epoch: 19, train time every whole data:283.16s
epoch: 19, total time:8664.16s
validation batch 1 / 25, loss: 0.07
validation cost time: 149.9738s
epoch: 20, train time every whole data:283.23s
epoch: 20, total time:9097.37s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9307s
epoch: 21, train time every whole data:283.18s
epoch: 21, total time:9530.48s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9361s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_22.params
epoch: 22, train time every whole data:283.09s
epoch: 22, total time:9963.52s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9321s
epoch: 23, train time every whole data:283.13s
epoch: 23, total time:10396.58s
validation batch 1 / 25, loss: 0.05
validation cost time: 149.9319s
epoch: 24, train time every whole data:283.11s
epoch: 24, total time:10829.62s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9638s
epoch: 25, train time every whole data:283.22s
epoch: 25, total time:11262.81s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9611s
epoch: 26, train time every whole data:283.06s
epoch: 26, total time:11695.84s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9360s
epoch: 27, train time every whole data:283.15s
epoch: 27, total time:12128.93s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9978s
epoch: 28, train time every whole data:283.30s
epoch: 28, total time:12562.22s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9845s
epoch: 29, train time every whole data:283.04s
epoch: 29, total time:12995.25s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9261s
epoch: 30, train time every whole data:283.02s
epoch: 30, total time:13428.20s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9223s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_31.params
epoch: 31, train time every whole data:283.10s
epoch: 31, total time:13861.23s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9241s
epoch: 32, train time every whole data:283.04s
epoch: 32, total time:14294.20s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9308s
epoch: 33, train time every whole data:283.07s
epoch: 33, total time:14727.20s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9262s
epoch: 34, train time every whole data:283.05s
epoch: 34, total time:15160.19s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9258s
epoch: 35, train time every whole data:283.08s
epoch: 35, total time:15593.19s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9286s
epoch: 36, train time every whole data:283.10s
epoch: 36, total time:16026.22s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9310s
epoch: 37, train time every whole data:283.15s
epoch: 37, total time:16459.31s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9326s
epoch: 38, train time every whole data:283.06s
epoch: 38, total time:16892.30s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9282s
epoch: 39, train time every whole data:283.09s
epoch: 39, total time:17325.33s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9193s
epoch: 40, train time every whole data:283.05s
epoch: 40, total time:17758.30s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9434s
epoch: 41, train time every whole data:283.23s
epoch: 41, total time:18191.48s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9920s
epoch: 42, train time every whole data:283.16s
epoch: 42, total time:18624.63s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9613s
epoch: 43, train time every whole data:283.07s
epoch: 43, total time:19057.66s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9224s
epoch: 44, train time every whole data:283.06s
epoch: 44, total time:19490.65s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9278s
epoch: 45, train time every whole data:283.02s
epoch: 45, total time:19923.59s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9203s
epoch: 46, train time every whole data:283.05s
epoch: 46, total time:20356.57s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9249s
epoch: 47, train time every whole data:283.02s
epoch: 47, total time:20789.52s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9242s
epoch: 48, train time every whole data:283.02s
epoch: 48, total time:21222.46s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9216s
epoch: 49, train time every whole data:283.06s
epoch: 49, total time:21655.44s
best epoch: 31
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_31.params
predicting testing set batch 1 / 25, time: 6.06s
test time on whole data:149.98s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 31, predict 0 points
MAE: 11.42
RMSE: 19.17
MAPE: 7.75
current epoch: 31, predict 1 points
MAE: 11.84
RMSE: 20.43
MAPE: 8.02
current epoch: 31, predict 2 points
MAE: 12.27
RMSE: 21.24
MAPE: 8.25
current epoch: 31, predict 3 points
MAE: 12.51
RMSE: 21.86
MAPE: 8.44
current epoch: 31, predict 4 points
MAE: 12.71
RMSE: 22.30
MAPE: 8.76
current epoch: 31, predict 5 points
MAE: 12.90
RMSE: 22.70
MAPE: 9.14
current epoch: 31, predict 6 points
MAE: 13.10
RMSE: 23.07
MAPE: 9.28
current epoch: 31, predict 7 points
MAE: 13.29
RMSE: 23.44
MAPE: 9.43
current epoch: 31, predict 8 points
MAE: 13.56
RMSE: 23.75
MAPE: 9.78
current epoch: 31, predict 9 points
MAE: 13.80
RMSE: 24.04
MAPE: 10.12
current epoch: 31, predict 10 points
MAE: 14.02
RMSE: 24.35
MAPE: 10.41
current epoch: 31, predict 11 points
MAE: 14.53
RMSE: 24.90
MAPE: 10.87
all MAE: 13.00
all RMSE: 22.66
all MAPE: 9.19
[11.4169235, 19.169036630254304, 7.75291845202446, 11.844576, 20.430329070949043, 8.017227053642273, 12.269443, 21.241311125724884, 8.249267935752869, 12.512357, 21.863396057296384, 8.444847911596298, 12.709791, 22.29937956763736, 8.762584626674652, 12.901212, 22.69803124851567, 9.136296808719635, 13.096209, 23.07320265294921, 9.279503673315048, 13.294465, 23.43631898066079, 9.425526857376099, 13.555493, 23.746816963921056, 9.780754894018173, 13.7992735, 24.04287323549265, 10.123571008443832, 14.020534, 24.345206651701737, 10.409870743751526, 14.534878, 24.898336993835425, 10.865480452775955, 12.99627, 22.661885075082566, 9.18731838464737]
fine tune the model ... 
epoch: 50, train time every whole data:723.50s
epoch: 50, total time:22530.28s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9415s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_50.params
epoch: 51, train time every whole data:722.97s
epoch: 51, total time:23403.20s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9362s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_51.params
epoch: 52, train time every whole data:723.68s
epoch: 52, total time:24276.83s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9904s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_52.params
epoch: 53, train time every whole data:723.27s
epoch: 53, total time:25150.11s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9254s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_53.params
epoch: 54, train time every whole data:723.17s
epoch: 54, total time:26023.22s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9473s
epoch: 55, train time every whole data:723.12s
epoch: 55, total time:26896.29s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9346s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_55.params
epoch: 56, train time every whole data:723.02s
epoch: 56, total time:27769.26s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9277s
epoch: 57, train time every whole data:723.09s
epoch: 57, total time:28642.27s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9274s
epoch: 58, train time every whole data:722.97s
epoch: 58, total time:29515.17s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9431s
epoch: 59, train time every whole data:723.57s
epoch: 59, total time:30388.68s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9640s
epoch: 60, train time every whole data:723.11s
epoch: 60, total time:31261.75s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9306s
epoch: 61, train time every whole data:723.09s
epoch: 61, total time:32134.78s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9805s
epoch: 62, train time every whole data:723.16s
epoch: 62, total time:33007.92s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9544s
epoch: 63, train time every whole data:723.21s
epoch: 63, total time:33881.08s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9285s
epoch: 64, train time every whole data:722.96s
epoch: 64, total time:34753.97s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9259s
epoch: 65, train time every whole data:723.26s
epoch: 65, total time:35627.16s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9336s
epoch: 66, train time every whole data:723.86s
epoch: 66, total time:36500.96s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9724s
epoch: 67, train time every whole data:722.96s
epoch: 67, total time:37373.90s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0051s
epoch: 68, train time every whole data:722.90s
epoch: 68, total time:38246.81s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9260s
epoch: 69, train time every whole data:723.38s
epoch: 69, total time:39120.11s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9274s
epoch: 70, train time every whole data:723.28s
epoch: 70, total time:39993.33s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9273s
epoch: 71, train time every whole data:723.21s
epoch: 71, total time:40866.47s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9533s
epoch: 72, train time every whole data:722.88s
epoch: 72, total time:41739.30s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9656s
epoch: 73, train time every whole data:723.58s
epoch: 73, total time:42612.85s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9663s
epoch: 74, train time every whole data:723.31s
epoch: 74, total time:43486.13s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9592s
best epoch: 55
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_55.params
predicting testing set batch 1 / 25, time: 6.06s
test time on whole data:149.97s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 55, predict 0 points
MAE: 11.18
RMSE: 19.08
MAPE: 7.58
current epoch: 55, predict 1 points
MAE: 11.68
RMSE: 20.29
MAPE: 7.88
current epoch: 55, predict 2 points
MAE: 11.99
RMSE: 20.99
MAPE: 8.11
current epoch: 55, predict 3 points
MAE: 12.22
RMSE: 21.57
MAPE: 8.28
current epoch: 55, predict 4 points
MAE: 12.40
RMSE: 22.03
MAPE: 8.40
current epoch: 55, predict 5 points
MAE: 12.57
RMSE: 22.46
MAPE: 8.51
current epoch: 55, predict 6 points
MAE: 12.74
RMSE: 22.84
MAPE: 8.60
current epoch: 55, predict 7 points
MAE: 12.90
RMSE: 23.21
MAPE: 8.70
current epoch: 55, predict 8 points
MAE: 13.03
RMSE: 23.50
MAPE: 8.79
current epoch: 55, predict 9 points
MAE: 13.16
RMSE: 23.77
MAPE: 8.87
current epoch: 55, predict 10 points
MAE: 13.32
RMSE: 24.02
MAPE: 8.99
current epoch: 55, predict 11 points
MAE: 13.61
RMSE: 24.48
MAPE: 9.16
all MAE: 12.57
all RMSE: 22.41
all MAPE: 8.49
[11.178527, 19.082111613827703, 7.578656822443008, 11.675617, 20.285732062042246, 7.880564033985138, 11.989005, 20.98816965294638, 8.10931846499443, 12.218265, 21.573676621040253, 8.276962488889694, 12.397445, 22.03271063974575, 8.395715802907944, 12.567242, 22.460775814635443, 8.510828018188477, 12.741867, 22.843041947816133, 8.599378168582916, 12.896257, 23.21350383405974, 8.699018508195877, 13.033694, 23.501976417055065, 8.7865449488163, 13.162547, 23.76607700096137, 8.874768763780594, 13.316216, 24.01736838987569, 8.9910127222538, 13.608503, 24.476955241423003, 9.164933115243912, 12.56543, 22.407754291596873, 8.488977700471878]
