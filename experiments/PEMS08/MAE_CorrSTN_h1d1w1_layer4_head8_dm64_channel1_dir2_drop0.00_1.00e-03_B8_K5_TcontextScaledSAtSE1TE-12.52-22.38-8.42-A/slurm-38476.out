Thu Nov 11 22:28:02 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   23C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   24C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   26C    P0    32W / 250W |   1142MiB / 32480MiB |     14%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   59C    P0   193W / 250W |  20710MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   49C    P0   135W / 250W |  13572MiB / 32480MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   56C    P0   126W / 250W |  13572MiB / 32480MiB |     90%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   51C    P0    29W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   54C    P0   176W / 250W |  13472MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    2     46840      C   python                                      1131MiB |
|    3     16900      C   python                                      7137MiB |
|    3     50948      C   python                                     13561MiB |
|    4     44007      C   python                                     13561MiB |
|    5     43061      C   python                                     13561MiB |
|    7     57303      C   python                                     13461MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/PEMS08_rdw.conf
total training epoch, fine tune epoch: 50 , 25
batch_size: 8
attention_top_k: 5
folder_dir: MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/PEMS08/PEMS08_r1_d1_w1.npz
ori length: 9497 , percent: 1.0 , scale: 9497
train: torch.Size([9497, 170, 1, 36]) torch.Size([9497, 170, 12]) torch.Size([9497, 170, 12])
val: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
test: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
TemporalPositionalEncoding max_len: 2016
w_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
d_index: [1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739]
h_index: [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 2016, 64])
src_embed.2.embedding.weight 	 torch.Size([170, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([170, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 591977
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 25, loss: 0.90
validation cost time: 150.4231s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:285.31s
epoch: 0, total time:435.75s
validation batch 1 / 25, loss: 0.08
validation cost time: 149.9169s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:285.25s
epoch: 1, total time:870.93s
validation batch 1 / 25, loss: 0.06
validation cost time: 149.9112s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:285.30s
epoch: 2, total time:1306.15s
validation batch 1 / 25, loss: 0.05
validation cost time: 149.9735s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:285.25s
epoch: 3, total time:1741.39s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9090s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_4.params
epoch: 4, train time every whole data:285.31s
epoch: 4, total time:2176.63s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9667s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_5.params
epoch: 5, train time every whole data:285.33s
epoch: 5, total time:2611.94s
validation batch 1 / 25, loss: 0.06
validation cost time: 149.9126s
epoch: 6, train time every whole data:285.26s
epoch: 6, total time:3047.12s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9820s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_7.params
epoch: 7, train time every whole data:285.34s
epoch: 7, total time:3482.45s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9316s
epoch: 8, train time every whole data:285.37s
epoch: 8, total time:3917.76s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9723s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:285.48s
epoch: 9, total time:4353.22s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9699s
epoch: 10, train time every whole data:285.29s
epoch: 10, total time:4788.48s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9712s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_11.params
epoch: 11, train time every whole data:285.26s
epoch: 11, total time:5223.73s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9289s
epoch: 12, train time every whole data:285.32s
epoch: 12, total time:5658.99s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0001s
epoch: 13, train time every whole data:285.23s
epoch: 13, total time:6094.22s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9428s
epoch: 14, train time every whole data:285.32s
epoch: 14, total time:6529.48s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0432s
epoch: 15, train time every whole data:285.71s
epoch: 15, total time:6965.23s
validation batch 1 / 25, loss: 0.05
validation cost time: 150.0828s
epoch: 16, train time every whole data:285.46s
epoch: 16, total time:7400.78s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9858s
epoch: 17, train time every whole data:285.26s
epoch: 17, total time:7836.03s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0416s
epoch: 18, train time every whole data:285.37s
epoch: 18, total time:8271.44s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9881s
epoch: 19, train time every whole data:285.24s
epoch: 19, total time:8706.67s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9813s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_20.params
epoch: 20, train time every whole data:285.32s
epoch: 20, total time:9141.99s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9387s
epoch: 21, train time every whole data:285.22s
epoch: 21, total time:9577.15s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9716s
epoch: 22, train time every whole data:285.07s
epoch: 22, total time:10012.20s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9384s
epoch: 23, train time every whole data:285.24s
epoch: 23, total time:10447.38s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9857s
epoch: 24, train time every whole data:285.06s
epoch: 24, total time:10882.43s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9421s
epoch: 25, train time every whole data:285.13s
epoch: 25, total time:11317.51s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9199s
epoch: 26, train time every whole data:285.04s
epoch: 26, total time:11752.47s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9843s
epoch: 27, train time every whole data:285.10s
epoch: 27, total time:12187.56s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9762s
epoch: 28, train time every whole data:285.03s
epoch: 28, total time:12622.57s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9651s
epoch: 29, train time every whole data:285.03s
epoch: 29, total time:13057.56s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9624s
epoch: 30, train time every whole data:284.93s
epoch: 30, total time:13492.45s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9477s
epoch: 31, train time every whole data:284.85s
epoch: 31, total time:13927.25s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0222s
epoch: 32, train time every whole data:285.00s
epoch: 32, total time:14362.28s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9742s
epoch: 33, train time every whole data:284.89s
epoch: 33, total time:14797.15s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9730s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_34.params
epoch: 34, train time every whole data:284.95s
epoch: 34, total time:15232.09s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9514s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_35.params
epoch: 35, train time every whole data:284.96s
epoch: 35, total time:15667.01s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9642s
epoch: 36, train time every whole data:284.97s
epoch: 36, total time:16101.95s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9762s
epoch: 37, train time every whole data:284.85s
epoch: 37, total time:16536.78s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9312s
epoch: 38, train time every whole data:284.90s
epoch: 38, total time:16971.61s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9483s
epoch: 39, train time every whole data:284.95s
epoch: 39, total time:17406.51s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0488s
epoch: 40, train time every whole data:285.37s
epoch: 40, total time:17841.93s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0270s
epoch: 41, train time every whole data:285.09s
epoch: 41, total time:18277.05s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9114s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_42.params
epoch: 42, train time every whole data:284.90s
epoch: 42, total time:18711.87s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0255s
epoch: 43, train time every whole data:285.05s
epoch: 43, total time:19146.95s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9286s
epoch: 44, train time every whole data:284.97s
epoch: 44, total time:19581.85s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9543s
epoch: 45, train time every whole data:284.94s
epoch: 45, total time:20016.75s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9640s
epoch: 46, train time every whole data:284.83s
epoch: 46, total time:20451.55s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9323s
epoch: 47, train time every whole data:285.08s
epoch: 47, total time:20886.56s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9732s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_48.params
epoch: 48, train time every whole data:284.97s
epoch: 48, total time:21321.52s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9577s
epoch: 49, train time every whole data:285.13s
epoch: 49, total time:21756.61s
best epoch: 48
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_48.params
predicting testing set batch 1 / 25, time: 6.07s
test time on whole data:150.06s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 48, predict 0 points
MAE: 11.14
RMSE: 18.83
MAPE: 7.58
current epoch: 48, predict 1 points
MAE: 11.75
RMSE: 20.23
MAPE: 8.03
current epoch: 48, predict 2 points
MAE: 12.22
RMSE: 21.03
MAPE: 8.54
current epoch: 48, predict 3 points
MAE: 12.59
RMSE: 21.66
MAPE: 8.87
current epoch: 48, predict 4 points
MAE: 12.89
RMSE: 22.17
MAPE: 9.17
current epoch: 48, predict 5 points
MAE: 13.14
RMSE: 22.66
MAPE: 9.41
current epoch: 48, predict 6 points
MAE: 13.36
RMSE: 23.06
MAPE: 9.60
current epoch: 48, predict 7 points
MAE: 13.53
RMSE: 23.41
MAPE: 9.75
current epoch: 48, predict 8 points
MAE: 13.71
RMSE: 23.71
MAPE: 9.86
current epoch: 48, predict 9 points
MAE: 13.96
RMSE: 24.02
MAPE: 10.07
current epoch: 48, predict 10 points
MAE: 14.25
RMSE: 24.37
MAPE: 10.23
current epoch: 48, predict 11 points
MAE: 14.87
RMSE: 24.90
MAPE: 10.86
all MAE: 13.12
all RMSE: 22.57
all MAPE: 9.33
[11.13969, 18.826015344723526, 7.5791895389556885, 11.746549, 20.231828236204876, 8.030779659748077, 12.223127, 21.034960029841542, 8.537906408309937, 12.589413, 21.662501634178387, 8.869866281747818, 12.887278, 22.168366943009623, 9.171947836875916, 13.140713, 22.664532430064327, 9.410087764263153, 13.361868, 23.06080352415517, 9.598448127508163, 13.533586, 23.413070601695967, 9.75208505988121, 13.711366, 23.705563383973022, 9.86097827553749, 13.9565115, 24.02429241365003, 10.07421761751175, 14.247227, 24.37403218230867, 10.229455679655075, 14.872063, 24.900675495590853, 10.864391177892685, 13.117441, 22.571789633430917, 9.331608563661575]
fine tune the model ... 
epoch: 50, train time every whole data:724.39s
epoch: 50, total time:22632.34s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9345s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_50.params
epoch: 51, train time every whole data:724.62s
epoch: 51, total time:23506.91s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9484s
epoch: 52, train time every whole data:724.48s
epoch: 52, total time:24381.34s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9469s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_52.params
epoch: 53, train time every whole data:724.59s
epoch: 53, total time:25255.89s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0240s
epoch: 54, train time every whole data:725.18s
epoch: 54, total time:26131.10s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9728s
epoch: 55, train time every whole data:724.39s
epoch: 55, total time:27005.46s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9204s
epoch: 56, train time every whole data:724.45s
epoch: 56, total time:27879.83s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9833s
epoch: 57, train time every whole data:726.34s
epoch: 57, total time:28756.16s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0152s
epoch: 58, train time every whole data:724.50s
epoch: 58, total time:29630.67s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0338s
epoch: 59, train time every whole data:724.78s
epoch: 59, total time:30505.49s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0078s
epoch: 60, train time every whole data:724.95s
epoch: 60, total time:31380.44s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9836s
epoch: 61, train time every whole data:724.52s
epoch: 61, total time:32254.95s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9922s
epoch: 62, train time every whole data:724.66s
epoch: 62, total time:33129.61s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9173s
epoch: 63, train time every whole data:724.71s
epoch: 63, total time:34004.24s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9986s
epoch: 64, train time every whole data:724.23s
epoch: 64, total time:34878.47s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9731s
epoch: 65, train time every whole data:725.07s
epoch: 65, total time:35753.52s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9588s
epoch: 66, train time every whole data:724.11s
epoch: 66, total time:36627.59s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9364s
epoch: 67, train time every whole data:724.17s
epoch: 67, total time:37501.70s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9749s
epoch: 68, train time every whole data:724.54s
epoch: 68, total time:38376.22s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9364s
epoch: 69, train time every whole data:724.43s
epoch: 69, total time:39250.59s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9452s
epoch: 70, train time every whole data:724.39s
epoch: 70, total time:40124.93s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9393s
epoch: 71, train time every whole data:724.38s
epoch: 71, total time:40999.25s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9421s
epoch: 72, train time every whole data:724.04s
epoch: 72, total time:41873.23s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9351s
epoch: 73, train time every whole data:723.90s
epoch: 73, total time:42747.07s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9993s
epoch: 74, train time every whole data:724.25s
epoch: 74, total time:43621.33s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0265s
best epoch: 52
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_52.params
predicting testing set batch 1 / 25, time: 6.07s
test time on whole data:150.09s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 52, predict 0 points
MAE: 10.95
RMSE: 18.81
MAPE: 7.39
current epoch: 52, predict 1 points
MAE: 11.59
RMSE: 20.20
MAPE: 7.79
current epoch: 52, predict 2 points
MAE: 11.94
RMSE: 20.95
MAPE: 8.02
current epoch: 52, predict 3 points
MAE: 12.19
RMSE: 21.55
MAPE: 8.19
current epoch: 52, predict 4 points
MAE: 12.39
RMSE: 22.04
MAPE: 8.32
current epoch: 52, predict 5 points
MAE: 12.58
RMSE: 22.49
MAPE: 8.43
current epoch: 52, predict 6 points
MAE: 12.74
RMSE: 22.87
MAPE: 8.54
current epoch: 52, predict 7 points
MAE: 12.89
RMSE: 23.21
MAPE: 8.65
current epoch: 52, predict 8 points
MAE: 13.02
RMSE: 23.49
MAPE: 8.76
current epoch: 52, predict 9 points
MAE: 13.15
RMSE: 23.75
MAPE: 8.87
current epoch: 52, predict 10 points
MAE: 13.31
RMSE: 24.03
MAPE: 8.99
current epoch: 52, predict 11 points
MAE: 13.55
RMSE: 24.42
MAPE: 9.14
all MAE: 12.52
all RMSE: 22.38
all MAPE: 8.42
[10.951399, 18.812738461424715, 7.3869578540325165, 11.586631, 20.198697129336246, 7.788125425577164, 11.940684, 20.95199474953101, 8.022985607385635, 12.18737, 21.55056281892656, 8.186515420675278, 12.394445, 22.038638776501006, 8.320897817611694, 12.578852, 22.49295544017268, 8.432745933532715, 12.742627, 22.868093646634605, 8.543483912944794, 12.888555, 23.214170350846594, 8.65413025021553, 13.023996, 23.485053321042034, 8.763564378023148, 13.149437, 23.748853796354574, 8.86937901377678, 13.308065, 24.03370842431521, 8.989793807268143, 13.547766, 24.416849840885366, 9.13892537355423, 12.524979, 22.375879707304946, 8.42478722333908]
