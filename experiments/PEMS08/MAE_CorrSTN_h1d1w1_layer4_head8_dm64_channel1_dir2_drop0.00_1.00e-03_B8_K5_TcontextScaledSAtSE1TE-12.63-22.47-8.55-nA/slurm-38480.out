Fri Nov 12 08:19:01 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   23C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   24C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   23C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   64C    P0   134W / 250W |  20710MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   52C    P0   138W / 250W |  13672MiB / 32480MiB |     96%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   61C    P0   171W / 250W |  13572MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   60C    P0   136W / 250W |  13670MiB / 32480MiB |     95%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   56C    P0   153W / 250W |  13674MiB / 32480MiB |     93%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    3     16900      C   python                                      7137MiB |
|    3     50948      C   python                                     13561MiB |
|    4     44007      C   python                                     13661MiB |
|    5     36378      C   python                                     13561MiB |
|    6       606      C   python                                     13659MiB |
|    7     57303      C   python                                     13663MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN-nA/configurations/PEMS08_rdw.conf
total training epoch, fine tune epoch: 50 , 25
batch_size: 8
attention_top_k: 5
folder_dir: MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN-nA/data/PEMS08/PEMS08_r1_d1_w1.npz
ori length: 9497 , percent: 1.0 , scale: 9497
train: torch.Size([9497, 170, 1, 36]) torch.Size([9497, 170, 12]) torch.Size([9497, 170, 12])
val: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
test: torch.Size([3166, 170, 1, 36]) torch.Size([3166, 170, 12]) torch.Size([3166, 170, 12])
TemporalPositionalEncoding max_len: 2016
w_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
d_index: [1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739]
h_index: [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(170, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([3])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 2016, 64])
src_embed.2.embedding.weight 	 torch.Size([170, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([170, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([3])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 591977
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 25, loss: 2.42
validation cost time: 150.7523s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:282.75s
epoch: 0, total time:433.53s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9606s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:282.86s
epoch: 1, total time:866.36s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9609s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:282.79s
epoch: 2, total time:1299.13s
validation batch 1 / 25, loss: 0.04
validation cost time: 150.0009s
epoch: 3, train time every whole data:282.79s
epoch: 3, total time:1731.92s
validation batch 1 / 25, loss: 0.10
validation cost time: 149.9691s
epoch: 4, train time every whole data:282.87s
epoch: 4, total time:2164.76s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0539s
epoch: 5, train time every whole data:282.81s
epoch: 5, total time:2597.63s
validation batch 1 / 25, loss: 0.05
validation cost time: 149.9566s
epoch: 6, train time every whole data:282.87s
epoch: 6, total time:3030.45s
validation batch 1 / 25, loss: 0.04
validation cost time: 150.0116s
epoch: 7, train time every whole data:282.89s
epoch: 7, total time:3463.35s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9633s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_8.params
epoch: 8, train time every whole data:282.84s
epoch: 8, total time:3896.17s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9579s
epoch: 9, train time every whole data:282.89s
epoch: 9, total time:4329.02s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9703s
epoch: 10, train time every whole data:282.82s
epoch: 10, total time:4761.82s
validation batch 1 / 25, loss: 0.04
validation cost time: 149.9640s
epoch: 11, train time every whole data:282.97s
epoch: 11, total time:5194.75s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9921s
epoch: 12, train time every whole data:282.93s
epoch: 12, total time:5627.68s
validation batch 1 / 25, loss: 0.06
validation cost time: 149.9618s
epoch: 13, train time every whole data:282.84s
epoch: 13, total time:6060.48s
validation batch 1 / 25, loss: 0.08
validation cost time: 150.0288s
epoch: 14, train time every whole data:282.76s
epoch: 14, total time:6493.27s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9844s
epoch: 15, train time every whole data:282.78s
epoch: 15, total time:6926.04s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9677s
epoch: 16, train time every whole data:282.77s
epoch: 16, total time:7358.78s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9907s
epoch: 17, train time every whole data:282.88s
epoch: 17, total time:7791.66s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9799s
epoch: 18, train time every whole data:282.94s
epoch: 18, total time:8224.58s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0296s
epoch: 19, train time every whole data:282.85s
epoch: 19, total time:8657.46s
validation batch 1 / 25, loss: 0.06
validation cost time: 150.0468s
epoch: 20, train time every whole data:282.88s
epoch: 20, total time:9090.39s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9523s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_21.params
epoch: 21, train time every whole data:282.78s
epoch: 21, total time:9523.14s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9640s
epoch: 22, train time every whole data:282.78s
epoch: 22, total time:9955.88s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9711s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_23.params
epoch: 23, train time every whole data:282.95s
epoch: 23, total time:10388.82s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0169s
epoch: 24, train time every whole data:282.90s
epoch: 24, total time:10821.74s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0075s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_25.params
epoch: 25, train time every whole data:283.02s
epoch: 25, total time:11254.78s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0532s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_26.params
epoch: 26, train time every whole data:282.92s
epoch: 26, total time:11687.77s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0083s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_27.params
epoch: 27, train time every whole data:282.76s
epoch: 27, total time:12120.55s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0170s
epoch: 28, train time every whole data:282.73s
epoch: 28, total time:12553.30s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9699s
epoch: 29, train time every whole data:282.82s
epoch: 29, total time:12986.09s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0134s
epoch: 30, train time every whole data:282.82s
epoch: 30, total time:13418.92s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9883s
epoch: 31, train time every whole data:282.86s
epoch: 31, total time:13851.77s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0322s
epoch: 32, train time every whole data:282.90s
epoch: 32, total time:14284.71s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0437s
epoch: 33, train time every whole data:282.93s
epoch: 33, total time:14717.69s
validation batch 1 / 25, loss: 0.03
validation cost time: 150.0417s
epoch: 34, train time every whole data:282.77s
epoch: 34, total time:15150.49s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9562s
epoch: 35, train time every whole data:282.73s
epoch: 35, total time:15583.19s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9546s
epoch: 36, train time every whole data:282.75s
epoch: 36, total time:16015.89s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9595s
epoch: 37, train time every whole data:282.75s
epoch: 37, total time:16448.60s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0160s
epoch: 38, train time every whole data:282.75s
epoch: 38, total time:16881.37s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0249s
epoch: 39, train time every whole data:282.83s
epoch: 39, total time:17314.23s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9951s
epoch: 40, train time every whole data:282.86s
epoch: 40, total time:17747.09s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0005s
epoch: 41, train time every whole data:282.83s
epoch: 41, total time:18179.93s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0146s
epoch: 42, train time every whole data:282.86s
epoch: 42, total time:18612.80s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9733s
epoch: 43, train time every whole data:282.81s
epoch: 43, total time:19045.59s
validation batch 1 / 25, loss: 0.03
validation cost time: 149.9867s
epoch: 44, train time every whole data:282.85s
epoch: 44, total time:19478.43s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0017s
epoch: 45, train time every whole data:282.76s
epoch: 45, total time:19911.20s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0466s
epoch: 46, train time every whole data:282.81s
epoch: 46, total time:20344.06s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0341s
epoch: 47, train time every whole data:282.95s
epoch: 47, total time:20777.05s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0340s
epoch: 48, train time every whole data:282.84s
epoch: 48, total time:21209.92s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9550s
epoch: 49, train time every whole data:282.75s
epoch: 49, total time:21642.63s
best epoch: 27
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_27.params
predicting testing set batch 1 / 25, time: 6.06s
test time on whole data:150.09s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 27, predict 0 points
MAE: 11.68
RMSE: 19.33
MAPE: 8.19
current epoch: 27, predict 1 points
MAE: 12.12
RMSE: 20.54
MAPE: 8.17
current epoch: 27, predict 2 points
MAE: 12.47
RMSE: 21.36
MAPE: 8.37
current epoch: 27, predict 3 points
MAE: 12.71
RMSE: 21.99
MAPE: 8.65
current epoch: 27, predict 4 points
MAE: 12.92
RMSE: 22.47
MAPE: 8.91
current epoch: 27, predict 5 points
MAE: 13.12
RMSE: 22.93
MAPE: 9.20
current epoch: 27, predict 6 points
MAE: 13.37
RMSE: 23.36
MAPE: 9.43
current epoch: 27, predict 7 points
MAE: 13.62
RMSE: 23.79
MAPE: 9.61
current epoch: 27, predict 8 points
MAE: 13.85
RMSE: 24.12
MAPE: 9.89
current epoch: 27, predict 9 points
MAE: 14.05
RMSE: 24.41
MAPE: 10.25
current epoch: 27, predict 10 points
MAE: 14.25
RMSE: 24.73
MAPE: 10.36
current epoch: 27, predict 11 points
MAE: 14.52
RMSE: 25.22
MAPE: 10.66
all MAE: 13.22
all RMSE: 22.92
all MAPE: 9.31
[11.677845, 19.3274223674833, 8.191664516925812, 12.118826, 20.544161239514168, 8.16800743341446, 12.4672165, 21.359765049931642, 8.365190774202347, 12.711565, 21.990188491519987, 8.65260362625122, 12.917199, 22.468257638685724, 8.908828347921371, 13.1192, 22.932870839504726, 9.197551757097244, 13.36605, 23.358881161167854, 9.426811337471008, 13.62328, 23.787633372507734, 9.605168551206589, 13.84576, 24.118702120806326, 9.888451546430588, 14.045987, 24.411058565196175, 10.248982161283493, 14.250437, 24.7328080086388, 10.364224761724472, 14.519795, 25.21562650072805, 10.655137151479721, 13.221931, 22.91796841709988, 9.306037425994873]
fine tune the model ... 
epoch: 50, train time every whole data:722.15s
epoch: 50, total time:22516.16s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9842s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_50.params
epoch: 51, train time every whole data:722.06s
epoch: 51, total time:23388.22s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0295s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_51.params
epoch: 52, train time every whole data:722.19s
epoch: 52, total time:24260.46s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9628s
epoch: 53, train time every whole data:721.83s
epoch: 53, total time:25132.25s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9571s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_53.params
epoch: 54, train time every whole data:721.93s
epoch: 54, total time:26004.16s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0350s
epoch: 55, train time every whole data:722.17s
epoch: 55, total time:26876.37s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9654s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_55.params
epoch: 56, train time every whole data:721.97s
epoch: 56, total time:27748.33s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9618s
epoch: 57, train time every whole data:721.97s
epoch: 57, total time:28620.26s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9810s
epoch: 58, train time every whole data:722.24s
epoch: 58, total time:29492.49s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9917s
epoch: 59, train time every whole data:722.13s
epoch: 59, total time:30364.61s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0046s
epoch: 60, train time every whole data:722.19s
epoch: 60, total time:31236.81s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0109s
epoch: 61, train time every whole data:722.55s
epoch: 61, total time:32109.38s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0551s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_61.params
epoch: 62, train time every whole data:722.40s
epoch: 62, total time:32981.84s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0139s
epoch: 63, train time every whole data:722.30s
epoch: 63, total time:33854.16s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0188s
save parameters to file: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_63.params
epoch: 64, train time every whole data:722.37s
epoch: 64, total time:34726.56s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9931s
epoch: 65, train time every whole data:722.28s
epoch: 65, total time:35598.83s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0094s
epoch: 66, train time every whole data:722.10s
epoch: 66, total time:36470.95s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0100s
epoch: 67, train time every whole data:722.07s
epoch: 67, total time:37343.03s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0344s
epoch: 68, train time every whole data:722.48s
epoch: 68, total time:38215.55s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0579s
epoch: 69, train time every whole data:722.46s
epoch: 69, total time:39088.07s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9888s
epoch: 70, train time every whole data:722.58s
epoch: 70, total time:39960.64s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0095s
epoch: 71, train time every whole data:722.29s
epoch: 71, total time:40832.94s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0210s
epoch: 72, train time every whole data:722.32s
epoch: 72, total time:41705.28s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9912s
epoch: 73, train time every whole data:722.18s
epoch: 73, total time:42577.46s
validation batch 1 / 25, loss: 0.02
validation cost time: 149.9982s
epoch: 74, train time every whole data:722.45s
epoch: 74, total time:43449.92s
validation batch 1 / 25, loss: 0.02
validation cost time: 150.0170s
best epoch: 63
apply the best val model on the test data set ...
load weight from: ./experiments/PEMS08/MAE_ASTGNN_h1d1w1_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_63.params
predicting testing set batch 1 / 25, time: 6.07s
test time on whole data:150.12s
input: (3166, 170, 36, 1)
prediction: (3166, 170, 12, 1)
data_target_tensor: (3166, 170, 12)
current epoch: 63, predict 0 points
MAE: 11.21
RMSE: 19.19
MAPE: 7.60
current epoch: 63, predict 1 points
MAE: 11.69
RMSE: 20.34
MAPE: 7.94
current epoch: 63, predict 2 points
MAE: 12.01
RMSE: 21.07
MAPE: 8.10
current epoch: 63, predict 3 points
MAE: 12.24
RMSE: 21.65
MAPE: 8.26
current epoch: 63, predict 4 points
MAE: 12.42
RMSE: 22.09
MAPE: 8.40
current epoch: 63, predict 5 points
MAE: 12.61
RMSE: 22.53
MAPE: 8.53
current epoch: 63, predict 6 points
MAE: 12.82
RMSE: 22.94
MAPE: 8.69
current epoch: 63, predict 7 points
MAE: 12.98
RMSE: 23.30
MAPE: 8.80
current epoch: 63, predict 8 points
MAE: 13.13
RMSE: 23.57
MAPE: 8.87
current epoch: 63, predict 9 points
MAE: 13.27
RMSE: 23.80
MAPE: 8.96
current epoch: 63, predict 10 points
MAE: 13.45
RMSE: 24.06
MAPE: 9.10
current epoch: 63, predict 11 points
MAE: 13.73
RMSE: 24.51
MAPE: 9.35
all MAE: 12.63
all RMSE: 22.47
all MAPE: 8.55
[11.209535, 19.19499532323424, 7.597466558218002, 11.685894, 20.339831371827422, 7.94110968708992, 12.014311, 21.067371382374468, 8.104470372200012, 12.240444, 21.649968368824325, 8.258621394634247, 12.419626, 22.089276283051564, 8.39947834610939, 12.610297, 22.533239607456164, 8.532211929559708, 12.816573, 22.938609582324567, 8.689642697572708, 12.979858, 23.297281078788195, 8.797501027584076, 13.125202, 23.56558231663022, 8.874589204788208, 13.26663, 23.796499248100417, 8.96013155579567, 13.448784, 24.05922892742058, 9.104997664690018, 13.730225, 24.51208073686894, 9.346512705087662, 12.628944, 22.4733837798322, 8.550561964511871]
