Mon Nov  1 19:03:46 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   25C    P0    23W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   40C    P0    54W / 250W |   3358MiB / 32480MiB |     53%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   59C    P0   140W / 250W |  21130MiB / 32480MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   63C    P0   143W / 250W |  21131MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   54C    P0    46W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   58C    P0   142W / 250W |  24589MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   28C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   58C    P0   146W / 250W |  19012MiB / 32480MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     22954      C   python                                      3347MiB |
|    2     38294      C   python                                     21119MiB |
|    3     45484      C   python                                     21119MiB |
|    5     49354      C   python                                     21119MiB |
|    5     53019      C   python                                      3459MiB |
|    7     37318      C   python                                     19001MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/HZME_OUTFLOW.conf
total training epoch, fine tune epoch: 350 , 170
batch_size: 8
attention_top_k: 5
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/HZME_OUTFLOW/HZME_OUTFLOW_r1_d0_w0.npz
ori length: 4479 , percent: 1.0 , scale: 4479
train: torch.Size([3323, 80, 1, 12]) torch.Size([3323, 80, 12]) torch.Size([3323, 80, 12])
val: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
test: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
            (1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 4))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 5])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([80, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([80, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 491729
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137]}]
validation batch 1 / 5, loss: 1.27
validation cost time: 4.5973s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:22.97s
epoch: 0, total time:27.58s
validation batch 1 / 5, loss: 0.08
validation cost time: 4.2888s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:22.93s
epoch: 1, total time:54.81s
validation batch 1 / 5, loss: 0.05
validation cost time: 4.2879s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:22.94s
epoch: 2, total time:82.05s
validation batch 1 / 5, loss: 0.05
validation cost time: 4.2885s
epoch: 3, train time every whole data:22.92s
epoch: 3, total time:109.26s
validation batch 1 / 5, loss: 0.04
validation cost time: 4.2886s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_4.params
epoch: 4, train time every whole data:22.96s
epoch: 4, total time:136.51s
validation batch 1 / 5, loss: 0.05
validation cost time: 4.2888s
epoch: 5, train time every whole data:22.95s
epoch: 5, total time:163.75s
validation batch 1 / 5, loss: 0.07
validation cost time: 4.2903s
epoch: 6, train time every whole data:22.94s
epoch: 6, total time:190.99s
validation batch 1 / 5, loss: 0.05
validation cost time: 4.2885s
epoch: 7, train time every whole data:22.93s
epoch: 7, total time:218.20s
validation batch 1 / 5, loss: 0.05
validation cost time: 4.2876s
epoch: 8, train time every whole data:22.92s
epoch: 8, total time:245.42s
validation batch 1 / 5, loss: 0.07
validation cost time: 4.2882s
epoch: 9, train time every whole data:22.93s
epoch: 9, total time:272.63s
validation batch 1 / 5, loss: 0.04
validation cost time: 4.2877s
epoch: 10, train time every whole data:22.91s
epoch: 10, total time:299.84s
validation batch 1 / 5, loss: 0.06
validation cost time: 4.2880s
epoch: 11, train time every whole data:22.94s
epoch: 11, total time:327.07s
validation batch 1 / 5, loss: 0.07
validation cost time: 4.2906s
epoch: 12, train time every whole data:22.92s
epoch: 12, total time:354.29s
validation batch 1 / 5, loss: 0.06
validation cost time: 4.2889s
epoch: 13, train time every whole data:22.94s
epoch: 13, total time:381.51s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2884s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_14.params
epoch: 14, train time every whole data:22.95s
epoch: 14, total time:408.76s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2880s
epoch: 15, train time every whole data:22.91s
epoch: 15, total time:435.96s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2877s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_16.params
epoch: 16, train time every whole data:22.90s
epoch: 16, total time:463.16s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2873s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_17.params
epoch: 17, train time every whole data:22.91s
epoch: 17, total time:490.37s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2877s
epoch: 18, train time every whole data:22.92s
epoch: 18, total time:517.59s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2883s
epoch: 19, train time every whole data:22.91s
epoch: 19, total time:544.78s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2880s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_20.params
epoch: 20, train time every whole data:22.91s
epoch: 20, total time:572.00s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2877s
epoch: 21, train time every whole data:22.93s
epoch: 21, total time:599.22s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2876s
epoch: 22, train time every whole data:22.93s
epoch: 22, total time:626.44s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2893s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_23.params
epoch: 23, train time every whole data:22.95s
epoch: 23, total time:653.69s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2892s
epoch: 24, train time every whole data:22.94s
epoch: 24, total time:680.93s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2895s
epoch: 25, train time every whole data:22.96s
epoch: 25, total time:708.17s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2884s
epoch: 26, train time every whole data:22.94s
epoch: 26, total time:735.40s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 27, train time every whole data:22.94s
epoch: 27, total time:762.63s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 28, train time every whole data:22.93s
epoch: 28, total time:789.85s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 29, train time every whole data:22.94s
epoch: 29, total time:817.08s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2896s
epoch: 30, train time every whole data:22.96s
epoch: 30, total time:844.33s
validation batch 1 / 5, loss: 0.04
validation cost time: 4.2897s
epoch: 31, train time every whole data:22.95s
epoch: 31, total time:871.57s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2888s
epoch: 32, train time every whole data:22.95s
epoch: 32, total time:898.81s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2900s
epoch: 33, train time every whole data:22.95s
epoch: 33, total time:926.06s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_34.params
epoch: 34, train time every whole data:22.93s
epoch: 34, total time:953.29s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_35.params
epoch: 35, train time every whole data:22.93s
epoch: 35, total time:980.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 36, train time every whole data:22.92s
epoch: 36, total time:1007.73s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 37, train time every whole data:22.95s
epoch: 37, total time:1034.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 38, train time every whole data:22.92s
epoch: 38, total time:1062.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 39, train time every whole data:22.94s
epoch: 39, total time:1089.41s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2885s
epoch: 40, train time every whole data:22.93s
epoch: 40, total time:1116.63s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 41, train time every whole data:22.95s
epoch: 41, total time:1143.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_42.params
epoch: 42, train time every whole data:22.96s
epoch: 42, total time:1171.13s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2882s
epoch: 43, train time every whole data:22.93s
epoch: 43, total time:1198.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 44, train time every whole data:22.93s
epoch: 44, total time:1225.57s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2882s
epoch: 45, train time every whole data:22.92s
epoch: 45, total time:1252.78s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2885s
epoch: 46, train time every whole data:22.91s
epoch: 46, total time:1279.99s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2898s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_47.params
epoch: 47, train time every whole data:22.92s
epoch: 47, total time:1307.21s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2958s
epoch: 48, train time every whole data:22.95s
epoch: 48, total time:1334.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 49, train time every whole data:22.95s
epoch: 49, total time:1361.69s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2882s
epoch: 50, train time every whole data:22.95s
epoch: 50, total time:1388.93s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 51, train time every whole data:22.95s
epoch: 51, total time:1416.17s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 52, train time every whole data:22.93s
epoch: 52, total time:1443.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 53, train time every whole data:22.94s
epoch: 53, total time:1470.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 54, train time every whole data:22.92s
epoch: 54, total time:1497.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 55, train time every whole data:22.94s
epoch: 55, total time:1525.05s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 56, train time every whole data:22.94s
epoch: 56, total time:1552.29s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 57, train time every whole data:22.92s
epoch: 57, total time:1579.49s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 58, train time every whole data:22.93s
epoch: 58, total time:1606.71s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.3238s
epoch: 59, train time every whole data:22.94s
epoch: 59, total time:1633.98s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2891s
epoch: 60, train time every whole data:22.95s
epoch: 60, total time:1661.22s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_61.params
epoch: 61, train time every whole data:22.94s
epoch: 61, total time:1688.46s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2886s
epoch: 62, train time every whole data:22.95s
epoch: 62, total time:1715.69s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 63, train time every whole data:22.93s
epoch: 63, total time:1742.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 64, train time every whole data:22.94s
epoch: 64, total time:1770.14s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 65, train time every whole data:22.94s
epoch: 65, total time:1797.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 66, train time every whole data:22.94s
epoch: 66, total time:1824.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_67.params
epoch: 67, train time every whole data:22.96s
epoch: 67, total time:1851.87s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_68.params
epoch: 68, train time every whole data:22.96s
epoch: 68, total time:1879.12s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_69.params
epoch: 69, train time every whole data:22.96s
epoch: 69, total time:1906.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 70, train time every whole data:22.94s
epoch: 70, total time:1933.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 71, train time every whole data:22.93s
epoch: 71, total time:1960.83s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 72, train time every whole data:22.93s
epoch: 72, total time:1988.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_73.params
epoch: 73, train time every whole data:22.90s
epoch: 73, total time:2015.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 74, train time every whole data:22.93s
epoch: 74, total time:2042.47s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_75.params
epoch: 75, train time every whole data:22.93s
epoch: 75, total time:2069.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2900s
epoch: 76, train time every whole data:22.93s
epoch: 76, total time:2096.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 77, train time every whole data:22.93s
epoch: 77, total time:2124.14s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2881s
epoch: 78, train time every whole data:22.95s
epoch: 78, total time:2151.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2901s
epoch: 79, train time every whole data:22.96s
epoch: 79, total time:2178.64s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_80.params
epoch: 80, train time every whole data:22.95s
epoch: 80, total time:2205.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
epoch: 81, train time every whole data:22.95s
epoch: 81, total time:2233.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 82, train time every whole data:22.94s
epoch: 82, total time:2260.36s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2897s
epoch: 83, train time every whole data:22.93s
epoch: 83, total time:2287.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 84, train time every whole data:22.95s
epoch: 84, total time:2314.83s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_85.params
epoch: 85, train time every whole data:22.94s
epoch: 85, total time:2342.07s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 86, train time every whole data:22.96s
epoch: 86, total time:2369.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 87, train time every whole data:22.96s
epoch: 87, total time:2396.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 88, train time every whole data:22.97s
epoch: 88, total time:2423.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 89, train time every whole data:22.95s
epoch: 89, total time:2451.06s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 90, train time every whole data:22.93s
epoch: 90, total time:2478.28s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_91.params
epoch: 91, train time every whole data:22.93s
epoch: 91, total time:2505.51s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2875s
epoch: 92, train time every whole data:22.94s
epoch: 92, total time:2532.74s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 93, train time every whole data:22.95s
epoch: 93, total time:2559.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 94, train time every whole data:22.93s
epoch: 94, total time:2587.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_95.params
epoch: 95, train time every whole data:22.94s
epoch: 95, total time:2614.43s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 96, train time every whole data:22.95s
epoch: 96, total time:2641.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 97, train time every whole data:22.94s
epoch: 97, total time:2668.90s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 98, train time every whole data:23.08s
epoch: 98, total time:2696.27s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 99, train time every whole data:22.94s
epoch: 99, total time:2723.50s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 100, train time every whole data:22.95s
epoch: 100, total time:2750.73s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 101, train time every whole data:22.94s
epoch: 101, total time:2777.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 102, train time every whole data:22.95s
epoch: 102, total time:2805.21s
validation batch 1 / 5, loss: 0.03
validation cost time: 4.2885s
epoch: 103, train time every whole data:22.95s
epoch: 103, total time:2832.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 104, train time every whole data:22.95s
epoch: 104, total time:2859.69s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2901s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_105.params
epoch: 105, train time every whole data:22.96s
epoch: 105, total time:2886.95s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 106, train time every whole data:22.96s
epoch: 106, total time:2914.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2897s
epoch: 107, train time every whole data:22.97s
epoch: 107, total time:2941.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 108, train time every whole data:22.94s
epoch: 108, total time:2968.69s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
epoch: 109, train time every whole data:22.94s
epoch: 109, total time:2995.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 110, train time every whole data:22.95s
epoch: 110, total time:3023.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 111, train time every whole data:22.96s
epoch: 111, total time:3050.40s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_112.params
epoch: 112, train time every whole data:22.95s
epoch: 112, total time:3077.65s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 113, train time every whole data:22.94s
epoch: 113, total time:3104.87s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_114.params
epoch: 114, train time every whole data:22.96s
epoch: 114, total time:3132.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2895s
epoch: 115, train time every whole data:22.96s
epoch: 115, total time:3159.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 116, train time every whole data:22.97s
epoch: 116, total time:3186.64s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 117, train time every whole data:22.94s
epoch: 117, total time:3213.87s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 118, train time every whole data:22.94s
epoch: 118, total time:3241.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 119, train time every whole data:22.95s
epoch: 119, total time:3268.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 120, train time every whole data:22.96s
epoch: 120, total time:3295.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 121, train time every whole data:22.97s
epoch: 121, total time:3322.85s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 122, train time every whole data:22.97s
epoch: 122, total time:3350.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 123, train time every whole data:22.97s
epoch: 123, total time:3377.36s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 124, train time every whole data:22.97s
epoch: 124, total time:3404.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
epoch: 125, train time every whole data:22.96s
epoch: 125, total time:3431.87s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 126, train time every whole data:22.96s
epoch: 126, total time:3459.12s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 127, train time every whole data:22.95s
epoch: 127, total time:3486.36s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 128, train time every whole data:22.94s
epoch: 128, total time:3513.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 129, train time every whole data:22.94s
epoch: 129, total time:3540.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 130, train time every whole data:22.96s
epoch: 130, total time:3568.07s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 131, train time every whole data:22.94s
epoch: 131, total time:3595.30s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 132, train time every whole data:22.94s
epoch: 132, total time:3622.53s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 133, train time every whole data:22.93s
epoch: 133, total time:3649.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 134, train time every whole data:22.95s
epoch: 134, total time:3676.99s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 135, train time every whole data:22.94s
epoch: 135, total time:3704.21s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 136, train time every whole data:22.93s
epoch: 136, total time:3731.43s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 137, train time every whole data:22.93s
epoch: 137, total time:3758.65s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 138, train time every whole data:22.94s
epoch: 138, total time:3785.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
epoch: 139, train time every whole data:22.96s
epoch: 139, total time:3813.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 140, train time every whole data:22.98s
epoch: 140, total time:3840.40s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2908s
epoch: 141, train time every whole data:22.97s
epoch: 141, total time:3867.66s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 142, train time every whole data:22.97s
epoch: 142, total time:3894.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 143, train time every whole data:22.96s
epoch: 143, total time:3922.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2902s
epoch: 144, train time every whole data:22.97s
epoch: 144, total time:3949.44s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 145, train time every whole data:22.95s
epoch: 145, total time:3976.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 146, train time every whole data:22.93s
epoch: 146, total time:4003.90s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 147, train time every whole data:22.94s
epoch: 147, total time:4031.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 148, train time every whole data:22.96s
epoch: 148, total time:4058.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 149, train time every whole data:22.95s
epoch: 149, total time:4085.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 150, train time every whole data:22.94s
epoch: 150, total time:4112.86s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 151, train time every whole data:22.93s
epoch: 151, total time:4140.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 152, train time every whole data:22.95s
epoch: 152, total time:4167.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 153, train time every whole data:22.97s
epoch: 153, total time:4194.57s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2897s
epoch: 154, train time every whole data:22.95s
epoch: 154, total time:4221.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 155, train time every whole data:22.94s
epoch: 155, total time:4249.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 156, train time every whole data:22.94s
epoch: 156, total time:4276.27s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 157, train time every whole data:22.95s
epoch: 157, total time:4303.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 158, train time every whole data:22.98s
epoch: 158, total time:4330.78s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 159, train time every whole data:22.97s
epoch: 159, total time:4358.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 160, train time every whole data:22.96s
epoch: 160, total time:4385.29s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 161, train time every whole data:22.97s
epoch: 161, total time:4412.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2895s
epoch: 162, train time every whole data:22.97s
epoch: 162, total time:4439.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.3224s
epoch: 163, train time every whole data:22.97s
epoch: 163, total time:4467.11s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 164, train time every whole data:22.93s
epoch: 164, total time:4494.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_165.params
epoch: 165, train time every whole data:22.93s
epoch: 165, total time:4521.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 166, train time every whole data:22.95s
epoch: 166, total time:4548.79s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 167, train time every whole data:22.96s
epoch: 167, total time:4576.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 168, train time every whole data:22.94s
epoch: 168, total time:4603.27s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 169, train time every whole data:22.95s
epoch: 169, total time:4630.51s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 170, train time every whole data:22.95s
epoch: 170, total time:4657.74s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 171, train time every whole data:22.98s
epoch: 171, total time:4685.01s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 172, train time every whole data:22.96s
epoch: 172, total time:4712.26s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 173, train time every whole data:22.94s
epoch: 173, total time:4739.49s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 174, train time every whole data:22.93s
epoch: 174, total time:4766.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 175, train time every whole data:22.93s
epoch: 175, total time:4793.93s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_176.params
epoch: 176, train time every whole data:22.96s
epoch: 176, total time:4821.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2902s
epoch: 177, train time every whole data:22.96s
epoch: 177, total time:4848.44s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 178, train time every whole data:22.96s
epoch: 178, total time:4875.69s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2923s
epoch: 179, train time every whole data:22.96s
epoch: 179, total time:4902.95s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 180, train time every whole data:22.97s
epoch: 180, total time:4930.21s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 181, train time every whole data:22.96s
epoch: 181, total time:4957.46s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
epoch: 182, train time every whole data:22.93s
epoch: 182, total time:4984.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 183, train time every whole data:22.92s
epoch: 183, total time:5011.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 184, train time every whole data:22.93s
epoch: 184, total time:5039.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_185.params
epoch: 185, train time every whole data:22.94s
epoch: 185, total time:5066.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2897s
epoch: 186, train time every whole data:22.95s
epoch: 186, total time:5093.58s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 187, train time every whole data:22.92s
epoch: 187, total time:5120.79s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 188, train time every whole data:22.92s
epoch: 188, total time:5148.00s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 189, train time every whole data:22.94s
epoch: 189, total time:5175.23s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 190, train time every whole data:22.96s
epoch: 190, total time:5202.48s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 191, train time every whole data:22.93s
epoch: 191, total time:5229.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 192, train time every whole data:22.93s
epoch: 192, total time:5256.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 193, train time every whole data:22.92s
epoch: 193, total time:5284.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 194, train time every whole data:22.95s
epoch: 194, total time:5311.37s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 195, train time every whole data:22.93s
epoch: 195, total time:5338.58s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 196, train time every whole data:22.93s
epoch: 196, total time:5365.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 197, train time every whole data:22.93s
epoch: 197, total time:5393.02s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 198, train time every whole data:22.94s
epoch: 198, total time:5420.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 199, train time every whole data:22.93s
epoch: 199, total time:5447.46s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 200, train time every whole data:22.92s
epoch: 200, total time:5474.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 201, train time every whole data:22.93s
epoch: 201, total time:5501.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 202, train time every whole data:22.92s
epoch: 202, total time:5529.11s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 203, train time every whole data:22.92s
epoch: 203, total time:5556.31s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 204, train time every whole data:22.95s
epoch: 204, total time:5583.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 205, train time every whole data:22.93s
epoch: 205, total time:5610.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 206, train time every whole data:22.92s
epoch: 206, total time:5637.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 207, train time every whole data:22.92s
epoch: 207, total time:5665.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 208, train time every whole data:22.94s
epoch: 208, total time:5692.42s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 209, train time every whole data:22.95s
epoch: 209, total time:5719.66s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 210, train time every whole data:22.93s
epoch: 210, total time:5746.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 211, train time every whole data:22.92s
epoch: 211, total time:5774.09s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 212, train time every whole data:22.92s
epoch: 212, total time:5801.29s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 213, train time every whole data:22.94s
epoch: 213, total time:5828.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 214, train time every whole data:22.96s
epoch: 214, total time:5855.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 215, train time every whole data:22.95s
epoch: 215, total time:5883.00s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2901s
epoch: 216, train time every whole data:22.96s
epoch: 216, total time:5910.26s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 217, train time every whole data:22.94s
epoch: 217, total time:5937.48s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 218, train time every whole data:22.93s
epoch: 218, total time:5964.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 219, train time every whole data:22.92s
epoch: 219, total time:5991.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 220, train time every whole data:22.92s
epoch: 220, total time:6019.12s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 221, train time every whole data:22.91s
epoch: 221, total time:6046.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 222, train time every whole data:22.92s
epoch: 222, total time:6073.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2895s
epoch: 223, train time every whole data:22.93s
epoch: 223, total time:6100.76s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 224, train time every whole data:22.92s
epoch: 224, total time:6127.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 225, train time every whole data:22.92s
epoch: 225, total time:6155.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 226, train time every whole data:22.91s
epoch: 226, total time:6182.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 227, train time every whole data:22.92s
epoch: 227, total time:6209.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2970s
epoch: 228, train time every whole data:22.91s
epoch: 228, total time:6236.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 229, train time every whole data:22.90s
epoch: 229, total time:6263.99s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 230, train time every whole data:22.89s
epoch: 230, total time:6291.17s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 231, train time every whole data:22.87s
epoch: 231, total time:6318.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 232, train time every whole data:22.92s
epoch: 232, total time:6345.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 233, train time every whole data:22.93s
epoch: 233, total time:6372.76s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 234, train time every whole data:22.93s
epoch: 234, total time:6399.98s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2901s
epoch: 235, train time every whole data:22.92s
epoch: 235, total time:6427.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 236, train time every whole data:22.94s
epoch: 236, total time:6454.42s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 237, train time every whole data:22.92s
epoch: 237, total time:6481.63s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 238, train time every whole data:22.89s
epoch: 238, total time:6508.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 239, train time every whole data:22.90s
epoch: 239, total time:6536.00s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 240, train time every whole data:22.89s
epoch: 240, total time:6563.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 241, train time every whole data:22.92s
epoch: 241, total time:6590.40s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 242, train time every whole data:22.90s
epoch: 242, total time:6617.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 243, train time every whole data:22.89s
epoch: 243, total time:6644.76s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 244, train time every whole data:22.88s
epoch: 244, total time:6671.93s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 245, train time every whole data:22.91s
epoch: 245, total time:6699.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 246, train time every whole data:22.92s
epoch: 246, total time:6726.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 247, train time every whole data:22.90s
epoch: 247, total time:6753.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 248, train time every whole data:22.90s
epoch: 248, total time:6780.72s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 249, train time every whole data:22.89s
epoch: 249, total time:6807.91s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 250, train time every whole data:22.91s
epoch: 250, total time:6835.11s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 251, train time every whole data:22.93s
epoch: 251, total time:6862.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 252, train time every whole data:22.92s
epoch: 252, total time:6889.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 253, train time every whole data:22.93s
epoch: 253, total time:6916.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 254, train time every whole data:22.93s
epoch: 254, total time:6943.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 255, train time every whole data:22.93s
epoch: 255, total time:6971.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 256, train time every whole data:22.90s
epoch: 256, total time:6998.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 257, train time every whole data:22.88s
epoch: 257, total time:7025.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 258, train time every whole data:22.87s
epoch: 258, total time:7052.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 259, train time every whole data:22.88s
epoch: 259, total time:7079.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 260, train time every whole data:22.91s
epoch: 260, total time:7107.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 261, train time every whole data:22.88s
epoch: 261, total time:7134.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2897s
epoch: 262, train time every whole data:22.88s
epoch: 262, total time:7161.42s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 263, train time every whole data:22.89s
epoch: 263, total time:7188.60s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 264, train time every whole data:22.92s
epoch: 264, total time:7215.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 265, train time every whole data:22.93s
epoch: 265, total time:7243.03s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 266, train time every whole data:22.90s
epoch: 266, total time:7270.22s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 267, train time every whole data:22.89s
epoch: 267, total time:7297.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 268, train time every whole data:22.88s
epoch: 268, total time:7324.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 269, train time every whole data:22.92s
epoch: 269, total time:7351.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.3217s
epoch: 270, train time every whole data:22.93s
epoch: 270, total time:7379.02s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 271, train time every whole data:22.92s
epoch: 271, total time:7406.24s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2893s
epoch: 272, train time every whole data:22.92s
epoch: 272, total time:7433.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2899s
epoch: 273, train time every whole data:22.92s
epoch: 273, total time:7460.66s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 274, train time every whole data:22.91s
epoch: 274, total time:7487.86s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 275, train time every whole data:22.88s
epoch: 275, total time:7515.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 276, train time every whole data:22.88s
epoch: 276, total time:7542.21s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 277, train time every whole data:22.89s
epoch: 277, total time:7569.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 278, train time every whole data:22.93s
epoch: 278, total time:7596.60s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 279, train time every whole data:22.90s
epoch: 279, total time:7623.79s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 280, train time every whole data:22.89s
epoch: 280, total time:7650.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 281, train time every whole data:22.90s
epoch: 281, total time:7678.16s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 282, train time every whole data:22.90s
epoch: 282, total time:7705.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 283, train time every whole data:22.91s
epoch: 283, total time:7732.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 284, train time every whole data:22.91s
epoch: 284, total time:7759.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 285, train time every whole data:22.90s
epoch: 285, total time:7786.94s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 286, train time every whole data:22.89s
epoch: 286, total time:7814.12s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 287, train time every whole data:22.89s
epoch: 287, total time:7841.30s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 288, train time every whole data:22.92s
epoch: 288, total time:7868.51s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 289, train time every whole data:22.90s
epoch: 289, total time:7895.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 290, train time every whole data:22.90s
epoch: 290, total time:7922.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 291, train time every whole data:22.91s
epoch: 291, total time:7950.09s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2905s
epoch: 292, train time every whole data:22.90s
epoch: 292, total time:7977.28s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 293, train time every whole data:22.88s
epoch: 293, total time:8004.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 294, train time every whole data:22.87s
epoch: 294, total time:8031.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 295, train time every whole data:22.89s
epoch: 295, total time:8058.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 296, train time every whole data:22.89s
epoch: 296, total time:8085.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 297, train time every whole data:22.92s
epoch: 297, total time:8113.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_298.params
epoch: 298, train time every whole data:22.89s
epoch: 298, total time:8140.37s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 299, train time every whole data:22.88s
epoch: 299, total time:8167.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 300, train time every whole data:22.89s
epoch: 300, total time:8194.72s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 301, train time every whole data:22.92s
epoch: 301, total time:8221.93s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 302, train time every whole data:22.93s
epoch: 302, total time:8249.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 303, train time every whole data:22.91s
epoch: 303, total time:8276.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 304, train time every whole data:22.90s
epoch: 304, total time:8303.53s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 305, train time every whole data:22.88s
epoch: 305, total time:8330.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 306, train time every whole data:22.90s
epoch: 306, total time:8357.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 307, train time every whole data:22.92s
epoch: 307, total time:8385.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 308, train time every whole data:22.92s
epoch: 308, total time:8412.31s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 309, train time every whole data:22.92s
epoch: 309, total time:8439.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 310, train time every whole data:22.91s
epoch: 310, total time:8466.73s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 311, train time every whole data:22.92s
epoch: 311, total time:8493.94s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 312, train time every whole data:22.89s
epoch: 312, total time:8521.11s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 313, train time every whole data:22.89s
epoch: 313, total time:8548.29s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 314, train time every whole data:22.92s
epoch: 314, total time:8575.50s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 315, train time every whole data:22.91s
epoch: 315, total time:8602.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 316, train time every whole data:22.91s
epoch: 316, total time:8629.90s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2871s
epoch: 317, train time every whole data:22.89s
epoch: 317, total time:8657.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 318, train time every whole data:22.88s
epoch: 318, total time:8684.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 319, train time every whole data:22.89s
epoch: 319, total time:8711.43s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 320, train time every whole data:22.91s
epoch: 320, total time:8738.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 321, train time every whole data:22.91s
epoch: 321, total time:8765.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 322, train time every whole data:22.88s
epoch: 322, total time:8792.99s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 323, train time every whole data:22.87s
epoch: 323, total time:8820.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 324, train time every whole data:22.87s
epoch: 324, total time:8847.31s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 325, train time every whole data:22.90s
epoch: 325, total time:8874.50s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 326, train time every whole data:22.92s
epoch: 326, total time:8901.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 327, train time every whole data:22.92s
epoch: 327, total time:8928.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2911s
epoch: 328, train time every whole data:22.92s
epoch: 328, total time:8956.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 329, train time every whole data:22.92s
epoch: 329, total time:8983.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 330, train time every whole data:22.91s
epoch: 330, total time:9010.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 331, train time every whole data:22.89s
epoch: 331, total time:9037.73s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 332, train time every whole data:22.88s
epoch: 332, total time:9064.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 333, train time every whole data:22.89s
epoch: 333, total time:9092.07s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 334, train time every whole data:22.92s
epoch: 334, total time:9119.28s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 335, train time every whole data:22.90s
epoch: 335, total time:9146.47s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 336, train time every whole data:22.89s
epoch: 336, total time:9173.65s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 337, train time every whole data:22.89s
epoch: 337, total time:9200.83s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 338, train time every whole data:22.91s
epoch: 338, total time:9228.03s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 339, train time every whole data:22.92s
epoch: 339, total time:9255.24s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 340, train time every whole data:22.91s
epoch: 340, total time:9282.44s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 341, train time every whole data:22.89s
epoch: 341, total time:9309.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 342, train time every whole data:22.89s
epoch: 342, total time:9336.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 343, train time every whole data:22.88s
epoch: 343, total time:9363.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 344, train time every whole data:22.93s
epoch: 344, total time:9391.19s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 345, train time every whole data:22.91s
epoch: 345, total time:9418.40s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 346, train time every whole data:22.92s
epoch: 346, total time:9445.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 347, train time every whole data:22.92s
epoch: 347, total time:9472.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 348, train time every whole data:22.92s
epoch: 348, total time:9500.04s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 349, train time every whole data:22.88s
epoch: 349, total time:9527.21s
best epoch: 298
apply the best val model on the test data set ...
load weight from: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_298.params
predicting testing set batch 1 / 5, time: 0.97s
test time on whole data:4.29s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 298, predict 0 points
MAE: 13.89
RMSE: 23.65
MAPE: 40.01
current epoch: 298, predict 1 points
MAE: 14.96
RMSE: 25.56
MAPE: 46.24
current epoch: 298, predict 2 points
MAE: 15.70
RMSE: 27.00
MAPE: 48.97
current epoch: 298, predict 3 points
MAE: 16.54
RMSE: 28.69
MAPE: 54.00
current epoch: 298, predict 4 points
MAE: 17.33
RMSE: 30.12
MAPE: 59.81
current epoch: 298, predict 5 points
MAE: 18.04
RMSE: 31.45
MAPE: 66.59
current epoch: 298, predict 6 points
MAE: 18.66
RMSE: 32.78
MAPE: 71.44
current epoch: 298, predict 7 points
MAE: 19.04
RMSE: 33.58
MAPE: 73.48
current epoch: 298, predict 8 points
MAE: 19.34
RMSE: 34.17
MAPE: 74.32
current epoch: 298, predict 9 points
MAE: 19.39
RMSE: 34.55
MAPE: 74.11
current epoch: 298, predict 10 points
MAE: 19.67
RMSE: 35.29
MAPE: 74.43
current epoch: 298, predict 11 points
MAE: 20.12
RMSE: 36.21
MAPE: 77.47
all MAE: 17.73
all RMSE: 31.33
all MAPE: 63.28
[13.891655, 23.650833779733063, 40.0143027305603, 14.963361, 25.560836924430774, 46.236592531204224, 15.695895, 26.995765636571367, 48.97430241107941, 16.54487, 28.686063842727926, 53.99816036224365, 17.331173, 30.118610131769547, 59.81358289718628, 18.044025, 31.45266897645075, 66.58936738967896, 18.662567, 32.77928750679497, 71.44126296043396, 19.035358, 33.57735428384918, 73.48222732543945, 19.34165, 34.17027995534369, 74.31724667549133, 19.393803, 34.5493059411564, 74.11195039749146, 19.67328, 35.29058190081934, 74.43002462387085, 20.124481, 36.21176593577701, 77.47295498847961, 17.725172, 31.332470280009144, 63.277775049209595]
fine tune the model ... 
epoch: 350, train time every whole data:63.97s
epoch: 350, total time:9595.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_350.params
epoch: 351, train time every whole data:63.85s
epoch: 351, total time:9663.74s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_351.params
epoch: 352, train time every whole data:63.91s
epoch: 352, total time:9731.95s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_352.params
epoch: 353, train time every whole data:64.00s
epoch: 353, total time:9800.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_353.params
epoch: 354, train time every whole data:63.96s
epoch: 354, total time:9868.51s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 355, train time every whole data:63.98s
epoch: 355, total time:9936.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2894s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_355.params
epoch: 356, train time every whole data:64.00s
epoch: 356, total time:10005.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_356.params
epoch: 357, train time every whole data:63.95s
epoch: 357, total time:10073.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 358, train time every whole data:63.97s
epoch: 358, total time:10141.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 359, train time every whole data:63.93s
epoch: 359, total time:10209.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 360, train time every whole data:63.98s
epoch: 360, total time:10278.09s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 361, train time every whole data:63.92s
epoch: 361, total time:10346.30s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 362, train time every whole data:63.97s
epoch: 362, total time:10414.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 363, train time every whole data:63.96s
epoch: 363, total time:10482.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 364, train time every whole data:63.88s
epoch: 364, total time:10550.98s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 365, train time every whole data:63.88s
epoch: 365, total time:10619.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_365.params
epoch: 366, train time every whole data:63.96s
epoch: 366, total time:10687.41s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 367, train time every whole data:63.93s
epoch: 367, total time:10755.63s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 368, train time every whole data:64.00s
epoch: 368, total time:10823.92s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2891s
epoch: 369, train time every whole data:63.96s
epoch: 369, total time:10892.17s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 370, train time every whole data:63.99s
epoch: 370, total time:10960.45s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 371, train time every whole data:63.99s
epoch: 371, total time:11028.73s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.3212s
epoch: 372, train time every whole data:63.92s
epoch: 372, total time:11096.97s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 373, train time every whole data:63.91s
epoch: 373, total time:11165.17s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 374, train time every whole data:63.88s
epoch: 374, total time:11233.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 375, train time every whole data:63.91s
epoch: 375, total time:11301.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 376, train time every whole data:63.85s
epoch: 376, total time:11369.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 377, train time every whole data:63.92s
epoch: 377, total time:11437.90s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 378, train time every whole data:63.96s
epoch: 378, total time:11506.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 379, train time every whole data:63.90s
epoch: 379, total time:11574.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 380, train time every whole data:63.93s
epoch: 380, total time:11642.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 381, train time every whole data:63.91s
epoch: 381, total time:11710.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 382, train time every whole data:63.94s
epoch: 382, total time:11778.98s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 383, train time every whole data:63.91s
epoch: 383, total time:11847.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 384, train time every whole data:63.94s
epoch: 384, total time:11915.40s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 385, train time every whole data:63.96s
epoch: 385, total time:11983.66s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 386, train time every whole data:63.93s
epoch: 386, total time:12051.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 387, train time every whole data:63.86s
epoch: 387, total time:12120.03s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2870s
save parameters to file: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_387.params
epoch: 388, train time every whole data:63.89s
epoch: 388, total time:12188.22s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 389, train time every whole data:63.84s
epoch: 389, total time:12256.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 390, train time every whole data:63.99s
epoch: 390, total time:12324.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 391, train time every whole data:63.90s
epoch: 391, total time:12392.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2866s
epoch: 392, train time every whole data:63.99s
epoch: 392, total time:12461.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 393, train time every whole data:63.96s
epoch: 393, total time:12529.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 394, train time every whole data:63.96s
epoch: 394, total time:12597.58s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 395, train time every whole data:63.97s
epoch: 395, total time:12665.84s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 396, train time every whole data:63.93s
epoch: 396, total time:12734.06s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 397, train time every whole data:63.95s
epoch: 397, total time:12802.30s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 398, train time every whole data:63.93s
epoch: 398, total time:12870.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 399, train time every whole data:63.93s
epoch: 399, total time:12938.74s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 400, train time every whole data:63.99s
epoch: 400, total time:13007.02s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 401, train time every whole data:63.89s
epoch: 401, total time:13075.20s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 402, train time every whole data:63.89s
epoch: 402, total time:13143.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 403, train time every whole data:63.89s
epoch: 403, total time:13211.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2869s
epoch: 404, train time every whole data:64.03s
epoch: 404, total time:13279.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 405, train time every whole data:63.90s
epoch: 405, total time:13348.07s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 406, train time every whole data:63.92s
epoch: 406, total time:13416.28s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 407, train time every whole data:63.91s
epoch: 407, total time:13484.48s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 408, train time every whole data:63.95s
epoch: 408, total time:13552.72s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 409, train time every whole data:63.91s
epoch: 409, total time:13620.91s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 410, train time every whole data:63.95s
epoch: 410, total time:13689.15s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 411, train time every whole data:63.90s
epoch: 411, total time:13757.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 412, train time every whole data:63.96s
epoch: 412, total time:13825.58s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 413, train time every whole data:63.80s
epoch: 413, total time:13893.68s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 414, train time every whole data:63.85s
epoch: 414, total time:13961.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 415, train time every whole data:63.98s
epoch: 415, total time:14030.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 416, train time every whole data:63.87s
epoch: 416, total time:14098.24s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 417, train time every whole data:63.86s
epoch: 417, total time:14166.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 418, train time every whole data:63.93s
epoch: 418, total time:14234.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 419, train time every whole data:63.91s
epoch: 419, total time:14302.81s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 420, train time every whole data:63.92s
epoch: 420, total time:14371.02s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 421, train time every whole data:63.86s
epoch: 421, total time:14439.17s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 422, train time every whole data:63.97s
epoch: 422, total time:14507.43s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 423, train time every whole data:63.91s
epoch: 423, total time:14575.63s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 424, train time every whole data:63.94s
epoch: 424, total time:14643.85s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 425, train time every whole data:63.89s
epoch: 425, total time:14712.03s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 426, train time every whole data:63.88s
epoch: 426, total time:14780.20s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 427, train time every whole data:63.88s
epoch: 427, total time:14848.37s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 428, train time every whole data:63.88s
epoch: 428, total time:14916.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 429, train time every whole data:63.92s
epoch: 429, total time:14984.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 430, train time every whole data:63.87s
epoch: 430, total time:15052.91s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 431, train time every whole data:63.88s
epoch: 431, total time:15121.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 432, train time every whole data:63.95s
epoch: 432, total time:15189.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 433, train time every whole data:63.92s
epoch: 433, total time:15257.53s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 434, train time every whole data:63.94s
epoch: 434, total time:15325.76s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 435, train time every whole data:63.90s
epoch: 435, total time:15393.95s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 436, train time every whole data:63.86s
epoch: 436, total time:15462.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 437, train time every whole data:63.91s
epoch: 437, total time:15530.31s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 438, train time every whole data:63.90s
epoch: 438, total time:15598.50s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 439, train time every whole data:63.86s
epoch: 439, total time:15666.64s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 440, train time every whole data:63.96s
epoch: 440, total time:15734.89s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2875s
epoch: 441, train time every whole data:63.97s
epoch: 441, total time:15803.14s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 442, train time every whole data:63.91s
epoch: 442, total time:15871.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 443, train time every whole data:63.79s
epoch: 443, total time:15939.42s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 444, train time every whole data:63.88s
epoch: 444, total time:16007.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 445, train time every whole data:63.93s
epoch: 445, total time:16075.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 446, train time every whole data:63.95s
epoch: 446, total time:16144.06s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 447, train time every whole data:63.93s
epoch: 447, total time:16212.28s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 448, train time every whole data:63.93s
epoch: 448, total time:16280.50s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 449, train time every whole data:63.90s
epoch: 449, total time:16348.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 450, train time every whole data:63.85s
epoch: 450, total time:16416.83s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2869s
epoch: 451, train time every whole data:63.84s
epoch: 451, total time:16484.96s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2903s
epoch: 452, train time every whole data:63.91s
epoch: 452, total time:16553.16s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 453, train time every whole data:63.96s
epoch: 453, total time:16621.41s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 454, train time every whole data:63.94s
epoch: 454, total time:16689.64s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 455, train time every whole data:63.92s
epoch: 455, total time:16757.85s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 456, train time every whole data:63.86s
epoch: 456, total time:16826.01s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2878s
epoch: 457, train time every whole data:63.83s
epoch: 457, total time:16894.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2867s
epoch: 458, train time every whole data:63.89s
epoch: 458, total time:16962.31s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 459, train time every whole data:63.92s
epoch: 459, total time:17030.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 460, train time every whole data:63.94s
epoch: 460, total time:17098.75s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 461, train time every whole data:63.96s
epoch: 461, total time:17167.00s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 462, train time every whole data:63.95s
epoch: 462, total time:17235.24s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 463, train time every whole data:63.86s
epoch: 463, total time:17303.39s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 464, train time every whole data:63.87s
epoch: 464, total time:17371.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2869s
epoch: 465, train time every whole data:63.81s
epoch: 465, total time:17439.66s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2870s
epoch: 466, train time every whole data:63.86s
epoch: 466, total time:17507.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 467, train time every whole data:64.09s
epoch: 467, total time:17576.18s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 468, train time every whole data:63.97s
epoch: 468, total time:17644.44s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 469, train time every whole data:63.94s
epoch: 469, total time:17712.67s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 470, train time every whole data:63.92s
epoch: 470, total time:17780.87s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 471, train time every whole data:63.94s
epoch: 471, total time:17849.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
epoch: 472, train time every whole data:63.96s
epoch: 472, total time:17917.35s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 473, train time every whole data:63.92s
epoch: 473, total time:17985.56s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 474, train time every whole data:63.97s
epoch: 474, total time:18053.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 475, train time every whole data:63.92s
epoch: 475, total time:18122.03s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.3203s
epoch: 476, train time every whole data:64.00s
epoch: 476, total time:18190.36s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 477, train time every whole data:63.96s
epoch: 477, total time:18258.61s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 478, train time every whole data:63.98s
epoch: 478, total time:18326.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 479, train time every whole data:63.96s
epoch: 479, total time:18395.13s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 480, train time every whole data:63.91s
epoch: 480, total time:18463.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 481, train time every whole data:63.91s
epoch: 481, total time:18531.54s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 482, train time every whole data:63.88s
epoch: 482, total time:18599.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 483, train time every whole data:63.84s
epoch: 483, total time:18667.84s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 484, train time every whole data:63.95s
epoch: 484, total time:18736.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2888s
epoch: 485, train time every whole data:63.96s
epoch: 485, total time:18804.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 486, train time every whole data:63.94s
epoch: 486, total time:18872.55s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2887s
epoch: 487, train time every whole data:63.92s
epoch: 487, total time:18940.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 488, train time every whole data:63.94s
epoch: 488, total time:19009.00s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 489, train time every whole data:63.96s
epoch: 489, total time:19077.24s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 490, train time every whole data:63.94s
epoch: 490, total time:19145.47s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 491, train time every whole data:63.96s
epoch: 491, total time:19213.73s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 492, train time every whole data:63.97s
epoch: 492, total time:19281.99s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 493, train time every whole data:63.97s
epoch: 493, total time:19350.25s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 494, train time every whole data:63.94s
epoch: 494, total time:19418.48s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2877s
epoch: 495, train time every whole data:63.85s
epoch: 495, total time:19486.62s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2871s
epoch: 496, train time every whole data:63.89s
epoch: 496, total time:19554.80s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2869s
epoch: 497, train time every whole data:63.90s
epoch: 497, total time:19622.98s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 498, train time every whole data:63.94s
epoch: 498, total time:19691.21s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2892s
epoch: 499, train time every whole data:63.94s
epoch: 499, total time:19759.44s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 500, train time every whole data:63.97s
epoch: 500, total time:19827.70s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 501, train time every whole data:63.97s
epoch: 501, total time:19895.96s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 502, train time every whole data:63.90s
epoch: 502, total time:19964.16s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 503, train time every whole data:63.87s
epoch: 503, total time:20032.32s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 504, train time every whole data:63.98s
epoch: 504, total time:20100.59s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2885s
epoch: 505, train time every whole data:63.94s
epoch: 505, total time:20168.82s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 506, train time every whole data:63.97s
epoch: 506, total time:20237.08s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2942s
epoch: 507, train time every whole data:63.96s
epoch: 507, total time:20305.33s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2876s
epoch: 508, train time every whole data:63.95s
epoch: 508, total time:20373.57s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2874s
epoch: 509, train time every whole data:63.91s
epoch: 509, total time:20441.77s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2873s
epoch: 510, train time every whole data:63.82s
epoch: 510, total time:20509.88s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2872s
epoch: 511, train time every whole data:63.93s
epoch: 511, total time:20578.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2880s
epoch: 512, train time every whole data:63.99s
epoch: 512, total time:20646.38s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2879s
epoch: 513, train time every whole data:63.98s
epoch: 513, total time:20714.64s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2882s
epoch: 514, train time every whole data:63.93s
epoch: 514, total time:20782.86s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2890s
epoch: 515, train time every whole data:63.95s
epoch: 515, total time:20851.10s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2889s
epoch: 516, train time every whole data:63.95s
epoch: 516, total time:20919.34s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2883s
epoch: 517, train time every whole data:63.89s
epoch: 517, total time:20987.52s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2881s
epoch: 518, train time every whole data:63.91s
epoch: 518, total time:21055.71s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2884s
epoch: 519, train time every whole data:63.94s
epoch: 519, total time:21123.95s
validation batch 1 / 5, loss: 0.02
validation cost time: 4.2886s
best epoch: 387
apply the best val model on the test data set ...
load weight from: ../experiments/HZME_OUTFLOW/MAE_ASTGNN_h1d0w0_layer3_head4_dm64_channel1_dir2_drop0.00_1.00e-03_B8_K5_TcontextScaledSAtSE1TE/epoch_387.params
predicting testing set batch 1 / 5, time: 0.97s
test time on whole data:4.29s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 387, predict 0 points
MAE: 13.93
RMSE: 24.00
MAPE: 39.21
current epoch: 387, predict 1 points
MAE: 15.03
RMSE: 25.99
MAPE: 47.04
current epoch: 387, predict 2 points
MAE: 15.76
RMSE: 27.44
MAPE: 51.05
current epoch: 387, predict 3 points
MAE: 16.54
RMSE: 28.84
MAPE: 57.13
current epoch: 387, predict 4 points
MAE: 17.19
RMSE: 30.14
MAPE: 64.15
current epoch: 387, predict 5 points
MAE: 17.78
RMSE: 31.24
MAPE: 70.74
current epoch: 387, predict 6 points
MAE: 18.20
RMSE: 32.39
MAPE: 72.96
current epoch: 387, predict 7 points
MAE: 18.45
RMSE: 32.84
MAPE: 75.09
current epoch: 387, predict 8 points
MAE: 18.65
RMSE: 33.27
MAPE: 76.69
current epoch: 387, predict 9 points
MAE: 18.65
RMSE: 33.42
MAPE: 75.12
current epoch: 387, predict 10 points
MAE: 18.75
RMSE: 33.59
MAPE: 76.17
current epoch: 387, predict 11 points
MAE: 19.14
RMSE: 34.37
MAPE: 78.33
all MAE: 17.34
all RMSE: 30.80
all MAPE: 65.18
[13.929659, 24.003281686850265, 39.21098709106445, 15.028196, 25.99236244117563, 47.039103507995605, 15.764844, 27.44201650789408, 51.05225443840027, 16.537714, 28.84497728970765, 57.13106393814087, 17.192364, 30.13745366286359, 64.15022015571594, 17.775173, 31.237128208446716, 70.73655128479004, 18.200943, 32.39414288361497, 72.95578122138977, 18.44556, 32.841659290616505, 75.09273290634155, 18.645853, 33.27172325503106, 76.69042348861694, 18.646618, 33.42412480739959, 75.1187264919281, 18.747673, 33.58956005847464, 76.17252469062805, 19.143087, 34.37096034502182, 78.32733988761902, 17.338142, 30.798590253793982, 65.17943739891052]
