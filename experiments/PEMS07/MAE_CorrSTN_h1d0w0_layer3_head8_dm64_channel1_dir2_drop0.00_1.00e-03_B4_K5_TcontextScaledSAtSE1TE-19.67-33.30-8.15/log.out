Tue Aug 24 18:05:57 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   31C    P0    39W / 250W |   1030MiB / 32480MiB |     29%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   27C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   27C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   26C    P0    25W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   27C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   66C    P0   135W / 250W |   5729MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   65C    P0   144W / 250W |  30930MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   40C    P0    88W / 250W |   1477MiB / 32480MiB |     49%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     46453      C   python                                      1019MiB |
|    5     49212      C   python                                      1643MiB |
|    5     50876      C   python                                      4075MiB |
|    6      7254      C   python                                      9969MiB |
|    6     28316      C   python                                      9953MiB |
|    6     54094      C   python                                     10997MiB |
|    7     51054      C   python                                      1465MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u9272/ICASTGNN/configurations/PEMS07.conf
total training epoch, fine tune epoch: 200 , 80
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE
load file: /data/home/u9272/ICASTGNN/data/PEMS07/PEMS07_r1_d0_w0.npz
ori length: 16920 , percent: 1.0 , scale: 16920
train: torch.Size([16920, 883, 1, 12]) torch.Size([16920, 883, 12]) torch.Size([16920, 883, 12])
val: torch.Size([5640, 883, 1, 12]) torch.Size([5640, 883, 12]) torch.Size([5640, 883, 12])
test: torch.Size([5641, 883, 1, 12]) torch.Size([5641, 883, 12]) torch.Size([5641, 883, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(883, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(883, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([883, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([883, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 447057
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137]}]
validation batch 1 / 1410, loss: 2.30
validation batch 101 / 1410, loss: 2.45
validation batch 201 / 1410, loss: 2.22
validation batch 301 / 1410, loss: 2.49
validation batch 401 / 1410, loss: 2.40
validation batch 501 / 1410, loss: 2.24
validation batch 601 / 1410, loss: 2.58
validation batch 701 / 1410, loss: 2.22
validation batch 801 / 1410, loss: 2.40
validation batch 901 / 1410, loss: 2.23
validation batch 1001 / 1410, loss: 2.22
validation batch 1101 / 1410, loss: 2.59
validation batch 1201 / 1410, loss: 2.23
validation batch 1301 / 1410, loss: 2.33
validation batch 1401 / 1410, loss: 2.28
validation cost time: 443.4592s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:877.90s
epoch: 0, total time:1321.37s
validation batch 1 / 1410, loss: 0.07
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.06
validation batch 301 / 1410, loss: 0.08
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.07
validation batch 601 / 1410, loss: 0.06
validation batch 701 / 1410, loss: 0.05
validation batch 801 / 1410, loss: 0.09
validation batch 901 / 1410, loss: 0.07
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.07
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.07
validation batch 1401 / 1410, loss: 0.08
validation cost time: 443.3382s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:877.67s
epoch: 1, total time:2642.40s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 443.2516s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:877.69s
epoch: 2, total time:3963.35s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 443.5374s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:877.66s
epoch: 3, total time:5284.55s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 443.3281s
epoch: 4, train time every whole data:877.44s
epoch: 4, total time:6605.32s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.09
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.07
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.08
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.06
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 442.9852s
epoch: 5, train time every whole data:877.75s
epoch: 5, total time:7926.06s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 443.2304s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:877.64s
epoch: 6, total time:9246.94s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.2511s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_7.params
epoch: 7, train time every whole data:877.59s
epoch: 7, total time:10567.79s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.2096s
epoch: 8, train time every whole data:877.50s
epoch: 8, total time:11888.51s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.3004s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:877.47s
epoch: 9, total time:13209.29s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 443.2028s
epoch: 10, train time every whole data:877.44s
epoch: 10, total time:14529.93s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.0137s
epoch: 11, train time every whole data:877.29s
epoch: 11, total time:15850.24s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.2909s
epoch: 12, train time every whole data:877.56s
epoch: 12, total time:17171.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1097s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_13.params
epoch: 13, train time every whole data:877.46s
epoch: 13, total time:18491.68s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 443.1860s
epoch: 14, train time every whole data:877.59s
epoch: 14, total time:19812.46s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1975s
epoch: 15, train time every whole data:877.49s
epoch: 15, total time:21133.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1741s
epoch: 16, train time every whole data:877.51s
epoch: 16, total time:22453.84s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.1791s
epoch: 17, train time every whole data:877.58s
epoch: 17, total time:23774.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2435s
epoch: 18, train time every whole data:877.62s
epoch: 18, total time:25095.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1644s
epoch: 19, train time every whole data:877.72s
epoch: 19, total time:26416.35s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2300s
epoch: 20, train time every whole data:877.59s
epoch: 20, total time:27737.17s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.07
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.06
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.06
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.06
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.2080s
epoch: 21, train time every whole data:877.16s
epoch: 21, total time:29057.54s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.1444s
epoch: 22, train time every whole data:877.66s
epoch: 22, total time:30378.35s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2532s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_23.params
epoch: 23, train time every whole data:877.60s
epoch: 23, total time:31699.22s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.06
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.06
validation batch 701 / 1410, loss: 0.05
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.05
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.06
validation batch 1401 / 1410, loss: 0.06
validation cost time: 443.1656s
epoch: 24, train time every whole data:877.81s
epoch: 24, total time:33020.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9415s
epoch: 25, train time every whole data:877.54s
epoch: 25, total time:34340.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8147s
epoch: 26, train time every whole data:877.78s
epoch: 26, total time:35661.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1395s
epoch: 27, train time every whole data:877.61s
epoch: 27, total time:36982.03s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7737s
epoch: 28, train time every whole data:877.79s
epoch: 28, total time:38302.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.0547s
epoch: 29, train time every whole data:877.68s
epoch: 29, total time:39623.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9633s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_30.params
epoch: 30, train time every whole data:877.68s
epoch: 30, total time:40943.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1064s
epoch: 31, train time every whole data:877.10s
epoch: 31, total time:42264.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2508s
epoch: 32, train time every whole data:877.45s
epoch: 32, total time:43584.90s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7788s
epoch: 33, train time every whole data:876.59s
epoch: 33, total time:44904.28s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7336s
epoch: 34, train time every whole data:877.24s
epoch: 34, total time:46224.25s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0979s
epoch: 35, train time every whole data:877.37s
epoch: 35, total time:47544.71s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7563s
epoch: 36, train time every whole data:877.19s
epoch: 36, total time:48864.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7070s
epoch: 37, train time every whole data:876.87s
epoch: 37, total time:50184.24s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0780s
epoch: 38, train time every whole data:877.06s
epoch: 38, total time:51504.38s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1725s
epoch: 39, train time every whole data:876.36s
epoch: 39, total time:52823.92s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7832s
epoch: 40, train time every whole data:877.00s
epoch: 40, total time:54143.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2126s
epoch: 41, train time every whole data:876.60s
epoch: 41, total time:55463.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1524s
epoch: 42, train time every whole data:877.01s
epoch: 42, total time:56783.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8441s
epoch: 43, train time every whole data:876.44s
epoch: 43, total time:58102.97s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 442.7502s
epoch: 44, train time every whole data:876.81s
epoch: 44, total time:59422.54s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8606s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_45.params
epoch: 45, train time every whole data:876.32s
epoch: 45, total time:60741.72s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7801s
epoch: 46, train time every whole data:877.07s
epoch: 46, total time:62061.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9930s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_47.params
epoch: 47, train time every whole data:876.67s
epoch: 47, total time:63381.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7852s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_48.params
epoch: 48, train time every whole data:876.74s
epoch: 48, total time:64700.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7200s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_49.params
epoch: 49, train time every whole data:877.30s
epoch: 49, total time:66020.83s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1900s
epoch: 50, train time every whole data:877.42s
epoch: 50, total time:67341.45s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0692s
epoch: 51, train time every whole data:877.20s
epoch: 51, total time:68661.72s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9037s
epoch: 52, train time every whole data:877.34s
epoch: 52, total time:69981.96s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.2313s
epoch: 53, train time every whole data:877.42s
epoch: 53, total time:71302.62s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9125s
epoch: 54, train time every whole data:876.58s
epoch: 54, total time:72622.12s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8159s
epoch: 55, train time every whole data:877.40s
epoch: 55, total time:73942.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0565s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_56.params
epoch: 56, train time every whole data:877.17s
epoch: 56, total time:75262.57s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1321s
epoch: 57, train time every whole data:876.47s
epoch: 57, total time:76582.17s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7380s
epoch: 58, train time every whole data:876.16s
epoch: 58, total time:77901.07s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.04
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 442.8509s
epoch: 59, train time every whole data:876.92s
epoch: 59, total time:79220.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.3106s
epoch: 60, train time every whole data:878.20s
epoch: 60, total time:80542.36s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.3518s
epoch: 61, train time every whole data:878.21s
epoch: 61, total time:81863.93s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.3657s
epoch: 62, train time every whole data:878.22s
epoch: 62, total time:83185.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.3301s
epoch: 63, train time every whole data:878.16s
epoch: 63, total time:84507.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8728s
epoch: 64, train time every whole data:877.41s
epoch: 64, total time:85827.29s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8002s
epoch: 65, train time every whole data:877.36s
epoch: 65, total time:87147.46s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8079s
epoch: 66, train time every whole data:877.41s
epoch: 66, total time:88467.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8118s
epoch: 67, train time every whole data:877.37s
epoch: 67, total time:89787.86s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8333s
epoch: 68, train time every whole data:877.50s
epoch: 68, total time:91108.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8264s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_69.params
epoch: 69, train time every whole data:877.40s
epoch: 69, total time:92428.43s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7652s
epoch: 70, train time every whole data:877.47s
epoch: 70, total time:93748.67s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 443.0745s
epoch: 71, train time every whole data:876.84s
epoch: 71, total time:95068.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1162s
epoch: 72, train time every whole data:876.82s
epoch: 72, total time:96388.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7863s
epoch: 73, train time every whole data:876.74s
epoch: 73, total time:97708.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9320s
epoch: 74, train time every whole data:876.18s
epoch: 74, total time:99027.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8906s
epoch: 75, train time every whole data:876.24s
epoch: 75, total time:100346.29s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 442.7989s
epoch: 76, train time every whole data:876.72s
epoch: 76, total time:101665.81s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1169s
epoch: 77, train time every whole data:876.77s
epoch: 77, total time:102985.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1292s
epoch: 78, train time every whole data:876.77s
epoch: 78, total time:104305.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1686s
epoch: 79, train time every whole data:876.73s
epoch: 79, total time:105625.50s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9437s
epoch: 80, train time every whole data:876.74s
epoch: 80, total time:106945.19s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7351s
epoch: 81, train time every whole data:876.63s
epoch: 81, total time:108264.55s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6645s
epoch: 82, train time every whole data:876.35s
epoch: 82, total time:109583.57s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7807s
epoch: 83, train time every whole data:876.60s
epoch: 83, total time:110902.95s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8383s
epoch: 84, train time every whole data:876.81s
epoch: 84, total time:112222.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8415s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_85.params
epoch: 85, train time every whole data:876.56s
epoch: 85, total time:113542.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1348s
epoch: 86, train time every whole data:876.21s
epoch: 86, total time:114861.35s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1091s
epoch: 87, train time every whole data:876.24s
epoch: 87, total time:116180.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7091s
epoch: 88, train time every whole data:876.18s
epoch: 88, total time:117499.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9559s
epoch: 89, train time every whole data:875.86s
epoch: 89, total time:118818.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1779s
epoch: 90, train time every whole data:876.57s
epoch: 90, total time:120138.17s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0216s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_91.params
epoch: 91, train time every whole data:876.51s
epoch: 91, total time:121457.71s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9032s
epoch: 92, train time every whole data:876.35s
epoch: 92, total time:122776.97s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7287s
epoch: 93, train time every whole data:876.10s
epoch: 93, total time:124095.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8692s
epoch: 94, train time every whole data:876.40s
epoch: 94, total time:125415.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7309s
epoch: 95, train time every whole data:876.09s
epoch: 95, total time:126733.89s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9480s
epoch: 96, train time every whole data:875.76s
epoch: 96, total time:128052.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6636s
epoch: 97, train time every whole data:876.06s
epoch: 97, total time:129371.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8293s
epoch: 98, train time every whole data:876.02s
epoch: 98, total time:130690.18s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8851s
epoch: 99, train time every whole data:876.15s
epoch: 99, total time:132009.22s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0231s
epoch: 100, train time every whole data:876.26s
epoch: 100, total time:133328.50s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9036s
epoch: 101, train time every whole data:876.34s
epoch: 101, total time:134647.75s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7453s
epoch: 102, train time every whole data:876.08s
epoch: 102, total time:135966.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7311s
epoch: 103, train time every whole data:876.02s
epoch: 103, total time:137285.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0688s
epoch: 104, train time every whole data:876.43s
epoch: 104, total time:138604.84s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7023s
epoch: 105, train time every whole data:875.79s
epoch: 105, total time:139923.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6247s
epoch: 106, train time every whole data:875.82s
epoch: 106, total time:141241.78s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6493s
epoch: 107, train time every whole data:876.08s
epoch: 107, total time:142560.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9207s
epoch: 108, train time every whole data:875.78s
epoch: 108, total time:143879.22s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6746s
epoch: 109, train time every whole data:875.80s
epoch: 109, total time:145197.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6750s
epoch: 110, train time every whole data:875.97s
epoch: 110, total time:146516.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7406s
epoch: 111, train time every whole data:876.05s
epoch: 111, total time:147835.14s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6747s
epoch: 112, train time every whole data:876.04s
epoch: 112, total time:149153.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 442.6956s
epoch: 113, train time every whole data:876.06s
epoch: 113, total time:150472.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6961s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_114.params
epoch: 114, train time every whole data:875.78s
epoch: 114, total time:151791.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6195s
epoch: 115, train time every whole data:875.86s
epoch: 115, total time:153109.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6526s
epoch: 116, train time every whole data:875.82s
epoch: 116, total time:154428.06s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6354s
epoch: 117, train time every whole data:875.79s
epoch: 117, total time:155746.49s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6726s
epoch: 118, train time every whole data:876.03s
epoch: 118, total time:157065.19s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6913s
epoch: 119, train time every whole data:875.81s
epoch: 119, total time:158383.69s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6779s
epoch: 120, train time every whole data:875.82s
epoch: 120, total time:159702.18s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6100s
epoch: 121, train time every whole data:875.82s
epoch: 121, total time:161020.62s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6199s
epoch: 122, train time every whole data:875.81s
epoch: 122, total time:162339.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6568s
epoch: 123, train time every whole data:876.10s
epoch: 123, total time:163657.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7716s
epoch: 124, train time every whole data:875.88s
epoch: 124, total time:164976.45s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7451s
epoch: 125, train time every whole data:875.80s
epoch: 125, total time:166295.00s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.5933s
epoch: 126, train time every whole data:875.80s
epoch: 126, total time:167613.39s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6658s
epoch: 127, train time every whole data:875.79s
epoch: 127, total time:168931.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6525s
epoch: 128, train time every whole data:875.87s
epoch: 128, total time:170250.38s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6665s
epoch: 129, train time every whole data:875.83s
epoch: 129, total time:171568.88s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6344s
epoch: 130, train time every whole data:876.16s
epoch: 130, total time:172887.67s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8416s
epoch: 131, train time every whole data:875.80s
epoch: 131, total time:174206.32s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6974s
epoch: 132, train time every whole data:875.91s
epoch: 132, total time:175524.93s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6636s
epoch: 133, train time every whole data:875.80s
epoch: 133, total time:176843.39s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6598s
epoch: 134, train time every whole data:875.81s
epoch: 134, total time:178161.86s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6404s
epoch: 135, train time every whole data:875.91s
epoch: 135, total time:179480.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7179s
epoch: 136, train time every whole data:876.07s
epoch: 136, total time:180799.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6224s
epoch: 137, train time every whole data:875.83s
epoch: 137, total time:182117.65s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7086s
epoch: 138, train time every whole data:875.77s
epoch: 138, total time:183436.13s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7203s
epoch: 139, train time every whole data:875.96s
epoch: 139, total time:184754.81s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9759s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_140.params
epoch: 140, train time every whole data:875.78s
epoch: 140, total time:186073.57s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6981s
epoch: 141, train time every whole data:875.81s
epoch: 141, total time:187392.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6862s
epoch: 142, train time every whole data:875.91s
epoch: 142, total time:188710.69s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0351s
epoch: 143, train time every whole data:876.43s
epoch: 143, total time:190030.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1143s
epoch: 144, train time every whole data:876.46s
epoch: 144, total time:191349.73s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1855s
epoch: 145, train time every whole data:876.40s
epoch: 145, total time:192669.31s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7316s
epoch: 146, train time every whole data:875.81s
epoch: 146, total time:193987.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7649s
epoch: 147, train time every whole data:876.33s
epoch: 147, total time:195306.94s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8971s
epoch: 148, train time every whole data:875.74s
epoch: 148, total time:196625.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6610s
epoch: 149, train time every whole data:875.74s
epoch: 149, total time:197943.98s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7310s
epoch: 150, train time every whole data:875.78s
epoch: 150, total time:199262.50s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7015s
epoch: 151, train time every whole data:876.30s
epoch: 151, total time:200581.51s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8196s
epoch: 152, train time every whole data:875.75s
epoch: 152, total time:201900.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7027s
epoch: 153, train time every whole data:876.40s
epoch: 153, total time:203219.18s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9141s
epoch: 154, train time every whole data:875.78s
epoch: 154, total time:204537.88s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6684s
epoch: 155, train time every whole data:875.83s
epoch: 155, total time:205856.38s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7946s
epoch: 156, train time every whole data:875.76s
epoch: 156, total time:207174.94s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7619s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_157.params
epoch: 157, train time every whole data:875.79s
epoch: 157, total time:208493.51s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6503s
epoch: 158, train time every whole data:875.82s
epoch: 158, total time:209811.98s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6590s
epoch: 159, train time every whole data:875.78s
epoch: 159, total time:211130.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6711s
epoch: 160, train time every whole data:875.79s
epoch: 160, total time:212448.88s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6004s
epoch: 161, train time every whole data:875.80s
epoch: 161, total time:213767.28s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6586s
epoch: 162, train time every whole data:876.39s
epoch: 162, total time:215086.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9891s
epoch: 163, train time every whole data:875.78s
epoch: 163, total time:216405.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.5608s
epoch: 164, train time every whole data:875.79s
epoch: 164, total time:217723.45s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6144s
epoch: 165, train time every whole data:875.84s
epoch: 165, total time:219041.91s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6352s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_166.params
epoch: 166, train time every whole data:875.82s
epoch: 166, total time:220360.37s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6742s
epoch: 167, train time every whole data:875.82s
epoch: 167, total time:221678.86s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7044s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_168.params
epoch: 168, train time every whole data:875.85s
epoch: 168, total time:222997.43s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7376s
epoch: 169, train time every whole data:875.83s
epoch: 169, total time:224316.00s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6033s
epoch: 170, train time every whole data:876.01s
epoch: 170, total time:225634.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6862s
epoch: 171, train time every whole data:1054.57s
epoch: 171, total time:227131.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9075s
epoch: 172, train time every whole data:1451.28s
epoch: 172, total time:229337.06s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.5057s
epoch: 173, train time every whole data:1451.45s
epoch: 173, total time:231542.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.0983s
epoch: 174, train time every whole data:1451.30s
epoch: 174, total time:233747.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.2861s
epoch: 175, train time every whole data:1451.65s
epoch: 175, total time:235953.35s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.0383s
epoch: 176, train time every whole data:1451.60s
epoch: 176, total time:238158.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.2918s
epoch: 177, train time every whole data:1451.59s
epoch: 177, total time:240364.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.6223s
epoch: 178, train time every whole data:1451.49s
epoch: 178, total time:242570.98s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.0819s
epoch: 179, train time every whole data:1451.76s
epoch: 179, total time:244776.82s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.6453s
epoch: 180, train time every whole data:1451.69s
epoch: 180, total time:246982.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.1550s
epoch: 181, train time every whole data:1451.78s
epoch: 181, total time:249188.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.4631s
epoch: 182, train time every whole data:1451.28s
epoch: 182, total time:251393.83s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.8701s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_183.params
epoch: 183, train time every whole data:1451.62s
epoch: 183, total time:253599.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9603s
epoch: 184, train time every whole data:1451.69s
epoch: 184, total time:255804.98s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9037s
epoch: 185, train time every whole data:1451.51s
epoch: 185, total time:258010.39s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.8494s
epoch: 186, train time every whole data:1451.48s
epoch: 186, total time:260215.73s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9183s
epoch: 187, train time every whole data:1452.11s
epoch: 187, total time:262421.76s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.8473s
epoch: 188, train time every whole data:1451.76s
epoch: 188, total time:264627.37s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 754.0268s
epoch: 189, train time every whole data:1442.75s
epoch: 189, total time:266824.14s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.1247s
epoch: 190, train time every whole data:1448.65s
epoch: 190, total time:269024.92s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.2225s
epoch: 191, train time every whole data:1447.51s
epoch: 191, total time:271224.65s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.8721s
epoch: 192, train time every whole data:1447.21s
epoch: 192, total time:273423.73s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.9642s
epoch: 193, train time every whole data:1447.28s
epoch: 193, total time:275622.97s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.4097s
epoch: 194, train time every whole data:1447.38s
epoch: 194, total time:277821.76s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.8310s
epoch: 195, train time every whole data:1447.42s
epoch: 195, total time:280021.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.7083s
epoch: 196, train time every whole data:1447.43s
epoch: 196, total time:282220.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.0212s
epoch: 197, train time every whole data:1447.39s
epoch: 197, total time:284419.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.5848s
epoch: 198, train time every whole data:1447.27s
epoch: 198, total time:286618.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.8160s
epoch: 199, train time every whole data:1447.35s
epoch: 199, total time:288817.58s
best epoch: 183
apply the best val model on the test data set ...
load weight from: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_183.params
predicting testing set batch 1 / 1411, time: 0.53s
predicting testing set batch 101 / 1411, time: 53.92s
predicting testing set batch 201 / 1411, time: 107.35s
predicting testing set batch 301 / 1411, time: 160.81s
predicting testing set batch 401 / 1411, time: 214.23s
predicting testing set batch 501 / 1411, time: 267.62s
predicting testing set batch 601 / 1411, time: 321.03s
predicting testing set batch 701 / 1411, time: 374.49s
predicting testing set batch 801 / 1411, time: 427.91s
predicting testing set batch 901 / 1411, time: 481.31s
predicting testing set batch 1001 / 1411, time: 534.75s
predicting testing set batch 1101 / 1411, time: 588.17s
predicting testing set batch 1201 / 1411, time: 641.59s
predicting testing set batch 1301 / 1411, time: 695.03s
predicting testing set batch 1401 / 1411, time: 748.43s
test time on whole data:753.45s
input: (5641, 883, 12, 1)
prediction: (5641, 883, 12, 1)
data_target_tensor: (5641, 883, 12)
current epoch: 183, predict 0 points
MAE: 15.96
RMSE: 25.97
MAPE: 6.75
current epoch: 183, predict 1 points
MAE: 17.56
RMSE: 28.80
MAPE: 7.45
current epoch: 183, predict 2 points
MAE: 18.55
RMSE: 30.55
MAPE: 7.88
current epoch: 183, predict 3 points
MAE: 19.30
RMSE: 31.86
MAPE: 8.20
current epoch: 183, predict 4 points
MAE: 19.95
RMSE: 32.97
MAPE: 8.52
current epoch: 183, predict 5 points
MAE: 20.49
RMSE: 33.81
MAPE: 8.79
current epoch: 183, predict 6 points
MAE: 21.04
RMSE: 34.66
MAPE: 9.05
current epoch: 183, predict 7 points
MAE: 21.55
RMSE: 35.47
MAPE: 9.33
current epoch: 183, predict 8 points
MAE: 22.04
RMSE: 36.22
MAPE: 9.58
current epoch: 183, predict 9 points
MAE: 22.49
RMSE: 36.89
MAPE: 9.79
current epoch: 183, predict 10 points
MAE: 22.95
RMSE: 37.58
MAPE: 10.01
current epoch: 183, predict 11 points
MAE: 23.42
RMSE: 38.24
MAPE: 10.24
all MAE: 20.44
all RMSE: 33.78
all MAPE: 8.80
[15.961022, 25.96679562629275, 6.749493628740311, 17.557316, 28.80377210709834, 7.450541108846664, 18.550238, 30.554434806229438, 7.882309705018997, 19.302816, 31.86014033993681, 8.204635977745056, 19.946972, 32.97168788746548, 8.516307175159454, 20.490202, 33.81312095086019, 8.789939433336258, 21.038671, 34.66281849948335, 9.0492382645607, 21.55118, 35.466655706341804, 9.328798204660416, 22.039335, 36.21589687586706, 9.578294306993484, 22.48741, 36.8935218975881, 9.792058914899826, 22.945492, 37.57933502469725, 10.009057074785233, 23.424091, 38.24344274625308, 10.235095769166946, 20.441261, 33.77616354224992, 8.79877582192421]
fine tune the model ... 
epoch: 200, train time every whole data:3258.96s
epoch: 200, total time:292836.90s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.4092s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_200.params
epoch: 201, train time every whole data:3259.12s
epoch: 201, total time:296849.44s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.7559s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_201.params
epoch: 202, train time every whole data:3258.34s
epoch: 202, total time:300860.55s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.2748s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_202.params
epoch: 203, train time every whole data:3255.41s
epoch: 203, total time:304867.24s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.0197s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_203.params
epoch: 204, train time every whole data:3205.63s
epoch: 204, total time:308825.90s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0794s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_204.params
epoch: 205, train time every whole data:1949.71s
epoch: 205, total time:311218.71s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1874s
epoch: 206, train time every whole data:1950.18s
epoch: 206, total time:313612.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7166s
epoch: 207, train time every whole data:1949.20s
epoch: 207, total time:316003.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7702s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_207.params
epoch: 208, train time every whole data:1949.49s
epoch: 208, total time:318396.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0647s
epoch: 209, train time every whole data:1950.45s
epoch: 209, total time:320789.78s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6637s
epoch: 210, train time every whole data:1949.20s
epoch: 210, total time:323181.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9794s
epoch: 211, train time every whole data:1949.23s
epoch: 211, total time:325573.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7645s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_211.params
epoch: 212, train time every whole data:1949.91s
epoch: 212, total time:327966.54s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7643s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_212.params
epoch: 213, train time every whole data:1949.48s
epoch: 213, total time:330358.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.1255s
epoch: 214, train time every whole data:1950.90s
epoch: 214, total time:332752.83s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7503s
epoch: 215, train time every whole data:1949.06s
epoch: 215, total time:335144.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7501s
epoch: 216, train time every whole data:1949.10s
epoch: 216, total time:337536.49s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9168s
epoch: 217, train time every whole data:1949.19s
epoch: 217, total time:339928.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6564s
epoch: 218, train time every whole data:1949.85s
epoch: 218, total time:342321.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7716s
epoch: 219, train time every whole data:1948.99s
epoch: 219, total time:344712.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.6950s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_219.params
epoch: 220, train time every whole data:1949.31s
epoch: 220, total time:347104.89s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9499s
epoch: 221, train time every whole data:1948.98s
epoch: 221, total time:349496.83s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8999s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_221.params
epoch: 222, train time every whole data:1949.04s
epoch: 222, total time:351888.78s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0855s
epoch: 223, train time every whole data:2701.15s
epoch: 223, total time:355033.02s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.8982s
epoch: 224, train time every whole data:3259.63s
epoch: 224, total time:359045.55s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.5439s
epoch: 225, train time every whole data:3259.99s
epoch: 225, total time:363058.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.4354s
epoch: 226, train time every whole data:3259.73s
epoch: 226, total time:367071.25s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.3564s
epoch: 227, train time every whole data:3259.87s
epoch: 227, total time:371083.48s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.2947s
epoch: 228, train time every whole data:3257.39s
epoch: 228, total time:375094.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.5558s
epoch: 229, train time every whole data:3251.95s
epoch: 229, total time:379097.67s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 750.0893s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_229.params
epoch: 230, train time every whole data:3252.29s
epoch: 230, total time:383100.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 750.9118s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_230.params
epoch: 231, train time every whole data:3252.57s
epoch: 231, total time:387103.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 750.3269s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_231.params
epoch: 232, train time every whole data:3252.69s
epoch: 232, total time:391106.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 751.7340s
epoch: 233, train time every whole data:3252.38s
epoch: 233, total time:395110.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 458.4123s
epoch: 234, train time every whole data:1950.83s
epoch: 234, total time:397519.95s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7496s
epoch: 235, train time every whole data:1950.76s
epoch: 235, total time:399913.45s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.9004s
epoch: 236, train time every whole data:1950.77s
epoch: 236, total time:402307.12s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8560s
epoch: 237, train time every whole data:1950.75s
epoch: 237, total time:404700.74s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7488s
epoch: 238, train time every whole data:1950.66s
epoch: 238, total time:407094.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7824s
epoch: 239, train time every whole data:1950.77s
epoch: 239, total time:409487.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8391s
epoch: 240, train time every whole data:1950.66s
epoch: 240, total time:411881.21s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7298s
epoch: 241, train time every whole data:1950.76s
epoch: 241, total time:414274.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8019s
epoch: 242, train time every whole data:1950.74s
epoch: 242, total time:416668.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8011s
epoch: 243, train time every whole data:1950.80s
epoch: 243, total time:419061.84s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8048s
epoch: 244, train time every whole data:1950.69s
epoch: 244, total time:421455.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8462s
epoch: 245, train time every whole data:1950.80s
epoch: 245, total time:423848.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7936s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_245.params
epoch: 246, train time every whole data:1950.93s
epoch: 246, total time:426242.72s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8570s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_246.params
epoch: 247, train time every whole data:1950.93s
epoch: 247, total time:428636.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7231s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_247.params
epoch: 248, train time every whole data:1949.08s
epoch: 248, total time:431028.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 443.0743s
epoch: 249, train time every whole data:1949.07s
epoch: 249, total time:433420.48s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.8154s
epoch: 250, train time every whole data:1948.89s
epoch: 250, total time:435812.19s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7598s
epoch: 251, train time every whole data:1949.01s
epoch: 251, total time:438203.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 442.7433s
epoch: 252, train time every whole data:2638.86s
epoch: 252, total time:441285.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 748.8368s
epoch: 253, train time every whole data:3247.76s
epoch: 253, total time:445282.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 748.8549s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_253.params
epoch: 254, train time every whole data:3252.65s
epoch: 254, total time:449283.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.4471s
epoch: 255, train time every whole data:3260.07s
epoch: 255, total time:453296.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.3599s
epoch: 256, train time every whole data:3260.51s
epoch: 256, total time:457310.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.8805s
epoch: 257, train time every whole data:3260.74s
epoch: 257, total time:461323.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 752.6575s
epoch: 258, train time every whole data:3260.86s
epoch: 258, total time:465337.22s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9456s
epoch: 259, train time every whole data:3260.64s
epoch: 259, total time:469351.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.2323s
epoch: 260, train time every whole data:3260.62s
epoch: 260, total time:473365.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.2019s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_260.params
epoch: 261, train time every whole data:3260.53s
epoch: 261, total time:477379.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 753.9576s
epoch: 262, train time every whole data:3260.88s
epoch: 262, total time:481394.25s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 581.8112s
epoch: 263, train time every whole data:2377.23s
epoch: 263, total time:484353.29s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 539.9665s
epoch: 264, train time every whole data:2377.42s
epoch: 264, total time:487270.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.2063s
epoch: 265, train time every whole data:2379.04s
epoch: 265, total time:490189.93s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.3102s
epoch: 266, train time every whole data:2378.46s
epoch: 266, total time:493108.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.4880s
epoch: 267, train time every whole data:2376.62s
epoch: 267, total time:496025.81s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.5656s
epoch: 268, train time every whole data:2378.13s
epoch: 268, total time:498944.51s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.4686s
epoch: 269, train time every whole data:2375.81s
epoch: 269, total time:501860.79s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.0517s
epoch: 270, train time every whole data:2375.48s
epoch: 270, total time:504776.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.4521s
epoch: 271, train time every whole data:2376.30s
epoch: 271, total time:507693.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.5168s
epoch: 272, train time every whole data:2378.80s
epoch: 272, total time:510612.40s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.6939s
epoch: 273, train time every whole data:2378.73s
epoch: 273, total time:513531.82s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.1290s
epoch: 274, train time every whole data:2375.31s
epoch: 274, total time:516447.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.0418s
epoch: 275, train time every whole data:2376.14s
epoch: 275, total time:519363.44s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.3966s
epoch: 276, train time every whole data:2375.44s
epoch: 276, total time:522279.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 539.7265s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_276.params
epoch: 277, train time every whole data:2374.65s
epoch: 277, total time:525193.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 540.3075s
epoch: 278, train time every whole data:3316.40s
epoch: 278, total time:529050.37s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.02
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 781.7439s
epoch: 279, train time every whole data:3414.94s
epoch: 279, total time:533247.05s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 782.1257s
best epoch: 276
apply the best val model on the test data set ...
load weight from: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03_4TcontextScaledSAtSE1TE/epoch_276.params
predicting testing set batch 1 / 1411, time: 0.55s
predicting testing set batch 101 / 1411, time: 56.07s
predicting testing set batch 201 / 1411, time: 111.55s
predicting testing set batch 301 / 1411, time: 167.06s
predicting testing set batch 401 / 1411, time: 222.55s
predicting testing set batch 501 / 1411, time: 278.05s
predicting testing set batch 601 / 1411, time: 333.51s
predicting testing set batch 701 / 1411, time: 389.04s
predicting testing set batch 801 / 1411, time: 445.16s
predicting testing set batch 901 / 1411, time: 500.65s
predicting testing set batch 1001 / 1411, time: 556.14s
predicting testing set batch 1101 / 1411, time: 611.65s
predicting testing set batch 1201 / 1411, time: 667.14s
predicting testing set batch 1301 / 1411, time: 722.63s
predicting testing set batch 1401 / 1411, time: 778.15s
test time on whole data:783.35s
input: (5641, 883, 12, 1)
prediction: (5641, 883, 12, 1)
data_target_tensor: (5641, 883, 12)
current epoch: 276, predict 0 points
MAE: 15.93
RMSE: 25.98
MAPE: 6.67
current epoch: 276, predict 1 points
MAE: 17.32
RMSE: 28.67
MAPE: 7.23
current epoch: 276, predict 2 points
MAE: 18.20
RMSE: 30.37
MAPE: 7.56
current epoch: 276, predict 3 points
MAE: 18.82
RMSE: 31.55
MAPE: 7.78
current epoch: 276, predict 4 points
MAE: 19.32
RMSE: 32.48
MAPE: 7.97
current epoch: 276, predict 5 points
MAE: 19.78
RMSE: 33.36
MAPE: 8.17
current epoch: 276, predict 6 points
MAE: 20.22
RMSE: 34.17
MAPE: 8.35
current epoch: 276, predict 7 points
MAE: 20.61
RMSE: 34.92
MAPE: 8.51
current epoch: 276, predict 8 points
MAE: 20.96
RMSE: 35.62
MAPE: 8.67
current epoch: 276, predict 9 points
MAE: 21.29
RMSE: 36.22
MAPE: 8.82
current epoch: 276, predict 10 points
MAE: 21.62
RMSE: 36.82
MAPE: 8.96
current epoch: 276, predict 11 points
MAE: 21.99
RMSE: 37.43
MAPE: 9.13
all MAE: 19.67
all RMSE: 33.30
all MAPE: 8.15
[15.929091, 25.976971331369278, 6.667410582304001, 17.318321, 28.67030394197104, 7.231611013412476, 18.204563, 30.373018678950483, 7.555130124092102, 18.817827, 31.54962802190087, 7.784508913755417, 19.322409, 32.48221982088336, 7.9719409346580505, 19.778578, 33.35684636201015, 8.17217156291008, 20.216356, 34.168524069812776, 8.348110318183899, 20.60953, 34.9204487963804, 8.508370071649551, 20.964361, 35.61580884724858, 8.670751750469208, 21.287727, 36.22262233936998, 8.81604328751564, 21.616264, 36.81629331050316, 8.957522362470627, 21.989206, 37.433826705747535, 9.133109450340271, 19.67115, 33.29999288839545, 8.151375502347946]
