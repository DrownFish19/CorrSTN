Mon Aug 16 09:44:41 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   61C    P0   174W / 250W |   5584MiB / 32480MiB |     61%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   23C    P0    23W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   41C    P0   100W / 250W |   9935MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   25C    P0    32W / 250W |   7568MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   22C    P0    23W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   30C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   41C    P0   156W / 250W |   7694MiB / 32480MiB |     96%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   44C    P0   125W / 250W |  13191MiB / 32480MiB |    100%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     17595      C   python                                      5573MiB |
|    2      6474      C   python                                      2367MiB |
|    2     38749      C   python                                      7557MiB |
|    3     31559      C   python                                      7557MiB |
|    6      6936      C   python                                      7683MiB |
|    7      6729      C   python                                      5623MiB |
|    7     21207      C   python                                      7557MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/IC-STGNN/configurations/PEMS07-smooth.conf
total training epoch, fine tune epoch: 200 , 80
batch_size: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE
load file: /data/home/u18112042/IC-STGNN/data/PEMS07/PEMS07_r1_d0_w0.npz
ori length: 16920 , percent: 1.0 , scale: 16920
train: torch.Size([16920, 883, 1, 12]) torch.Size([16920, 883, 12]) torch.Size([16920, 883, 12])
val: torch.Size([5640, 883, 1, 12]) torch.Size([5640, 883, 12]) torch.Size([5640, 883, 12])
test: torch.Size([5641, 883, 1, 12]) torch.Size([5641, 883, 12]) torch.Size([5641, 883, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(883, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(883, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.coefficient 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([883, 64])
src_embed.2.gcn_smooth_layers.0.coefficient 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([883, 64])
trg_embed.2.gcn_smooth_layers.0.coefficient 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 447049
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129]}]
validation batch 1 / 1410, loss: 0.67
validation batch 101 / 1410, loss: 0.51
validation batch 201 / 1410, loss: 0.76
validation batch 301 / 1410, loss: 0.46
validation batch 401 / 1410, loss: 0.57
validation batch 501 / 1410, loss: 0.74
validation batch 601 / 1410, loss: 0.35
validation batch 701 / 1410, loss: 0.76
validation batch 801 / 1410, loss: 0.56
validation batch 901 / 1410, loss: 0.76
validation batch 1001 / 1410, loss: 0.77
validation batch 1101 / 1410, loss: 0.35
validation batch 1201 / 1410, loss: 0.75
validation batch 1301 / 1410, loss: 0.64
validation batch 1401 / 1410, loss: 0.72
validation cost time: 402.5434s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:776.59s
epoch: 0, total time:1179.15s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.06
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.07
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.3489s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:776.32s
epoch: 1, total time:2357.83s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.06
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.2443s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_2.params
epoch: 2, train time every whole data:776.68s
epoch: 2, total time:3536.77s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.07
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.08
validation cost time: 402.3170s
epoch: 3, train time every whole data:776.43s
epoch: 3, total time:4715.52s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.07
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.8148s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_4.params
epoch: 4, train time every whole data:776.42s
epoch: 4, total time:5894.76s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.09
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.06
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.05
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.2367s
epoch: 5, train time every whole data:777.10s
epoch: 5, total time:7074.10s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.08
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.2360s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:776.95s
epoch: 6, total time:8253.29s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.4584s
epoch: 7, train time every whole data:776.88s
epoch: 7, total time:9432.64s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.09
validation cost time: 402.1336s
epoch: 8, train time every whole data:777.02s
epoch: 8, total time:10611.80s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.4171s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:776.79s
epoch: 9, total time:11791.01s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.07
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.07
validation cost time: 402.3006s
epoch: 10, train time every whole data:777.16s
epoch: 10, total time:12970.47s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.2854s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_11.params
epoch: 11, train time every whole data:776.78s
epoch: 11, total time:14149.55s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.9786s
epoch: 12, train time every whole data:776.13s
epoch: 12, total time:15328.65s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.3806s
epoch: 13, train time every whole data:776.45s
epoch: 13, total time:16507.49s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.06
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.05
validation batch 701 / 1410, loss: 0.05
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.06
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.05
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.07
validation cost time: 403.8736s
epoch: 14, train time every whole data:775.74s
epoch: 14, total time:17687.11s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 402.6247s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_15.params
epoch: 15, train time every whole data:776.13s
epoch: 15, total time:18865.87s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.09
validation batch 201 / 1410, loss: 0.07
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.08
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.07
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.07
validation batch 1001 / 1410, loss: 0.08
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.07
validation batch 1301 / 1410, loss: 0.07
validation batch 1401 / 1410, loss: 0.07
validation cost time: 404.4643s
epoch: 16, train time every whole data:776.62s
epoch: 16, total time:20046.96s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 404.0655s
epoch: 17, train time every whole data:775.88s
epoch: 17, total time:21226.91s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 404.5218s
epoch: 18, train time every whole data:776.47s
epoch: 18, total time:22407.90s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.07
validation batch 201 / 1410, loss: 0.06
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.08
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.06
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.07
validation batch 1001 / 1410, loss: 0.07
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.06
validation batch 1301 / 1410, loss: 0.07
validation batch 1401 / 1410, loss: 0.07
validation cost time: 402.8181s
epoch: 19, train time every whole data:776.28s
epoch: 19, total time:23587.00s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.9567s
epoch: 20, train time every whole data:775.98s
epoch: 20, total time:24765.94s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.05
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.04
validation batch 701 / 1410, loss: 0.05
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.04
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.06
validation cost time: 402.7892s
epoch: 21, train time every whole data:776.76s
epoch: 21, total time:25945.49s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 402.7496s
epoch: 22, train time every whole data:776.12s
epoch: 22, total time:27124.36s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.05
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.04
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 403.4803s
epoch: 23, train time every whole data:776.22s
epoch: 23, total time:28304.07s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 404.0749s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_24.params
epoch: 24, train time every whole data:777.25s
epoch: 24, total time:29485.40s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 403.8190s
epoch: 25, train time every whole data:776.57s
epoch: 25, total time:30665.79s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 403.1790s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_26.params
epoch: 26, train time every whole data:777.19s
epoch: 26, total time:31846.17s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.05
validation cost time: 402.9510s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_27.params
epoch: 27, train time every whole data:777.52s
epoch: 27, total time:33026.66s
validation batch 1 / 1410, loss: 0.06
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.05
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.06
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.05
validation batch 801 / 1410, loss: 0.06
validation batch 901 / 1410, loss: 0.06
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.05
validation batch 1401 / 1410, loss: 0.07
validation cost time: 403.1326s
epoch: 28, train time every whole data:776.92s
epoch: 28, total time:34206.72s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 403.1823s
epoch: 29, train time every whole data:777.41s
epoch: 29, total time:35387.31s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 404.7438s
epoch: 30, train time every whole data:777.34s
epoch: 30, total time:36569.39s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.9351s
epoch: 31, train time every whole data:777.17s
epoch: 31, total time:37750.49s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.07
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 404.7194s
epoch: 32, train time every whole data:777.87s
epoch: 32, total time:38933.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5298s
epoch: 33, train time every whole data:777.28s
epoch: 33, total time:40114.89s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.03
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.6592s
epoch: 34, train time every whole data:777.20s
epoch: 34, total time:41295.75s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4172s
epoch: 35, train time every whole data:777.17s
epoch: 35, total time:42477.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.6303s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_36.params
epoch: 36, train time every whole data:775.06s
epoch: 36, total time:43657.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.6438s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_37.params
epoch: 37, train time every whole data:774.95s
epoch: 37, total time:44836.65s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.07
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.05
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.05
validation cost time: 403.6553s
epoch: 38, train time every whole data:774.24s
epoch: 38, total time:46014.55s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.2035s
epoch: 39, train time every whole data:774.21s
epoch: 39, total time:47191.96s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.2368s
epoch: 40, train time every whole data:774.24s
epoch: 40, total time:48369.43s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.2511s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_41.params
epoch: 41, train time every whole data:774.12s
epoch: 41, total time:49546.82s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0449s
epoch: 42, train time every whole data:774.21s
epoch: 42, total time:50724.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9321s
epoch: 43, train time every whole data:774.24s
epoch: 43, total time:51901.25s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.1198s
epoch: 44, train time every whole data:774.25s
epoch: 44, total time:53078.62s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0854s
epoch: 45, train time every whole data:774.18s
epoch: 45, total time:54255.89s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.06
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.04
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.05
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.05
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.04
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.06
validation cost time: 403.1606s
epoch: 46, train time every whole data:774.23s
epoch: 46, total time:55433.28s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0730s
epoch: 47, train time every whole data:774.25s
epoch: 47, total time:56610.61s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0961s
epoch: 48, train time every whole data:774.23s
epoch: 48, total time:57787.94s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0797s
epoch: 49, train time every whole data:774.25s
epoch: 49, total time:58965.27s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.06
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9311s
epoch: 50, train time every whole data:774.25s
epoch: 50, total time:60142.46s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9098s
epoch: 51, train time every whole data:774.25s
epoch: 51, total time:61319.62s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8628s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_52.params
epoch: 52, train time every whole data:774.17s
epoch: 52, total time:62496.66s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0636s
epoch: 53, train time every whole data:774.44s
epoch: 53, total time:63674.17s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9119s
epoch: 54, train time every whole data:774.51s
epoch: 54, total time:64851.59s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8424s
epoch: 55, train time every whole data:774.45s
epoch: 55, total time:66028.88s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8449s
epoch: 56, train time every whole data:774.49s
epoch: 56, total time:67206.22s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.7711s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_57.params
epoch: 57, train time every whole data:774.44s
epoch: 57, total time:68383.44s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9934s
epoch: 58, train time every whole data:774.52s
epoch: 58, total time:69560.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9748s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_59.params
epoch: 59, train time every whole data:774.43s
epoch: 59, total time:70738.37s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8029s
epoch: 60, train time every whole data:774.47s
epoch: 60, total time:71915.65s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9690s
epoch: 61, train time every whole data:774.94s
epoch: 61, total time:73093.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.05
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9604s
epoch: 62, train time every whole data:775.06s
epoch: 62, total time:74271.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5542s
epoch: 63, train time every whole data:775.02s
epoch: 63, total time:75451.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.8300s
epoch: 64, train time every whole data:774.88s
epoch: 64, total time:76629.87s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4918s
epoch: 65, train time every whole data:774.84s
epoch: 65, total time:77809.21s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5431s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_66.params
epoch: 66, train time every whole data:774.88s
epoch: 66, total time:78988.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8930s
epoch: 67, train time every whole data:774.77s
epoch: 67, total time:80166.31s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.2985s
epoch: 68, train time every whole data:774.96s
epoch: 68, total time:81345.57s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8748s
epoch: 69, train time every whole data:774.95s
epoch: 69, total time:82523.39s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8703s
epoch: 70, train time every whole data:775.07s
epoch: 70, total time:83701.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8918s
epoch: 71, train time every whole data:774.93s
epoch: 71, total time:84879.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8301s
epoch: 72, train time every whole data:774.92s
epoch: 72, total time:86056.92s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8599s
epoch: 73, train time every whole data:774.83s
epoch: 73, total time:87234.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8347s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_74.params
epoch: 74, train time every whole data:774.77s
epoch: 74, total time:88412.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8967s
epoch: 75, train time every whole data:774.86s
epoch: 75, total time:89589.98s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8696s
epoch: 76, train time every whole data:774.75s
epoch: 76, total time:90767.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4509s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_77.params
epoch: 77, train time every whole data:774.93s
epoch: 77, total time:91947.00s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5563s
epoch: 78, train time every whole data:774.77s
epoch: 78, total time:93126.32s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8869s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_79.params
epoch: 79, train time every whole data:774.91s
epoch: 79, total time:94304.14s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.0206s
epoch: 80, train time every whole data:774.58s
epoch: 80, total time:95482.74s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.8578s
epoch: 81, train time every whole data:774.60s
epoch: 81, total time:96661.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.9339s
epoch: 82, train time every whole data:774.81s
epoch: 82, total time:97839.94s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8415s
epoch: 83, train time every whole data:774.99s
epoch: 83, total time:99017.77s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4683s
epoch: 84, train time every whole data:775.05s
epoch: 84, total time:100197.29s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4747s
epoch: 85, train time every whole data:774.75s
epoch: 85, total time:101376.51s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.3289s
epoch: 86, train time every whole data:774.76s
epoch: 86, total time:102555.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.0332s
epoch: 87, train time every whole data:774.62s
epoch: 87, total time:103734.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8542s
epoch: 88, train time every whole data:774.79s
epoch: 88, total time:104911.91s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.3505s
epoch: 89, train time every whole data:774.78s
epoch: 89, total time:106091.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.3956s
epoch: 90, train time every whole data:774.80s
epoch: 90, total time:107270.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.1752s
epoch: 91, train time every whole data:774.72s
epoch: 91, total time:108449.13s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9315s
epoch: 92, train time every whole data:774.78s
epoch: 92, total time:109626.84s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.9183s
epoch: 93, train time every whole data:774.82s
epoch: 93, total time:110805.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8971s
epoch: 94, train time every whole data:774.75s
epoch: 94, total time:111983.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9158s
epoch: 95, train time every whole data:775.02s
epoch: 95, total time:113161.17s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8561s
epoch: 96, train time every whole data:775.05s
epoch: 96, total time:114339.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8607s
epoch: 97, train time every whole data:775.02s
epoch: 97, total time:115516.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8983s
epoch: 98, train time every whole data:774.84s
epoch: 98, total time:116694.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.0875s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_99.params
epoch: 99, train time every whole data:774.96s
epoch: 99, total time:117873.76s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.04
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.04
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8806s
epoch: 100, train time every whole data:774.86s
epoch: 100, total time:119051.50s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4251s
epoch: 101, train time every whole data:775.18s
epoch: 101, total time:120231.11s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4476s
epoch: 102, train time every whole data:775.04s
epoch: 102, total time:121410.60s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5508s
epoch: 103, train time every whole data:775.00s
epoch: 103, total time:122590.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5759s
epoch: 104, train time every whole data:775.05s
epoch: 104, total time:123769.78s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.0174s
epoch: 105, train time every whole data:774.95s
epoch: 105, total time:124947.75s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4691s
epoch: 106, train time every whole data:775.05s
epoch: 106, total time:126127.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3253s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_107.params
epoch: 107, train time every whole data:774.93s
epoch: 107, total time:127306.54s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8568s
epoch: 108, train time every whole data:775.08s
epoch: 108, total time:128484.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8019s
epoch: 109, train time every whole data:774.99s
epoch: 109, total time:129662.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8323s
epoch: 110, train time every whole data:775.12s
epoch: 110, total time:130840.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.04
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4391s
epoch: 111, train time every whole data:774.99s
epoch: 111, total time:132019.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3787s
epoch: 112, train time every whole data:774.92s
epoch: 112, total time:133198.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9103s
epoch: 113, train time every whole data:774.79s
epoch: 113, total time:134376.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8920s
epoch: 114, train time every whole data:774.69s
epoch: 114, total time:135554.25s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.0290s
epoch: 115, train time every whole data:774.82s
epoch: 115, total time:136733.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4642s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_116.params
epoch: 116, train time every whole data:774.84s
epoch: 116, total time:137912.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.2926s
epoch: 117, train time every whole data:774.87s
epoch: 117, total time:139091.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.1022s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_118.params
epoch: 118, train time every whole data:774.87s
epoch: 118, total time:140270.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.1464s
epoch: 119, train time every whole data:775.05s
epoch: 119, total time:141449.76s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9200s
epoch: 120, train time every whole data:775.02s
epoch: 120, total time:142627.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3190s
epoch: 121, train time every whole data:775.14s
epoch: 121, total time:143807.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8830s
epoch: 122, train time every whole data:775.20s
epoch: 122, total time:144985.25s
validation batch 1 / 1410, loss: 0.05
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.04
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.04
validation batch 1301 / 1410, loss: 0.04
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.9151s
epoch: 123, train time every whole data:775.18s
epoch: 123, total time:146163.34s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8494s
epoch: 124, train time every whole data:775.21s
epoch: 124, total time:147341.40s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5002s
epoch: 125, train time every whole data:775.30s
epoch: 125, total time:148521.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.1978s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_126.params
epoch: 126, train time every whole data:775.11s
epoch: 126, total time:149700.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 403.5185s
epoch: 127, train time every whole data:775.22s
epoch: 127, total time:150879.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7973s
epoch: 128, train time every whole data:775.42s
epoch: 128, total time:152057.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8417s
epoch: 129, train time every whole data:775.32s
epoch: 129, total time:153235.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4823s
epoch: 130, train time every whole data:775.32s
epoch: 130, total time:154415.44s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.3466s
epoch: 131, train time every whole data:775.25s
epoch: 131, total time:155595.04s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5496s
epoch: 132, train time every whole data:775.27s
epoch: 132, total time:156774.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5646s
epoch: 133, train time every whole data:775.31s
epoch: 133, total time:157954.74s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8085s
epoch: 134, train time every whole data:775.22s
epoch: 134, total time:159132.77s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5427s
epoch: 135, train time every whole data:775.36s
epoch: 135, total time:160312.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1107s
epoch: 136, train time every whole data:775.19s
epoch: 136, total time:161490.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4411s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_137.params
epoch: 137, train time every whole data:775.06s
epoch: 137, total time:162670.50s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8038s
epoch: 138, train time every whole data:775.12s
epoch: 138, total time:163848.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.4859s
epoch: 139, train time every whole data:775.05s
epoch: 139, total time:165027.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7950s
epoch: 140, train time every whole data:775.00s
epoch: 140, total time:166205.76s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4568s
epoch: 141, train time every whole data:775.01s
epoch: 141, total time:167385.23s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 402.8129s
epoch: 142, train time every whole data:775.04s
epoch: 142, total time:168563.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8620s
epoch: 143, train time every whole data:775.11s
epoch: 143, total time:169741.05s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 404.5529s
epoch: 144, train time every whole data:775.08s
epoch: 144, total time:170920.69s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4823s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_145.params
epoch: 145, train time every whole data:774.95s
epoch: 145, total time:172100.14s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7448s
epoch: 146, train time every whole data:775.04s
epoch: 146, total time:173277.92s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.0650s
epoch: 147, train time every whole data:775.01s
epoch: 147, total time:174456.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5045s
epoch: 148, train time every whole data:774.97s
epoch: 148, total time:175636.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4915s
epoch: 149, train time every whole data:774.96s
epoch: 149, total time:176815.92s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7776s
epoch: 150, train time every whole data:774.76s
epoch: 150, total time:177993.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.8752s
epoch: 151, train time every whole data:774.84s
epoch: 151, total time:179172.18s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7109s
epoch: 152, train time every whole data:774.90s
epoch: 152, total time:180349.79s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7250s
epoch: 153, train time every whole data:774.74s
epoch: 153, total time:181527.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7808s
epoch: 154, train time every whole data:774.83s
epoch: 154, total time:182704.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9523s
epoch: 155, train time every whole data:775.03s
epoch: 155, total time:183882.86s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3693s
epoch: 156, train time every whole data:774.94s
epoch: 156, total time:185062.16s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.03
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.2988s
epoch: 157, train time every whole data:775.00s
epoch: 157, total time:186241.46s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3105s
epoch: 158, train time every whole data:774.94s
epoch: 158, total time:187420.72s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4250s
epoch: 159, train time every whole data:774.94s
epoch: 159, total time:188600.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8019s
epoch: 160, train time every whole data:775.01s
epoch: 160, total time:189777.90s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3926s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_161.params
epoch: 161, train time every whole data:774.78s
epoch: 161, total time:190957.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.8004s
epoch: 162, train time every whole data:774.91s
epoch: 162, total time:192134.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.05
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.3571s
epoch: 163, train time every whole data:774.90s
epoch: 163, total time:193313.06s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.9383s
epoch: 164, train time every whole data:774.64s
epoch: 164, total time:194491.63s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7629s
epoch: 165, train time every whole data:774.70s
epoch: 165, total time:195669.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.7545s
epoch: 166, train time every whole data:774.78s
epoch: 166, total time:196846.63s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.9352s
epoch: 167, train time every whole data:774.79s
epoch: 167, total time:198025.36s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0254s
epoch: 168, train time every whole data:779.98s
epoch: 168, total time:199208.36s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 405.6640s
epoch: 169, train time every whole data:780.98s
epoch: 169, total time:200395.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.04
validation cost time: 610.4176s
epoch: 170, train time every whole data:1524.99s
epoch: 170, total time:202530.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.2023s
epoch: 171, train time every whole data:1524.63s
epoch: 171, total time:204915.26s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 859.9078s
epoch: 172, train time every whole data:1525.20s
epoch: 172, total time:207300.37s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 859.9107s
epoch: 173, train time every whole data:1525.65s
epoch: 173, total time:209685.93s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.5679s
epoch: 174, train time every whole data:1526.34s
epoch: 174, total time:212072.84s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.7203s
epoch: 175, train time every whole data:1525.75s
epoch: 175, total time:214459.31s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.2857s
epoch: 176, train time every whole data:1526.13s
epoch: 176, total time:216845.73s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.4077s
epoch: 177, train time every whole data:1524.82s
epoch: 177, total time:219230.96s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.5610s
epoch: 178, train time every whole data:1525.68s
epoch: 178, total time:221617.21s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 866.8271s
epoch: 179, train time every whole data:1525.60s
epoch: 179, total time:224009.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 867.8892s
epoch: 180, train time every whole data:1525.77s
epoch: 180, total time:226403.30s
validation batch 1 / 1410, loss: 0.04
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 867.8730s
epoch: 181, train time every whole data:1525.99s
epoch: 181, total time:228797.17s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 868.2860s
epoch: 182, train time every whole data:1525.74s
epoch: 182, total time:231191.19s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.0048s
epoch: 183, train time every whole data:1517.22s
epoch: 183, total time:233577.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.0724s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_184.params
epoch: 184, train time every whole data:1526.90s
epoch: 184, total time:235975.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.7542s
epoch: 185, train time every whole data:1526.84s
epoch: 185, total time:238373.00s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.8742s
epoch: 186, train time every whole data:1527.22s
epoch: 186, total time:240772.10s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.5140s
epoch: 187, train time every whole data:1526.95s
epoch: 187, total time:243170.57s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.02
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.8457s
epoch: 188, train time every whole data:1527.19s
epoch: 188, total time:245569.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.9606s
epoch: 189, train time every whole data:1527.06s
epoch: 189, total time:247968.63s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.7722s
epoch: 190, train time every whole data:1526.45s
epoch: 190, total time:250364.86s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.6860s
epoch: 191, train time every whole data:1526.51s
epoch: 191, total time:252761.06s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.3688s
epoch: 192, train time every whole data:1527.18s
epoch: 192, total time:255157.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.03
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.3273s
epoch: 193, train time every whole data:1527.15s
epoch: 193, total time:257555.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.03
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.6211s
epoch: 194, train time every whole data:1526.75s
epoch: 194, total time:259952.47s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.02
validation batch 701 / 1410, loss: 0.04
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.4157s
epoch: 195, train time every whole data:1526.71s
epoch: 195, total time:262349.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.4433s
epoch: 196, train time every whole data:1520.23s
epoch: 196, total time:264739.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.04
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.6286s
epoch: 197, train time every whole data:1526.79s
epoch: 197, total time:267135.69s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.04
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.2698s
epoch: 198, train time every whole data:1526.58s
epoch: 198, total time:269532.54s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.04
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.03
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.3340s
epoch: 199, train time every whole data:1526.40s
epoch: 199, total time:271929.28s
best epoch: 184
apply the best val model on the test data set ...
load weight from: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_184.params
predicting testing set batch 1 / 1411, time: 0.62s
predicting testing set batch 101 / 1411, time: 62.39s
predicting testing set batch 201 / 1411, time: 124.08s
predicting testing set batch 301 / 1411, time: 185.69s
predicting testing set batch 401 / 1411, time: 247.33s
predicting testing set batch 501 / 1411, time: 309.01s
predicting testing set batch 601 / 1411, time: 370.69s
predicting testing set batch 701 / 1411, time: 432.35s
predicting testing set batch 801 / 1411, time: 494.09s
predicting testing set batch 901 / 1411, time: 555.81s
predicting testing set batch 1001 / 1411, time: 617.44s
predicting testing set batch 1101 / 1411, time: 679.09s
predicting testing set batch 1201 / 1411, time: 740.78s
predicting testing set batch 1301 / 1411, time: 802.47s
predicting testing set batch 1401 / 1411, time: 864.23s
test time on whole data:870.05s
input: (5641, 883, 12, 1)
prediction: (5641, 883, 12, 1)
data_target_tensor: (5641, 883, 12)
current epoch: 184, predict 0 points
MAE: 16.45
RMSE: 26.64
MAPE: 6.90
current epoch: 184, predict 1 points
MAE: 17.85
RMSE: 29.26
MAPE: 7.52
current epoch: 184, predict 2 points
MAE: 18.81
RMSE: 30.88
MAPE: 7.88
current epoch: 184, predict 3 points
MAE: 19.51
RMSE: 32.05
MAPE: 8.17
current epoch: 184, predict 4 points
MAE: 20.12
RMSE: 33.02
MAPE: 8.43
current epoch: 184, predict 5 points
MAE: 20.71
RMSE: 33.89
MAPE: 8.70
current epoch: 184, predict 6 points
MAE: 21.28
RMSE: 34.73
MAPE: 8.96
current epoch: 184, predict 7 points
MAE: 21.83
RMSE: 35.51
MAPE: 9.23
current epoch: 184, predict 8 points
MAE: 22.36
RMSE: 36.25
MAPE: 9.50
current epoch: 184, predict 9 points
MAE: 22.88
RMSE: 36.97
MAPE: 9.77
current epoch: 184, predict 10 points
MAE: 23.39
RMSE: 37.69
MAPE: 10.05
current epoch: 184, predict 11 points
MAE: 23.98
RMSE: 38.45
MAPE: 10.37
all MAE: 20.76
all RMSE: 33.95
all MAPE: 8.79
[16.454739, 26.635996665403287, 6.901650130748749, 17.85396, 29.25616755222307, 7.515472173690796, 18.814367, 30.88231149195179, 7.87554457783699, 19.508213, 32.04757777447365, 8.167186379432678, 20.117844, 33.02219084026111, 8.428765833377838, 20.707766, 33.89178839058954, 8.699926733970642, 21.280985, 34.726366527849734, 8.964447677135468, 21.829681, 35.51462307484675, 9.22643318772316, 22.357779, 36.25334373048402, 9.495275467634201, 22.876196, 36.96676215069762, 9.771213680505753, 23.39497, 37.69225133295801, 10.054009407758713, 23.982023, 38.45474555961445, 10.369367152452469, 20.764883, 33.95192775730857, 8.789082616567612]
fine tune the model ... 
epoch: 200, train time every whole data:3681.21s
epoch: 200, total time:276487.08s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.0159s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_200.params
epoch: 201, train time every whole data:3671.57s
epoch: 201, total time:281027.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.4546s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_201.params
epoch: 202, train time every whole data:3667.77s
epoch: 202, total time:285564.92s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.6038s
epoch: 203, train time every whole data:3669.24s
epoch: 203, total time:290103.76s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.3337s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_203.params
epoch: 204, train time every whole data:3668.22s
epoch: 204, total time:294641.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 861.3870s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_204.params
epoch: 205, train time every whole data:3667.39s
epoch: 205, total time:299170.12s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.2049s
epoch: 206, train time every whole data:3669.54s
epoch: 206, total time:303709.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.2133s
epoch: 207, train time every whole data:3666.33s
epoch: 207, total time:308245.41s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.6714s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_207.params
epoch: 208, train time every whole data:3669.30s
epoch: 208, total time:312784.40s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.2439s
epoch: 209, train time every whole data:3668.84s
epoch: 209, total time:317323.49s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 869.3883s
epoch: 210, train time every whole data:3668.83s
epoch: 210, total time:321861.71s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.6717s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_210.params
epoch: 211, train time every whole data:3659.65s
epoch: 211, total time:326392.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.1027s
epoch: 212, train time every whole data:3666.60s
epoch: 212, total time:330928.74s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.0625s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_212.params
epoch: 213, train time every whole data:3664.89s
epoch: 213, total time:335464.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.7272s
epoch: 214, train time every whole data:3664.47s
epoch: 214, total time:339999.90s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 871.1444s
epoch: 215, train time every whole data:3667.47s
epoch: 215, total time:344538.52s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 870.4584s
epoch: 216, train time every whole data:3651.34s
epoch: 216, total time:349060.32s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 865.0807s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_216.params
epoch: 217, train time every whole data:3644.42s
epoch: 217, total time:353569.83s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 863.9862s
epoch: 218, train time every whole data:3619.71s
epoch: 218, total time:358053.53s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 860.8867s
epoch: 219, train time every whole data:3635.64s
epoch: 219, total time:362550.07s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 862.6202s
epoch: 220, train time every whole data:3635.99s
epoch: 220, total time:367048.68s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 859.9650s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_220.params
epoch: 221, train time every whole data:3634.93s
epoch: 221, total time:371543.59s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 673.8414s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_221.params
epoch: 222, train time every whole data:1887.22s
epoch: 222, total time:374104.66s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.0638s
epoch: 223, train time every whole data:2024.22s
epoch: 223, total time:376589.94s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.3808s
epoch: 224, train time every whole data:2026.20s
epoch: 224, total time:379077.53s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.0785s
epoch: 225, train time every whole data:2027.81s
epoch: 225, total time:381566.42s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.1292s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_225.params
epoch: 226, train time every whole data:2023.82s
epoch: 226, total time:384051.38s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.3269s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_226.params
epoch: 227, train time every whole data:2026.43s
epoch: 227, total time:386539.15s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.3529s
epoch: 228, train time every whole data:2026.55s
epoch: 228, total time:389027.05s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.2285s
epoch: 229, train time every whole data:2024.92s
epoch: 229, total time:391513.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.6944s
epoch: 230, train time every whole data:2025.80s
epoch: 230, total time:394000.70s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.4701s
epoch: 231, train time every whole data:2025.82s
epoch: 231, total time:396487.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 460.9743s
epoch: 232, train time every whole data:2023.83s
epoch: 232, total time:398972.80s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.1209s
epoch: 233, train time every whole data:2026.32s
epoch: 233, total time:401460.25s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 460.9800s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_233.params
epoch: 234, train time every whole data:2026.78s
epoch: 234, total time:403948.02s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 460.9348s
epoch: 235, train time every whole data:2023.07s
epoch: 235, total time:406432.03s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.5096s
epoch: 236, train time every whole data:2024.74s
epoch: 236, total time:408918.28s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 461.2981s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_236.params
epoch: 237, train time every whole data:2026.41s
epoch: 237, total time:411405.99s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 460.3205s
epoch: 238, train time every whole data:2017.89s
epoch: 238, total time:413884.20s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 460.6286s
epoch: 239, train time every whole data:2021.92s
epoch: 239, total time:416366.75s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 459.7590s
epoch: 240, train time every whole data:2010.61s
epoch: 240, total time:418837.12s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9970s
epoch: 241, train time every whole data:1767.83s
epoch: 241, total time:421007.95s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.0964s
epoch: 242, train time every whole data:1766.83s
epoch: 242, total time:423178.88s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.6527s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_242.params
epoch: 243, train time every whole data:1767.57s
epoch: 243, total time:425350.12s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3201s
epoch: 244, train time every whole data:1767.43s
epoch: 244, total time:427521.87s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9767s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_244.params
epoch: 245, train time every whole data:1767.18s
epoch: 245, total time:429692.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0889s
epoch: 246, train time every whole data:1767.43s
epoch: 246, total time:431862.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0174s
epoch: 247, train time every whole data:1767.33s
epoch: 247, total time:434032.91s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9666s
epoch: 248, train time every whole data:1766.43s
epoch: 248, total time:436202.31s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9539s
epoch: 249, train time every whole data:1767.71s
epoch: 249, total time:438372.97s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.1941s
epoch: 250, train time every whole data:1767.97s
epoch: 250, total time:440545.13s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.3201s
epoch: 251, train time every whole data:1769.69s
epoch: 251, total time:442718.14s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.2005s
epoch: 252, train time every whole data:1769.63s
epoch: 252, total time:444890.97s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1468s
epoch: 253, train time every whole data:1769.92s
epoch: 253, total time:447064.04s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.4174s
epoch: 254, train time every whole data:1769.82s
epoch: 254, total time:449238.27s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1080s
epoch: 255, train time every whole data:1769.71s
epoch: 255, total time:451411.09s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.5739s
epoch: 256, train time every whole data:1769.34s
epoch: 256, total time:453585.01s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 402.9938s
epoch: 257, train time every whole data:1767.91s
epoch: 257, total time:455755.91s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3353s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_257.params
epoch: 258, train time every whole data:1768.71s
epoch: 258, total time:457928.97s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0491s
epoch: 259, train time every whole data:1769.59s
epoch: 259, total time:460101.61s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1533s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_259.params
epoch: 260, train time every whole data:1768.07s
epoch: 260, total time:462272.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.2643s
epoch: 261, train time every whole data:1767.64s
epoch: 261, total time:464443.75s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0082s
epoch: 262, train time every whole data:1767.73s
epoch: 262, total time:466614.49s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3802s
epoch: 263, train time every whole data:1768.03s
epoch: 263, total time:468786.91s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3704s
epoch: 264, train time every whole data:1768.05s
epoch: 264, total time:470959.33s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.0726s
epoch: 265, train time every whole data:1767.95s
epoch: 265, total time:473130.35s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3492s
epoch: 266, train time every whole data:1767.85s
epoch: 266, total time:475302.55s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.4077s
epoch: 267, train time every whole data:1769.27s
epoch: 267, total time:477475.24s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.2026s
epoch: 268, train time every whole data:1769.20s
epoch: 268, total time:479647.64s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.2222s
epoch: 269, train time every whole data:1769.37s
epoch: 269, total time:481820.24s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1543s
epoch: 270, train time every whole data:1769.39s
epoch: 270, total time:483992.78s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.3735s
epoch: 271, train time every whole data:1769.21s
epoch: 271, total time:486166.36s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 404.2426s
epoch: 272, train time every whole data:1769.58s
epoch: 272, total time:488340.18s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.2004s
epoch: 273, train time every whole data:1768.17s
epoch: 273, total time:490511.56s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.5277s
epoch: 274, train time every whole data:1768.76s
epoch: 274, total time:492683.85s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1764s
epoch: 275, train time every whole data:1768.46s
epoch: 275, total time:494855.48s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.8847s
epoch: 276, train time every whole data:1768.25s
epoch: 276, total time:497027.62s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.5979s
epoch: 277, train time every whole data:1767.89s
epoch: 277, total time:499199.11s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.9369s
epoch: 278, train time every whole data:1768.53s
epoch: 278, total time:501371.58s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1756s
save parameters to file: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_278.params
epoch: 279, train time every whole data:1768.25s
epoch: 279, total time:503543.02s
validation batch 1 / 1410, loss: 0.03
validation batch 101 / 1410, loss: 0.02
validation batch 201 / 1410, loss: 0.03
validation batch 301 / 1410, loss: 0.02
validation batch 401 / 1410, loss: 0.03
validation batch 501 / 1410, loss: 0.03
validation batch 601 / 1410, loss: 0.01
validation batch 701 / 1410, loss: 0.03
validation batch 801 / 1410, loss: 0.02
validation batch 901 / 1410, loss: 0.03
validation batch 1001 / 1410, loss: 0.03
validation batch 1101 / 1410, loss: 0.01
validation batch 1201 / 1410, loss: 0.03
validation batch 1301 / 1410, loss: 0.03
validation batch 1401 / 1410, loss: 0.03
validation cost time: 403.1797s
best epoch: 278
apply the best val model on the test data set ...
load weight from: ../experiments/PEMS07/MAE_ASTGNN_h1d0w0_layer3_head8_dm64_channel1_dir2_drop0.00_1.00e-03TcontextScaledSAtSE1TE/epoch_278.params
predicting testing set batch 1 / 1411, time: 0.29s
predicting testing set batch 101 / 1411, time: 28.91s
predicting testing set batch 201 / 1411, time: 57.55s
predicting testing set batch 301 / 1411, time: 86.18s
predicting testing set batch 401 / 1411, time: 114.82s
predicting testing set batch 501 / 1411, time: 143.46s
predicting testing set batch 601 / 1411, time: 172.10s
predicting testing set batch 701 / 1411, time: 200.75s
predicting testing set batch 801 / 1411, time: 229.40s
predicting testing set batch 901 / 1411, time: 258.05s
predicting testing set batch 1001 / 1411, time: 286.71s
predicting testing set batch 1101 / 1411, time: 315.38s
predicting testing set batch 1201 / 1411, time: 344.03s
predicting testing set batch 1301 / 1411, time: 372.69s
predicting testing set batch 1401 / 1411, time: 401.36s
test time on whole data:404.06s
input: (5641, 883, 12, 1)
prediction: (5641, 883, 12, 1)
data_target_tensor: (5641, 883, 12)
current epoch: 278, predict 0 points
MAE: 16.31
RMSE: 26.51
MAPE: 6.84
current epoch: 278, predict 1 points
MAE: 17.44
RMSE: 28.86
MAPE: 7.35
current epoch: 278, predict 2 points
MAE: 18.20
RMSE: 30.32
MAPE: 7.67
current epoch: 278, predict 3 points
MAE: 18.75
RMSE: 31.35
MAPE: 7.91
current epoch: 278, predict 4 points
MAE: 19.22
RMSE: 32.21
MAPE: 8.10
current epoch: 278, predict 5 points
MAE: 19.62
RMSE: 32.93
MAPE: 8.27
current epoch: 278, predict 6 points
MAE: 20.01
RMSE: 33.61
MAPE: 8.43
current epoch: 278, predict 7 points
MAE: 20.36
RMSE: 34.22
MAPE: 8.59
current epoch: 278, predict 8 points
MAE: 20.71
RMSE: 34.81
MAPE: 8.76
current epoch: 278, predict 9 points
MAE: 21.06
RMSE: 35.38
MAPE: 8.93
current epoch: 278, predict 10 points
MAE: 21.41
RMSE: 35.97
MAPE: 9.10
current epoch: 278, predict 11 points
MAE: 21.82
RMSE: 36.58
MAPE: 9.29
all MAE: 19.58
all RMSE: 32.86
all MAPE: 8.27
[16.312544, 26.505235838518185, 6.844793260097504, 17.441397, 28.85952092884058, 7.3524631559848785, 18.198229, 30.32129483399672, 7.674466818571091, 18.754229, 31.35238403795286, 7.910890877246857, 19.215397, 32.2102619759992, 8.101709932088852, 19.617102, 32.929629114716924, 8.268684893846512, 20.006372, 33.60565741003942, 8.431649953126907, 20.359568, 34.21523597824331, 8.593262732028961, 20.711464, 34.80951057350832, 8.762727677822113, 21.055288, 35.37909407901172, 8.926896750926971, 21.407232, 35.967221066005884, 9.095834195613861, 21.823973, 36.57745587544755, 9.289351105690002, 19.575226, 32.85648465652366, 8.271043002605438]
