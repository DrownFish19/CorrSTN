Sun Oct 31 20:56:15 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   27C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   55C    P0   108W / 250W |   3654MiB / 32480MiB |     61%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   58C    P0    79W / 250W |   6563MiB / 32480MiB |     99%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   53C    P0    58W / 250W |  19884MiB / 32480MiB |     88%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   44C    P0    61W / 250W |   2808MiB / 32480MiB |     47%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   30C    P0    26W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   29C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   45C    P0    26W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     19680      C   python                                      3643MiB |
|    2     23887      C   python                                      3643MiB |
|    2     25317      C   python                                      2909MiB |
|    3      4214      C   python                                      2797MiB |
|    3     53949      C   python                                     17075MiB |
|    4     23888      C   python                                      2797MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/HZME_INFLOW.conf
total training epoch, fine tune epoch: 300 , 100
batch_size: 4
attention_top_k: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/HZME_INFLOW/HZME_INFLOW_r1_d0_w0.npz
ori length: 4479 , percent: 1.0 , scale: 4479
train: torch.Size([3323, 80, 1, 12]) torch.Size([3323, 80, 12]) torch.Size([3323, 80, 12])
val: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
test: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([80, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([80, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 452181
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 9, loss: 2.02
validation cost time: 7.0242s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:58.24s
epoch: 0, total time:65.28s
validation batch 1 / 9, loss: 0.05
validation cost time: 6.7164s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:58.00s
epoch: 1, total time:130.01s
validation batch 1 / 9, loss: 0.05
validation cost time: 6.7175s
epoch: 2, train time every whole data:58.01s
epoch: 2, total time:194.74s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7204s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:58.02s
epoch: 3, total time:259.49s
validation batch 1 / 9, loss: 0.04
validation cost time: 6.7210s
epoch: 4, train time every whole data:57.98s
epoch: 4, total time:324.20s
validation batch 1 / 9, loss: 0.06
validation cost time: 6.7245s
epoch: 5, train time every whole data:57.98s
epoch: 5, total time:388.91s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7232s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:57.99s
epoch: 6, total time:453.64s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7238s
epoch: 7, train time every whole data:58.00s
epoch: 7, total time:518.36s
validation batch 1 / 9, loss: 0.08
validation cost time: 6.7243s
epoch: 8, train time every whole data:58.02s
epoch: 8, total time:583.11s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7261s
epoch: 9, train time every whole data:58.04s
epoch: 9, total time:647.88s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7246s
epoch: 10, train time every whole data:58.05s
epoch: 10, total time:712.66s
validation batch 1 / 9, loss: 0.08
validation cost time: 6.7255s
epoch: 11, train time every whole data:58.06s
epoch: 11, total time:777.44s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7224s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_12.params
epoch: 12, train time every whole data:58.07s
epoch: 12, total time:842.25s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7255s
epoch: 13, train time every whole data:58.07s
epoch: 13, total time:907.04s
validation batch 1 / 9, loss: 0.04
validation cost time: 6.7240s
epoch: 14, train time every whole data:58.03s
epoch: 14, total time:971.80s
validation batch 1 / 9, loss: 0.04
validation cost time: 6.7239s
epoch: 15, train time every whole data:58.03s
epoch: 15, total time:1036.56s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7253s
epoch: 16, train time every whole data:58.02s
epoch: 16, total time:1101.30s
validation batch 1 / 9, loss: 0.05
validation cost time: 6.7246s
epoch: 17, train time every whole data:58.00s
epoch: 17, total time:1166.03s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7254s
epoch: 18, train time every whole data:57.99s
epoch: 18, total time:1230.75s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7250s
epoch: 19, train time every whole data:57.99s
epoch: 19, total time:1295.47s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7250s
epoch: 20, train time every whole data:58.01s
epoch: 20, total time:1360.20s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7249s
epoch: 21, train time every whole data:58.00s
epoch: 21, total time:1424.93s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7236s
epoch: 22, train time every whole data:58.01s
epoch: 22, total time:1489.66s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7244s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_23.params
epoch: 23, train time every whole data:58.01s
epoch: 23, total time:1554.41s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7244s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_24.params
epoch: 24, train time every whole data:58.02s
epoch: 24, total time:1619.16s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7249s
epoch: 25, train time every whole data:58.01s
epoch: 25, total time:1683.90s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7245s
epoch: 26, train time every whole data:57.98s
epoch: 26, total time:1748.60s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7247s
epoch: 27, train time every whole data:57.99s
epoch: 27, total time:1813.31s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7239s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_28.params
epoch: 28, train time every whole data:58.01s
epoch: 28, total time:1878.06s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7247s
epoch: 29, train time every whole data:57.98s
epoch: 29, total time:1942.77s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7250s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_30.params
epoch: 30, train time every whole data:57.98s
epoch: 30, total time:2007.49s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7249s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_31.params
epoch: 31, train time every whole data:57.98s
epoch: 31, total time:2072.20s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7256s
epoch: 32, train time every whole data:57.96s
epoch: 32, total time:2136.89s
validation batch 1 / 9, loss: 0.04
validation cost time: 6.7258s
epoch: 33, train time every whole data:57.95s
epoch: 33, total time:2201.56s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7252s
epoch: 34, train time every whole data:57.97s
epoch: 34, total time:2266.26s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7244s
epoch: 35, train time every whole data:57.93s
epoch: 35, total time:2330.92s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7250s
epoch: 36, train time every whole data:57.95s
epoch: 36, total time:2395.60s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7248s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_37.params
epoch: 37, train time every whole data:57.97s
epoch: 37, total time:2460.30s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7244s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_38.params
epoch: 38, train time every whole data:57.95s
epoch: 38, total time:2524.99s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7249s
epoch: 39, train time every whole data:57.79s
epoch: 39, total time:2589.50s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7240s
epoch: 40, train time every whole data:57.61s
epoch: 40, total time:2653.84s
validation batch 1 / 9, loss: 0.03
validation cost time: 6.7243s
epoch: 41, train time every whole data:57.65s
epoch: 41, total time:2718.21s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_42.params
epoch: 42, train time every whole data:57.61s
epoch: 42, total time:2782.56s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7240s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_43.params
epoch: 43, train time every whole data:57.64s
epoch: 43, total time:2846.93s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_44.params
epoch: 44, train time every whole data:57.62s
epoch: 44, total time:2911.29s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7241s
epoch: 45, train time every whole data:57.60s
epoch: 45, total time:2975.62s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7239s
epoch: 46, train time every whole data:57.58s
epoch: 46, total time:3039.93s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7240s
epoch: 47, train time every whole data:57.61s
epoch: 47, total time:3104.27s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7218s
epoch: 48, train time every whole data:57.62s
epoch: 48, total time:3168.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7246s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_49.params
epoch: 49, train time every whole data:57.60s
epoch: 49, total time:3232.95s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7241s
epoch: 50, train time every whole data:57.60s
epoch: 50, total time:3297.27s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7238s
epoch: 51, train time every whole data:57.60s
epoch: 51, total time:3361.60s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_52.params
epoch: 52, train time every whole data:57.62s
epoch: 52, total time:3425.96s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7245s
epoch: 53, train time every whole data:57.62s
epoch: 53, total time:3490.30s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7229s
epoch: 54, train time every whole data:57.60s
epoch: 54, total time:3554.63s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7253s
epoch: 55, train time every whole data:57.61s
epoch: 55, total time:3618.97s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7243s
epoch: 56, train time every whole data:57.62s
epoch: 56, total time:3683.31s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7238s
epoch: 57, train time every whole data:57.64s
epoch: 57, total time:3747.68s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 58, train time every whole data:57.59s
epoch: 58, total time:3812.00s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7233s
epoch: 59, train time every whole data:57.61s
epoch: 59, total time:3876.34s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7239s
epoch: 60, train time every whole data:57.71s
epoch: 60, total time:3940.77s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 61, train time every whole data:57.54s
epoch: 61, total time:4005.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 62, train time every whole data:57.54s
epoch: 62, total time:4069.30s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7230s
epoch: 63, train time every whole data:57.56s
epoch: 63, total time:4133.58s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 64, train time every whole data:57.56s
epoch: 64, total time:4197.86s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 65, train time every whole data:57.57s
epoch: 65, total time:4262.16s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7230s
epoch: 66, train time every whole data:57.53s
epoch: 66, total time:4326.41s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7239s
epoch: 67, train time every whole data:57.54s
epoch: 67, total time:4390.68s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7214s
epoch: 68, train time every whole data:57.54s
epoch: 68, total time:4454.95s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 69, train time every whole data:57.59s
epoch: 69, total time:4519.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 70, train time every whole data:57.55s
epoch: 70, total time:4583.54s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7237s
epoch: 71, train time every whole data:57.56s
epoch: 71, total time:4647.82s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_72.params
epoch: 72, train time every whole data:57.56s
epoch: 72, total time:4712.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 73, train time every whole data:57.59s
epoch: 73, total time:4776.44s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 74, train time every whole data:57.56s
epoch: 74, total time:4840.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7238s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_75.params
epoch: 75, train time every whole data:57.59s
epoch: 75, total time:4905.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7217s
epoch: 76, train time every whole data:57.56s
epoch: 76, total time:4969.33s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_77.params
epoch: 77, train time every whole data:57.59s
epoch: 77, total time:5033.66s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 78, train time every whole data:57.55s
epoch: 78, total time:5097.94s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 79, train time every whole data:57.57s
epoch: 79, total time:5162.23s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 80, train time every whole data:57.57s
epoch: 80, total time:5226.53s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7234s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_81.params
epoch: 81, train time every whole data:57.57s
epoch: 81, total time:5290.83s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 82, train time every whole data:57.56s
epoch: 82, total time:5355.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 83, train time every whole data:57.56s
epoch: 83, total time:5419.40s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 84, train time every whole data:57.55s
epoch: 84, total time:5483.67s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 85, train time every whole data:57.58s
epoch: 85, total time:5547.98s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7219s
epoch: 86, train time every whole data:57.56s
epoch: 86, total time:5612.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_87.params
epoch: 87, train time every whole data:57.57s
epoch: 87, total time:5676.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 88, train time every whole data:57.55s
epoch: 88, total time:5740.85s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 89, train time every whole data:57.55s
epoch: 89, total time:5805.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 90, train time every whole data:57.58s
epoch: 90, total time:5869.43s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 91, train time every whole data:57.59s
epoch: 91, total time:5933.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7213s
epoch: 92, train time every whole data:57.56s
epoch: 92, total time:5998.03s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7217s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_93.params
epoch: 93, train time every whole data:57.56s
epoch: 93, total time:6062.32s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7234s
epoch: 94, train time every whole data:57.57s
epoch: 94, total time:6126.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7217s
epoch: 95, train time every whole data:57.59s
epoch: 95, total time:6190.92s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 96, train time every whole data:57.57s
epoch: 96, total time:6255.21s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 97, train time every whole data:57.56s
epoch: 97, total time:6319.50s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 98, train time every whole data:57.58s
epoch: 98, total time:6383.80s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 99, train time every whole data:57.56s
epoch: 99, total time:6448.09s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 100, train time every whole data:57.54s
epoch: 100, total time:6512.35s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 101, train time every whole data:57.57s
epoch: 101, total time:6576.65s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 102, train time every whole data:57.57s
epoch: 102, total time:6640.94s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 103, train time every whole data:57.59s
epoch: 103, total time:6705.25s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7234s
epoch: 104, train time every whole data:57.54s
epoch: 104, total time:6769.52s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7243s
epoch: 105, train time every whole data:57.54s
epoch: 105, total time:6833.79s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 106, train time every whole data:57.57s
epoch: 106, total time:6898.08s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7237s
epoch: 107, train time every whole data:57.58s
epoch: 107, total time:6962.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7207s
epoch: 108, train time every whole data:57.57s
epoch: 108, total time:7026.69s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7237s
epoch: 109, train time every whole data:57.56s
epoch: 109, total time:7090.97s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 110, train time every whole data:57.57s
epoch: 110, total time:7155.27s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 111, train time every whole data:57.56s
epoch: 111, total time:7219.55s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7223s
epoch: 112, train time every whole data:57.60s
epoch: 112, total time:7283.88s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 113, train time every whole data:57.56s
epoch: 113, total time:7348.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7238s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_114.params
epoch: 114, train time every whole data:57.58s
epoch: 114, total time:7412.48s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 115, train time every whole data:57.56s
epoch: 115, total time:7476.77s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 116, train time every whole data:57.58s
epoch: 116, total time:7541.08s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 117, train time every whole data:57.60s
epoch: 117, total time:7605.40s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7205s
epoch: 118, train time every whole data:57.60s
epoch: 118, total time:7669.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 119, train time every whole data:57.57s
epoch: 119, total time:7734.02s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 120, train time every whole data:57.58s
epoch: 120, total time:7798.31s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7210s
epoch: 121, train time every whole data:57.58s
epoch: 121, total time:7862.62s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7214s
epoch: 122, train time every whole data:57.61s
epoch: 122, total time:7926.95s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7219s
epoch: 123, train time every whole data:57.58s
epoch: 123, total time:7991.25s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7212s
epoch: 124, train time every whole data:57.58s
epoch: 124, total time:8055.56s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7231s
epoch: 125, train time every whole data:57.59s
epoch: 125, total time:8119.88s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 126, train time every whole data:57.58s
epoch: 126, total time:8184.19s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 127, train time every whole data:57.55s
epoch: 127, total time:8248.46s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 128, train time every whole data:57.57s
epoch: 128, total time:8312.76s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7214s
epoch: 129, train time every whole data:57.61s
epoch: 129, total time:8377.09s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 130, train time every whole data:57.60s
epoch: 130, total time:8441.41s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 131, train time every whole data:57.58s
epoch: 131, total time:8505.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 132, train time every whole data:57.60s
epoch: 132, total time:8570.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 133, train time every whole data:57.61s
epoch: 133, total time:8634.37s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 134, train time every whole data:57.63s
epoch: 134, total time:8698.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 135, train time every whole data:57.59s
epoch: 135, total time:8763.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 136, train time every whole data:57.63s
epoch: 136, total time:8827.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 137, train time every whole data:57.59s
epoch: 137, total time:8891.71s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 138, train time every whole data:57.62s
epoch: 138, total time:8956.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 139, train time every whole data:57.57s
epoch: 139, total time:9020.35s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 140, train time every whole data:57.61s
epoch: 140, total time:9084.68s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 141, train time every whole data:57.60s
epoch: 141, total time:9149.01s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 142, train time every whole data:57.58s
epoch: 142, total time:9213.31s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 143, train time every whole data:57.58s
epoch: 143, total time:9277.62s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_144.params
epoch: 144, train time every whole data:57.64s
epoch: 144, total time:9342.00s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 145, train time every whole data:57.62s
epoch: 145, total time:9406.34s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 146, train time every whole data:57.60s
epoch: 146, total time:9470.66s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 147, train time every whole data:57.57s
epoch: 147, total time:9534.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 148, train time every whole data:57.60s
epoch: 148, total time:9599.28s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 149, train time every whole data:57.57s
epoch: 149, total time:9663.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7231s
epoch: 150, train time every whole data:57.61s
epoch: 150, total time:9727.91s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 151, train time every whole data:57.58s
epoch: 151, total time:9792.21s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7212s
epoch: 152, train time every whole data:57.58s
epoch: 152, total time:9856.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7234s
epoch: 153, train time every whole data:57.59s
epoch: 153, total time:9920.82s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7211s
epoch: 154, train time every whole data:57.58s
epoch: 154, total time:9985.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 155, train time every whole data:57.61s
epoch: 155, total time:10049.45s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 156, train time every whole data:57.60s
epoch: 156, total time:10113.78s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 157, train time every whole data:57.62s
epoch: 157, total time:10178.13s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 158, train time every whole data:57.58s
epoch: 158, total time:10242.43s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 159, train time every whole data:57.55s
epoch: 159, total time:10306.70s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 160, train time every whole data:57.60s
epoch: 160, total time:10371.02s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7247s
epoch: 161, train time every whole data:57.61s
epoch: 161, total time:10435.36s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 162, train time every whole data:57.56s
epoch: 162, total time:10499.64s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 163, train time every whole data:57.59s
epoch: 163, total time:10563.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 164, train time every whole data:57.62s
epoch: 164, total time:10628.30s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 165, train time every whole data:57.61s
epoch: 165, total time:10692.64s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7205s
epoch: 166, train time every whole data:57.56s
epoch: 166, total time:10756.92s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7208s
epoch: 167, train time every whole data:57.62s
epoch: 167, total time:10821.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7226s
epoch: 168, train time every whole data:57.60s
epoch: 168, total time:10885.59s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 169, train time every whole data:57.57s
epoch: 169, total time:10949.89s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7216s
epoch: 170, train time every whole data:57.56s
epoch: 170, total time:11014.17s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7219s
epoch: 171, train time every whole data:57.58s
epoch: 171, total time:11078.48s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 172, train time every whole data:57.61s
epoch: 172, total time:11142.81s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7211s
epoch: 173, train time every whole data:57.59s
epoch: 173, total time:11207.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7215s
epoch: 174, train time every whole data:57.55s
epoch: 174, total time:11271.40s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 175, train time every whole data:57.58s
epoch: 175, total time:11335.71s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 176, train time every whole data:57.59s
epoch: 176, total time:11400.02s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 177, train time every whole data:57.59s
epoch: 177, total time:11464.33s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7219s
epoch: 178, train time every whole data:57.55s
epoch: 178, total time:11528.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7218s
epoch: 179, train time every whole data:57.58s
epoch: 179, total time:11592.91s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 180, train time every whole data:57.62s
epoch: 180, total time:11657.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 181, train time every whole data:57.60s
epoch: 181, total time:11721.59s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7215s
epoch: 182, train time every whole data:57.57s
epoch: 182, total time:11785.88s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 183, train time every whole data:57.56s
epoch: 183, total time:11850.17s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7213s
epoch: 184, train time every whole data:57.62s
epoch: 184, total time:11914.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 185, train time every whole data:57.62s
epoch: 185, total time:11978.85s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 186, train time every whole data:57.53s
epoch: 186, total time:12043.11s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 187, train time every whole data:57.60s
epoch: 187, total time:12107.43s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 188, train time every whole data:57.59s
epoch: 188, total time:12171.74s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7212s
epoch: 189, train time every whole data:57.58s
epoch: 189, total time:12236.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7219s
epoch: 190, train time every whole data:57.59s
epoch: 190, total time:12300.36s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7221s
epoch: 191, train time every whole data:57.59s
epoch: 191, total time:12364.67s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7232s
epoch: 192, train time every whole data:57.61s
epoch: 192, total time:12429.00s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 193, train time every whole data:57.57s
epoch: 193, total time:12493.30s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 194, train time every whole data:57.57s
epoch: 194, total time:12557.60s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7230s
epoch: 195, train time every whole data:57.61s
epoch: 195, total time:12621.93s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7212s
epoch: 196, train time every whole data:57.58s
epoch: 196, total time:12686.23s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7217s
epoch: 197, train time every whole data:57.59s
epoch: 197, total time:12750.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7211s
epoch: 198, train time every whole data:57.58s
epoch: 198, total time:12814.85s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 199, train time every whole data:57.59s
epoch: 199, total time:12879.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7214s
epoch: 200, train time every whole data:57.62s
epoch: 200, total time:12943.50s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 201, train time every whole data:57.58s
epoch: 201, total time:13007.80s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 202, train time every whole data:57.59s
epoch: 202, total time:13072.12s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7223s
epoch: 203, train time every whole data:57.58s
epoch: 203, total time:13136.42s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 204, train time every whole data:57.61s
epoch: 204, total time:13200.76s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 205, train time every whole data:57.59s
epoch: 205, total time:13265.07s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7222s
epoch: 206, train time every whole data:57.58s
epoch: 206, total time:13329.37s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 207, train time every whole data:57.59s
epoch: 207, total time:13393.69s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7244s
epoch: 208, train time every whole data:57.62s
epoch: 208, total time:13458.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7231s
epoch: 209, train time every whole data:57.59s
epoch: 209, total time:13522.35s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7214s
epoch: 210, train time every whole data:57.57s
epoch: 210, total time:13586.64s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 211, train time every whole data:57.60s
epoch: 211, total time:13650.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 212, train time every whole data:57.60s
epoch: 212, total time:13715.29s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 213, train time every whole data:57.60s
epoch: 213, total time:13779.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 214, train time every whole data:57.57s
epoch: 214, total time:13843.91s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 215, train time every whole data:57.59s
epoch: 215, total time:13908.22s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7234s
epoch: 216, train time every whole data:57.59s
epoch: 216, total time:13972.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 217, train time every whole data:57.58s
epoch: 217, total time:14036.84s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7224s
epoch: 218, train time every whole data:57.61s
epoch: 218, total time:14101.18s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7227s
epoch: 219, train time every whole data:57.60s
epoch: 219, total time:14165.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7218s
epoch: 220, train time every whole data:57.59s
epoch: 220, total time:14229.82s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7237s
epoch: 221, train time every whole data:57.57s
epoch: 221, total time:14294.11s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7225s
epoch: 222, train time every whole data:57.60s
epoch: 222, total time:14358.44s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7244s
epoch: 223, train time every whole data:57.59s
epoch: 223, total time:14422.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 224, train time every whole data:57.62s
epoch: 224, total time:14487.10s
validation batch 1 / 9, loss: 0.02
validation cost time: 6.7237s
epoch: 225, train time every whole data:57.58s
epoch: 225, total time:14551.41s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7220s
epoch: 226, train time every whole data:57.59s
epoch: 226, total time:14615.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 227, train time every whole data:57.71s
epoch: 227, total time:14680.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7216s
epoch: 228, train time every whole data:57.46s
epoch: 228, total time:14744.33s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 229, train time every whole data:57.55s
epoch: 229, total time:14808.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7235s
epoch: 230, train time every whole data:57.55s
epoch: 230, total time:14872.89s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7237s
epoch: 231, train time every whole data:57.51s
epoch: 231, total time:14937.13s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7212s
epoch: 232, train time every whole data:57.49s
epoch: 232, total time:15001.34s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7251s
epoch: 233, train time every whole data:57.51s
epoch: 233, total time:15065.58s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 234, train time every whole data:57.56s
epoch: 234, total time:15129.86s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7237s
epoch: 235, train time every whole data:57.48s
epoch: 235, total time:15194.07s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7229s
epoch: 236, train time every whole data:57.47s
epoch: 236, total time:15258.27s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7249s
epoch: 237, train time every whole data:57.51s
epoch: 237, total time:15322.50s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7251s
epoch: 238, train time every whole data:57.54s
epoch: 238, total time:15386.78s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7246s
epoch: 239, train time every whole data:57.51s
epoch: 239, total time:15451.01s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7228s
epoch: 240, train time every whole data:57.52s
epoch: 240, total time:15515.25s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7234s
epoch: 241, train time every whole data:57.53s
epoch: 241, total time:15579.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7260s
epoch: 242, train time every whole data:57.52s
epoch: 242, total time:15643.76s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7240s
epoch: 243, train time every whole data:57.45s
epoch: 243, total time:15707.94s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7233s
epoch: 244, train time every whole data:57.50s
epoch: 244, total time:15772.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7247s
epoch: 245, train time every whole data:57.51s
epoch: 245, total time:15836.40s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7236s
epoch: 246, train time every whole data:57.55s
epoch: 246, total time:15900.68s
validation batch 1 / 9, loss: 0.01
validation cost time: 6.7242s
epoch: 247, train time every whole data:61.40s
epoch: 247, total time:15968.81s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.4900s
epoch: 248, train time every whole data:73.27s
epoch: 248, total time:16054.56s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.8746s
epoch: 249, train time every whole data:72.97s
epoch: 249, total time:16140.41s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.2241s
epoch: 250, train time every whole data:72.72s
epoch: 250, total time:16226.36s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.5085s
epoch: 251, train time every whole data:72.47s
epoch: 251, total time:16312.34s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.8008s
epoch: 252, train time every whole data:72.27s
epoch: 252, total time:16398.41s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.0641s
epoch: 253, train time every whole data:72.06s
epoch: 253, total time:16484.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.3789s
epoch: 254, train time every whole data:71.73s
epoch: 254, total time:16570.65s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.6767s
epoch: 255, train time every whole data:71.49s
epoch: 255, total time:16656.82s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.0374s
epoch: 256, train time every whole data:71.19s
epoch: 256, total time:16743.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.3103s
epoch: 257, train time every whole data:70.96s
epoch: 257, total time:16829.32s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6124s
epoch: 258, train time every whole data:70.76s
epoch: 258, total time:16915.70s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.5522s
epoch: 259, train time every whole data:71.01s
epoch: 259, total time:17002.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.2584s
epoch: 260, train time every whole data:71.27s
epoch: 260, total time:17088.79s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.9888s
epoch: 261, train time every whole data:71.50s
epoch: 261, total time:17175.28s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.6605s
epoch: 262, train time every whole data:71.74s
epoch: 262, total time:17261.68s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.3688s
epoch: 263, train time every whole data:72.02s
epoch: 263, total time:17348.08s
validation batch 1 / 9, loss: 0.01
validation cost time: 14.1188s
epoch: 264, train time every whole data:72.25s
epoch: 264, total time:17434.44s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.7777s
epoch: 265, train time every whole data:72.52s
epoch: 265, total time:17520.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.5078s
epoch: 266, train time every whole data:72.73s
epoch: 266, total time:17606.98s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.2245s
epoch: 267, train time every whole data:72.95s
epoch: 267, total time:17693.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.9038s
epoch: 268, train time every whole data:73.23s
epoch: 268, total time:17779.29s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.6194s
epoch: 269, train time every whole data:73.47s
epoch: 269, total time:17865.38s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.3338s
epoch: 270, train time every whole data:73.77s
epoch: 270, total time:17951.49s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.0107s
epoch: 271, train time every whole data:74.96s
epoch: 271, total time:18038.45s
validation batch 1 / 9, loss: 0.01
validation cost time: 11.6529s
epoch: 272, train time every whole data:74.62s
epoch: 272, total time:18124.73s
validation batch 1 / 9, loss: 0.01
validation cost time: 11.3262s
epoch: 273, train time every whole data:74.51s
epoch: 273, total time:18210.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.9225s
epoch: 274, train time every whole data:74.84s
epoch: 274, total time:18296.34s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8289s
epoch: 275, train time every whole data:75.11s
epoch: 275, total time:18382.28s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8405s
epoch: 276, train time every whole data:74.97s
epoch: 276, total time:18468.09s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8270s
epoch: 277, train time every whole data:74.95s
epoch: 277, total time:18553.87s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8285s
epoch: 278, train time every whole data:75.03s
epoch: 278, total time:18639.73s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8319s
epoch: 279, train time every whole data:74.92s
epoch: 279, total time:18725.49s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8394s
epoch: 280, train time every whole data:75.14s
epoch: 280, total time:18811.47s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8325s
epoch: 281, train time every whole data:75.02s
epoch: 281, total time:18897.32s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8383s
epoch: 282, train time every whole data:74.96s
epoch: 282, total time:18983.13s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8243s
epoch: 283, train time every whole data:75.01s
epoch: 283, total time:19068.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8200s
epoch: 284, train time every whole data:74.99s
epoch: 284, total time:19154.77s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8252s
epoch: 285, train time every whole data:74.98s
epoch: 285, total time:19240.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8335s
epoch: 286, train time every whole data:74.97s
epoch: 286, total time:19326.38s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8138s
epoch: 287, train time every whole data:75.47s
epoch: 287, total time:19412.67s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8317s
epoch: 288, train time every whole data:75.89s
epoch: 288, total time:19499.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8241s
epoch: 289, train time every whole data:74.94s
epoch: 289, total time:19585.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8149s
epoch: 290, train time every whole data:76.20s
epoch: 290, total time:19672.17s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8284s
epoch: 291, train time every whole data:74.96s
epoch: 291, total time:19757.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8317s
epoch: 292, train time every whole data:74.96s
epoch: 292, total time:19843.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8143s
epoch: 293, train time every whole data:76.19s
epoch: 293, total time:19930.76s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8311s
epoch: 294, train time every whole data:74.95s
epoch: 294, total time:20016.55s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8276s
epoch: 295, train time every whole data:80.82s
epoch: 295, total time:20108.19s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8273s
epoch: 296, train time every whole data:75.00s
epoch: 296, total time:20194.02s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8294s
epoch: 297, train time every whole data:74.96s
epoch: 297, total time:20279.81s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8237s
epoch: 298, train time every whole data:74.97s
epoch: 298, total time:20365.60s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8169s
epoch: 299, train time every whole data:74.93s
epoch: 299, total time:20451.35s
best epoch: 144
apply the best val model on the test data set ...
load weight from: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_144.params
predicting testing set batch 1 / 9, time: 1.22s
test time on whole data:10.82s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 144, predict 0 points
MAE: 10.15
RMSE: 16.84
MAPE: 22.86
current epoch: 144, predict 1 points
MAE: 10.62
RMSE: 18.41
MAPE: 22.79
current epoch: 144, predict 2 points
MAE: 10.96
RMSE: 19.24
MAPE: 22.82
current epoch: 144, predict 3 points
MAE: 11.12
RMSE: 19.57
MAPE: 22.96
current epoch: 144, predict 4 points
MAE: 11.28
RMSE: 20.04
MAPE: 23.25
current epoch: 144, predict 5 points
MAE: 11.47
RMSE: 20.44
MAPE: 23.46
current epoch: 144, predict 6 points
MAE: 11.70
RMSE: 21.04
MAPE: 23.66
current epoch: 144, predict 7 points
MAE: 12.02
RMSE: 21.76
MAPE: 24.00
current epoch: 144, predict 8 points
MAE: 12.21
RMSE: 22.06
MAPE: 24.34
current epoch: 144, predict 9 points
MAE: 12.48
RMSE: 22.64
MAPE: 24.84
current epoch: 144, predict 10 points
MAE: 12.72
RMSE: 23.56
MAPE: 25.34
current epoch: 144, predict 11 points
MAE: 12.91
RMSE: 23.88
MAPE: 25.93
all MAE: 11.64
all RMSE: 20.89
all MAPE: 23.84
[10.145447, 16.8379648213842, 22.860607504844666, 10.6202545, 18.413422772086502, 22.79379516839981, 10.961603, 19.235930614642175, 22.815272212028503, 11.123817, 19.572770710134126, 22.95982390642166, 11.2835865, 20.04069650989113, 23.25069308280945, 11.467361, 20.43502858002421, 23.45602512359619, 11.703816, 21.04202932920244, 23.662780225276947, 12.02249, 21.758474518653788, 23.998677730560303, 12.209349, 22.063775995546198, 24.335232377052307, 12.482935, 22.643724986185468, 24.840350449085236, 12.721774, 23.55757652266238, 25.343650579452515, 12.911589, 23.875365569027156, 25.930392742156982, 11.6378355, 20.887885770768094, 23.837830126285553]
fine tune the model ... 
epoch: 300, train time every whole data:217.48s
epoch: 300, total time:20679.80s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8249s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_300.params
epoch: 301, train time every whole data:217.35s
epoch: 301, total time:20907.99s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8330s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_301.params
epoch: 302, train time every whole data:216.82s
epoch: 302, total time:21135.66s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8305s
save parameters to file: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_302.params
epoch: 303, train time every whole data:214.73s
epoch: 303, total time:21361.24s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.3161s
epoch: 304, train time every whole data:212.63s
epoch: 304, total time:21587.19s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8284s
epoch: 305, train time every whole data:216.65s
epoch: 305, total time:21814.67s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8459s
epoch: 306, train time every whole data:216.66s
epoch: 306, total time:22042.17s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8265s
epoch: 307, train time every whole data:216.63s
epoch: 307, total time:22269.63s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8299s
epoch: 308, train time every whole data:216.64s
epoch: 308, total time:22497.10s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8310s
epoch: 309, train time every whole data:212.90s
epoch: 309, total time:22720.83s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.5024s
epoch: 310, train time every whole data:213.00s
epoch: 310, total time:22949.34s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8346s
epoch: 311, train time every whole data:216.68s
epoch: 311, total time:23176.85s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8466s
epoch: 312, train time every whole data:216.79s
epoch: 312, total time:23404.49s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8308s
epoch: 313, train time every whole data:216.66s
epoch: 313, total time:23631.98s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8291s
epoch: 314, train time every whole data:216.70s
epoch: 314, total time:23859.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8407s
epoch: 315, train time every whole data:212.40s
epoch: 315, total time:24082.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.4623s
epoch: 316, train time every whole data:214.10s
epoch: 316, total time:24310.31s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8238s
epoch: 317, train time every whole data:216.48s
epoch: 317, total time:24537.62s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8434s
epoch: 318, train time every whole data:216.21s
epoch: 318, total time:24764.67s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8319s
epoch: 319, train time every whole data:216.07s
epoch: 319, total time:24991.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8233s
epoch: 320, train time every whole data:216.31s
epoch: 320, total time:25218.71s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.9778s
epoch: 321, train time every whole data:212.40s
epoch: 321, total time:25442.09s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8558s
epoch: 322, train time every whole data:216.77s
epoch: 322, total time:25669.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8414s
epoch: 323, train time every whole data:216.16s
epoch: 323, total time:25896.72s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8200s
epoch: 324, train time every whole data:216.49s
epoch: 324, total time:26124.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8442s
epoch: 325, train time every whole data:216.30s
epoch: 325, total time:26351.18s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8426s
epoch: 326, train time every whole data:214.61s
epoch: 326, total time:26576.63s
validation batch 1 / 9, loss: 0.01
validation cost time: 12.9675s
epoch: 327, train time every whole data:212.27s
epoch: 327, total time:26801.87s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8234s
epoch: 328, train time every whole data:216.26s
epoch: 328, total time:27028.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8405s
epoch: 329, train time every whole data:216.05s
epoch: 329, total time:27255.85s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8362s
epoch: 330, train time every whole data:216.39s
epoch: 330, total time:27483.08s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8400s
epoch: 331, train time every whole data:216.15s
epoch: 331, total time:27710.07s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8453s
epoch: 332, train time every whole data:212.48s
epoch: 332, total time:27933.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.4749s
epoch: 333, train time every whole data:212.29s
epoch: 333, total time:28161.15s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8335s
epoch: 334, train time every whole data:216.06s
epoch: 334, total time:28388.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8211s
epoch: 335, train time every whole data:216.35s
epoch: 335, total time:28615.22s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8493s
epoch: 336, train time every whole data:216.19s
epoch: 336, total time:28842.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8309s
epoch: 337, train time every whole data:216.19s
epoch: 337, total time:29069.28s
validation batch 1 / 9, loss: 0.01
validation cost time: 10.8379s
epoch: 338, train time every whole data:212.27s
epoch: 338, total time:29292.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 13.5439s
epoch: 339, train time every whole data:394.03s
epoch: 339, total time:29699.97s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.2294s
epoch: 340, train time every whole data:405.42s
epoch: 340, total time:30124.62s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.1786s
epoch: 341, train time every whole data:405.12s
epoch: 341, total time:30548.92s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.1896s
epoch: 342, train time every whole data:384.25s
epoch: 342, total time:30952.36s
validation batch 1 / 9, loss: 0.01
validation cost time: 22.3698s
epoch: 343, train time every whole data:391.81s
epoch: 343, total time:31366.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.1100s
epoch: 344, train time every whole data:405.24s
epoch: 344, total time:31790.90s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.1103s
epoch: 345, train time every whole data:405.40s
epoch: 345, total time:32215.40s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.2989s
epoch: 346, train time every whole data:403.79s
epoch: 346, total time:32638.49s
validation batch 1 / 9, loss: 0.01
validation cost time: 21.3368s
epoch: 347, train time every whole data:382.20s
epoch: 347, total time:33042.03s
validation batch 1 / 9, loss: 0.01
validation cost time: 22.5723s
epoch: 348, train time every whole data:393.45s
epoch: 348, total time:33458.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.3852s
epoch: 349, train time every whole data:405.31s
epoch: 349, total time:33882.75s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.5614s
epoch: 350, train time every whole data:405.19s
epoch: 350, total time:34307.51s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.7967s
epoch: 351, train time every whole data:401.49s
epoch: 351, total time:34728.79s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.0636s
epoch: 352, train time every whole data:380.89s
epoch: 352, total time:35132.74s
validation batch 1 / 9, loss: 0.01
validation cost time: 22.9544s
epoch: 353, train time every whole data:394.82s
epoch: 353, total time:35550.52s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.8621s
epoch: 354, train time every whole data:404.77s
epoch: 354, total time:35975.15s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.9467s
epoch: 355, train time every whole data:404.64s
epoch: 355, total time:36399.74s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.0296s
epoch: 356, train time every whole data:400.06s
epoch: 356, total time:36819.83s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.3663s
epoch: 357, train time every whole data:380.77s
epoch: 357, total time:37223.97s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.2934s
epoch: 358, train time every whole data:395.99s
epoch: 358, total time:37643.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.2585s
epoch: 359, train time every whole data:404.30s
epoch: 359, total time:38067.82s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.3854s
epoch: 360, train time every whole data:404.05s
epoch: 360, total time:38492.26s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.3850s
epoch: 361, train time every whole data:397.52s
epoch: 361, total time:38910.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.7581s
epoch: 362, train time every whole data:380.11s
epoch: 362, total time:39314.03s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.3002s
epoch: 363, train time every whole data:397.43s
epoch: 363, total time:39734.77s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.1912s
epoch: 364, train time every whole data:404.35s
epoch: 364, total time:40159.31s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.2596s
epoch: 365, train time every whole data:404.27s
epoch: 365, total time:40583.83s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.3695s
epoch: 366, train time every whole data:396.34s
epoch: 366, total time:41000.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.9267s
epoch: 367, train time every whole data:379.83s
epoch: 367, total time:41404.30s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.5368s
epoch: 368, train time every whole data:398.89s
epoch: 368, total time:41826.73s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.4057s
epoch: 369, train time every whole data:404.13s
epoch: 369, total time:42251.27s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.5661s
epoch: 370, train time every whole data:403.93s
epoch: 370, total time:42675.77s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.6563s
epoch: 371, train time every whole data:394.38s
epoch: 371, total time:43090.81s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.9785s
epoch: 372, train time every whole data:380.25s
epoch: 372, total time:43495.05s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.8429s
epoch: 373, train time every whole data:399.74s
epoch: 373, total time:43918.63s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.4878s
epoch: 374, train time every whole data:403.92s
epoch: 374, total time:44343.04s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.5221s
epoch: 375, train time every whole data:403.81s
epoch: 375, total time:44767.37s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.5695s
epoch: 376, train time every whole data:393.00s
epoch: 376, total time:45180.95s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.9208s
epoch: 377, train time every whole data:380.50s
epoch: 377, total time:45585.37s
validation batch 1 / 9, loss: 0.01
validation cost time: 23.8344s
epoch: 378, train time every whole data:401.22s
epoch: 378, total time:46010.43s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.5569s
epoch: 379, train time every whole data:403.97s
epoch: 379, total time:46434.96s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.6991s
epoch: 380, train time every whole data:403.69s
epoch: 380, total time:46859.35s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.6991s
epoch: 381, train time every whole data:391.89s
epoch: 381, total time:47271.94s
validation batch 1 / 9, loss: 0.01
validation cost time: 24.1791s
epoch: 382, train time every whole data:381.31s
epoch: 382, total time:47677.44s
validation batch 1 / 9, loss: 0.01
validation cost time: 22.6292s
epoch: 383, train time every whole data:402.50s
epoch: 383, total time:48102.57s
validation batch 1 / 9, loss: 0.01
validation cost time: 21.0151s
epoch: 384, train time every whole data:403.52s
epoch: 384, total time:48527.11s
validation batch 1 / 9, loss: 0.01
validation cost time: 20.6926s
epoch: 385, train time every whole data:366.81s
epoch: 385, total time:48914.61s
validation batch 1 / 9, loss: 0.01
validation cost time: 17.1535s
epoch: 386, train time every whole data:361.77s
epoch: 386, total time:49293.54s
validation batch 1 / 9, loss: 0.01
validation cost time: 18.9928s
epoch: 387, train time every whole data:352.84s
epoch: 387, total time:49665.37s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.0050s
epoch: 388, train time every whole data:364.42s
epoch: 388, total time:50048.79s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6668s
epoch: 389, train time every whole data:370.93s
epoch: 389, total time:50435.39s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6637s
epoch: 390, train time every whole data:370.91s
epoch: 390, total time:50821.97s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6543s
epoch: 391, train time every whole data:370.82s
epoch: 391, total time:51208.44s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6693s
epoch: 392, train time every whole data:355.02s
epoch: 392, total time:51579.13s
validation batch 1 / 9, loss: 0.01
validation cost time: 18.9665s
epoch: 393, train time every whole data:356.25s
epoch: 393, total time:51954.35s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6453s
epoch: 394, train time every whole data:371.16s
epoch: 394, total time:52341.16s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.7145s
epoch: 395, train time every whole data:370.83s
epoch: 395, total time:52727.71s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6753s
epoch: 396, train time every whole data:370.83s
epoch: 396, total time:53114.22s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6687s
epoch: 397, train time every whole data:363.63s
epoch: 397, total time:53493.52s
validation batch 1 / 9, loss: 0.01
validation cost time: 18.9933s
epoch: 398, train time every whole data:351.62s
epoch: 398, total time:53864.13s
validation batch 1 / 9, loss: 0.01
validation cost time: 19.0000s
epoch: 399, train time every whole data:363.61s
epoch: 399, total time:54246.74s
validation batch 1 / 9, loss: 0.01
validation cost time: 15.6420s
best epoch: 302
apply the best val model on the test data set ...
load weight from: ../experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_302.params
predicting testing set batch 1 / 9, time: 1.79s
test time on whole data:15.70s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 302, predict 0 points
MAE: 10.12
RMSE: 16.74
MAPE: 22.29
current epoch: 302, predict 1 points
MAE: 10.59
RMSE: 18.15
MAPE: 22.65
current epoch: 302, predict 2 points
MAE: 10.80
RMSE: 18.57
MAPE: 22.93
current epoch: 302, predict 3 points
MAE: 10.97
RMSE: 19.13
MAPE: 23.13
current epoch: 302, predict 4 points
MAE: 11.03
RMSE: 19.23
MAPE: 23.26
current epoch: 302, predict 5 points
MAE: 11.15
RMSE: 19.58
MAPE: 23.44
current epoch: 302, predict 6 points
MAE: 11.33
RMSE: 19.99
MAPE: 23.72
current epoch: 302, predict 7 points
MAE: 11.53
RMSE: 20.49
MAPE: 24.06
current epoch: 302, predict 8 points
MAE: 11.63
RMSE: 20.62
MAPE: 24.43
current epoch: 302, predict 9 points
MAE: 11.76
RMSE: 20.96
MAPE: 24.82
current epoch: 302, predict 10 points
MAE: 11.85
RMSE: 21.16
MAPE: 25.12
current epoch: 302, predict 11 points
MAE: 12.00
RMSE: 21.58
MAPE: 25.57
all MAE: 11.23
all RMSE: 19.73
all MAPE: 23.77
[10.123012, 16.74456607870334, 22.289688885211945, 10.58589, 18.147963295569664, 22.645242512226105, 10.796383, 18.573526620253926, 22.931091487407684, 10.971929, 19.126270925142546, 23.127354681491852, 11.032526, 19.23178070694849, 23.25579524040222, 11.145806, 19.579304944989907, 23.43837022781372, 11.331383, 19.985191966784274, 23.717650771141052, 11.529952, 20.491709451629458, 24.05698299407959, 11.63117, 20.62348479282781, 24.427121877670288, 11.763572, 20.958695253719426, 24.81636255979538, 11.850568, 21.162109284869636, 25.117167830467224, 12.00032, 21.58120367474394, 25.56997537612915, 11.230209, 19.729896840726337, 23.7666055560112]
