Sun Nov 14 08:35:21 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   43C    P0    80W / 250W |   2160MiB / 32480MiB |     49%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   40C    P0    58W / 250W |   2160MiB / 32480MiB |     46%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   38C    P0    88W / 250W |   2160MiB / 32480MiB |     49%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   30C    P0    33W / 250W |   7157MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   34C    P0    49W / 250W |   2134MiB / 32480MiB |     47%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   29C    P0    26W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   29C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   27C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     51112      C   python                                      2149MiB |
|    1     51475      C   python                                      2149MiB |
|    2     51739      C   python                                      2149MiB |
|    3     18905      C   python                                      7145MiB |
|    4     52017      C   python                                      2123MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/HZME_INFLOW.conf
total training epoch, fine tune epoch: 300 , 100
batch_size: 4
attention_top_k: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/HZME_INFLOW/HZME_INFLOW_r1_d0_w0.npz
ori length: 4479 , percent: 1.0 , scale: 4479
train: torch.Size([3323, 80, 1, 12]) torch.Size([3323, 80, 12]) torch.Size([3323, 80, 12])
val: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
test: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([80, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([80, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 452181
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 18, loss: 0.57
validation cost time: 7.5018s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:58.11s
epoch: 0, total time:65.62s
validation batch 1 / 18, loss: 0.05
validation cost time: 7.1330s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:57.94s
epoch: 1, total time:130.71s
validation batch 1 / 18, loss: 0.05
validation cost time: 7.1389s
epoch: 2, train time every whole data:57.98s
epoch: 2, total time:195.83s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1379s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:57.98s
epoch: 3, total time:260.96s
validation batch 1 / 18, loss: 0.05
validation cost time: 7.1361s
epoch: 4, train time every whole data:57.98s
epoch: 4, total time:326.07s
validation batch 1 / 18, loss: 0.09
validation cost time: 7.1369s
epoch: 5, train time every whole data:57.96s
epoch: 5, total time:391.17s
validation batch 1 / 18, loss: 0.16
validation cost time: 7.1346s
epoch: 6, train time every whole data:57.95s
epoch: 6, total time:456.26s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1400s
epoch: 7, train time every whole data:57.98s
epoch: 7, total time:521.39s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1370s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_8.params
epoch: 8, train time every whole data:57.98s
epoch: 8, total time:586.51s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1364s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:58.01s
epoch: 9, total time:651.67s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1369s
epoch: 10, train time every whole data:58.00s
epoch: 10, total time:716.81s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1402s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_11.params
epoch: 11, train time every whole data:58.02s
epoch: 11, total time:781.98s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1361s
epoch: 12, train time every whole data:58.01s
epoch: 12, total time:847.13s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1351s
epoch: 13, train time every whole data:58.03s
epoch: 13, total time:912.30s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1402s
epoch: 14, train time every whole data:57.99s
epoch: 14, total time:977.43s
validation batch 1 / 18, loss: 0.06
validation cost time: 7.1381s
epoch: 15, train time every whole data:58.01s
epoch: 15, total time:1042.57s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1370s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_16.params
epoch: 16, train time every whole data:57.98s
epoch: 16, total time:1107.71s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1393s
epoch: 17, train time every whole data:58.02s
epoch: 17, total time:1172.87s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1433s
epoch: 18, train time every whole data:57.96s
epoch: 18, total time:1237.98s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1401s
epoch: 19, train time every whole data:57.99s
epoch: 19, total time:1303.11s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1370s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_20.params
epoch: 20, train time every whole data:57.99s
epoch: 20, total time:1368.25s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1402s
epoch: 21, train time every whole data:58.01s
epoch: 21, total time:1433.41s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1408s
epoch: 22, train time every whole data:57.99s
epoch: 22, total time:1498.54s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1346s
epoch: 23, train time every whole data:58.02s
epoch: 23, total time:1563.70s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1358s
epoch: 24, train time every whole data:57.99s
epoch: 24, total time:1628.82s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1401s
epoch: 25, train time every whole data:57.96s
epoch: 25, total time:1693.92s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1414s
epoch: 26, train time every whole data:57.97s
epoch: 26, total time:1759.04s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1378s
epoch: 27, train time every whole data:58.01s
epoch: 27, total time:1824.19s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_28.params
epoch: 28, train time every whole data:58.01s
epoch: 28, total time:1889.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 29, train time every whole data:58.03s
epoch: 29, total time:1954.52s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1376s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_30.params
epoch: 30, train time every whole data:58.01s
epoch: 30, total time:2019.68s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1381s
epoch: 31, train time every whole data:57.97s
epoch: 31, total time:2084.79s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1419s
epoch: 32, train time every whole data:58.00s
epoch: 32, total time:2149.93s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1428s
epoch: 33, train time every whole data:58.02s
epoch: 33, total time:2215.10s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1403s
epoch: 34, train time every whole data:57.99s
epoch: 34, total time:2280.23s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 35, train time every whole data:57.98s
epoch: 35, total time:2345.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1408s
epoch: 36, train time every whole data:57.99s
epoch: 36, total time:2410.48s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1397s
epoch: 37, train time every whole data:58.02s
epoch: 37, total time:2475.65s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1428s
epoch: 38, train time every whole data:57.98s
epoch: 38, total time:2540.78s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1373s
epoch: 39, train time every whole data:57.99s
epoch: 39, total time:2605.91s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1423s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_40.params
epoch: 40, train time every whole data:58.01s
epoch: 40, total time:2671.07s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1417s
epoch: 41, train time every whole data:58.00s
epoch: 41, total time:2736.22s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1426s
epoch: 42, train time every whole data:58.00s
epoch: 42, total time:2801.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1421s
epoch: 43, train time every whole data:57.98s
epoch: 43, total time:2866.49s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 44, train time every whole data:58.00s
epoch: 44, total time:2931.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1426s
epoch: 45, train time every whole data:57.99s
epoch: 45, total time:2996.76s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1446s
epoch: 46, train time every whole data:57.97s
epoch: 46, total time:3061.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_47.params
epoch: 47, train time every whole data:58.00s
epoch: 47, total time:3127.04s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1380s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_48.params
epoch: 48, train time every whole data:57.99s
epoch: 48, total time:3192.18s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1397s
epoch: 49, train time every whole data:57.99s
epoch: 49, total time:3257.31s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1388s
epoch: 50, train time every whole data:58.01s
epoch: 50, total time:3322.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1387s
epoch: 51, train time every whole data:58.00s
epoch: 51, total time:3387.60s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1417s
epoch: 52, train time every whole data:57.99s
epoch: 52, total time:3452.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 53, train time every whole data:58.00s
epoch: 53, total time:3517.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1383s
epoch: 54, train time every whole data:58.02s
epoch: 54, total time:3583.04s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1408s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_55.params
epoch: 55, train time every whole data:58.02s
epoch: 55, total time:3648.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 56, train time every whole data:58.01s
epoch: 56, total time:3713.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1512s
epoch: 57, train time every whole data:58.01s
epoch: 57, total time:3778.52s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1430s
epoch: 58, train time every whole data:57.99s
epoch: 58, total time:3843.66s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1415s
epoch: 59, train time every whole data:58.04s
epoch: 59, total time:3908.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
epoch: 60, train time every whole data:58.02s
epoch: 60, total time:3974.00s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1430s
epoch: 61, train time every whole data:58.02s
epoch: 61, total time:4039.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1554s
epoch: 62, train time every whole data:58.01s
epoch: 62, total time:4104.32s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1437s
epoch: 63, train time every whole data:58.01s
epoch: 63, total time:4169.48s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1439s
epoch: 64, train time every whole data:57.99s
epoch: 64, total time:4234.61s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1421s
epoch: 65, train time every whole data:58.04s
epoch: 65, total time:4299.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 66, train time every whole data:57.97s
epoch: 66, total time:4364.91s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1376s
epoch: 67, train time every whole data:57.98s
epoch: 67, total time:4430.03s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1399s
epoch: 68, train time every whole data:58.02s
epoch: 68, total time:4495.19s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1366s
epoch: 69, train time every whole data:58.02s
epoch: 69, total time:4560.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1376s
epoch: 70, train time every whole data:58.02s
epoch: 70, total time:4625.50s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1379s
epoch: 71, train time every whole data:58.03s
epoch: 71, total time:4690.67s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1360s
epoch: 72, train time every whole data:58.01s
epoch: 72, total time:4755.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1407s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_73.params
epoch: 73, train time every whole data:58.01s
epoch: 73, total time:4820.98s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 74, train time every whole data:57.98s
epoch: 74, total time:4886.11s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1403s
epoch: 75, train time every whole data:58.01s
epoch: 75, total time:4951.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1517s
epoch: 76, train time every whole data:58.02s
epoch: 76, total time:5016.42s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1377s
epoch: 77, train time every whole data:58.01s
epoch: 77, total time:5081.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1465s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_78.params
epoch: 78, train time every whole data:57.98s
epoch: 78, total time:5146.71s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1446s
epoch: 79, train time every whole data:57.96s
epoch: 79, total time:5211.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 80, train time every whole data:58.00s
epoch: 80, total time:5276.97s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1411s
epoch: 81, train time every whole data:58.01s
epoch: 81, total time:5342.12s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1393s
epoch: 82, train time every whole data:58.00s
epoch: 82, total time:5407.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1430s
epoch: 83, train time every whole data:57.99s
epoch: 83, total time:5472.40s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1432s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_84.params
epoch: 84, train time every whole data:58.01s
epoch: 84, total time:5537.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1384s
epoch: 85, train time every whole data:58.02s
epoch: 85, total time:5602.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1386s
epoch: 86, train time every whole data:58.00s
epoch: 86, total time:5667.87s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1373s
epoch: 87, train time every whole data:57.98s
epoch: 87, total time:5732.99s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 88, train time every whole data:58.00s
epoch: 88, total time:5798.13s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1421s
epoch: 89, train time every whole data:58.01s
epoch: 89, total time:5863.29s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 90, train time every whole data:57.97s
epoch: 90, total time:5928.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1449s
epoch: 91, train time every whole data:58.00s
epoch: 91, total time:5993.54s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1390s
epoch: 92, train time every whole data:57.98s
epoch: 92, total time:6058.67s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
epoch: 93, train time every whole data:58.01s
epoch: 93, total time:6123.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 94, train time every whole data:58.01s
epoch: 94, total time:6188.98s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1407s
epoch: 95, train time every whole data:58.02s
epoch: 95, total time:6254.14s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 96, train time every whole data:57.98s
epoch: 96, total time:6319.27s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 97, train time every whole data:58.00s
epoch: 97, total time:6384.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 98, train time every whole data:58.01s
epoch: 98, total time:6449.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1403s
epoch: 99, train time every whole data:58.02s
epoch: 99, total time:6514.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1406s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_100.params
epoch: 100, train time every whole data:58.01s
epoch: 100, total time:6579.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1417s
epoch: 101, train time every whole data:58.00s
epoch: 101, total time:6645.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1371s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_102.params
epoch: 102, train time every whole data:57.98s
epoch: 102, total time:6710.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 103, train time every whole data:58.01s
epoch: 103, total time:6775.31s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 104, train time every whole data:58.02s
epoch: 104, total time:6840.47s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1353s
epoch: 105, train time every whole data:57.99s
epoch: 105, total time:6905.60s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1370s
epoch: 106, train time every whole data:58.00s
epoch: 106, total time:6970.74s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1370s
epoch: 107, train time every whole data:58.00s
epoch: 107, total time:7035.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1411s
epoch: 108, train time every whole data:58.00s
epoch: 108, total time:7101.02s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 109, train time every whole data:57.99s
epoch: 109, total time:7166.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1378s
epoch: 110, train time every whole data:58.00s
epoch: 110, total time:7231.30s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 111, train time every whole data:58.03s
epoch: 111, total time:7296.47s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1371s
epoch: 112, train time every whole data:57.96s
epoch: 112, total time:7361.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 113, train time every whole data:58.00s
epoch: 113, total time:7426.71s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 114, train time every whole data:57.98s
epoch: 114, total time:7491.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1356s
epoch: 115, train time every whole data:58.02s
epoch: 115, total time:7556.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1348s
epoch: 116, train time every whole data:58.00s
epoch: 116, total time:7622.12s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1357s
epoch: 117, train time every whole data:58.00s
epoch: 117, total time:7687.26s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1352s
epoch: 118, train time every whole data:58.03s
epoch: 118, total time:7752.43s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1362s
epoch: 119, train time every whole data:58.00s
epoch: 119, total time:7817.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1492s
epoch: 120, train time every whole data:58.01s
epoch: 120, total time:7882.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1361s
epoch: 121, train time every whole data:58.02s
epoch: 121, total time:7947.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1348s
epoch: 122, train time every whole data:58.01s
epoch: 122, total time:8013.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1366s
epoch: 123, train time every whole data:57.99s
epoch: 123, total time:8078.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1362s
epoch: 124, train time every whole data:57.99s
epoch: 124, total time:8143.28s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 125, train time every whole data:58.01s
epoch: 125, total time:8208.43s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 126, train time every whole data:58.01s
epoch: 126, total time:8273.58s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1375s
epoch: 127, train time every whole data:58.00s
epoch: 127, total time:8338.71s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1367s
epoch: 128, train time every whole data:57.99s
epoch: 128, total time:8403.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 129, train time every whole data:57.98s
epoch: 129, total time:8468.96s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1425s
epoch: 130, train time every whole data:58.00s
epoch: 130, total time:8534.10s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 131, train time every whole data:58.00s
epoch: 131, total time:8599.24s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1407s
epoch: 132, train time every whole data:58.00s
epoch: 132, total time:8664.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1413s
epoch: 133, train time every whole data:58.01s
epoch: 133, total time:8729.54s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1360s
epoch: 134, train time every whole data:57.99s
epoch: 134, total time:8794.66s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 135, train time every whole data:58.01s
epoch: 135, total time:8859.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1401s
epoch: 136, train time every whole data:58.01s
epoch: 136, total time:8924.97s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1433s
epoch: 137, train time every whole data:57.99s
epoch: 137, total time:8990.11s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1370s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_138.params
epoch: 138, train time every whole data:57.99s
epoch: 138, total time:9055.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1401s
epoch: 139, train time every whole data:58.01s
epoch: 139, total time:9120.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1390s
epoch: 140, train time every whole data:58.01s
epoch: 140, total time:9185.56s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 141, train time every whole data:58.00s
epoch: 141, total time:9250.70s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1368s
epoch: 142, train time every whole data:57.96s
epoch: 142, total time:9315.80s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1371s
epoch: 143, train time every whole data:58.01s
epoch: 143, total time:9380.95s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1417s
epoch: 144, train time every whole data:57.98s
epoch: 144, total time:9446.08s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1411s
epoch: 145, train time every whole data:58.00s
epoch: 145, total time:9511.22s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1372s
epoch: 146, train time every whole data:58.00s
epoch: 146, total time:9576.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1405s
epoch: 147, train time every whole data:57.99s
epoch: 147, total time:9641.49s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 148, train time every whole data:57.99s
epoch: 148, total time:9706.61s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1408s
epoch: 149, train time every whole data:57.98s
epoch: 149, total time:9771.73s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1417s
epoch: 150, train time every whole data:58.00s
epoch: 150, total time:9836.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 151, train time every whole data:57.99s
epoch: 151, total time:9902.01s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1363s
epoch: 152, train time every whole data:57.98s
epoch: 152, total time:9967.13s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1388s
epoch: 153, train time every whole data:57.98s
epoch: 153, total time:10032.25s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1384s
epoch: 154, train time every whole data:57.97s
epoch: 154, total time:10097.36s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1420s
epoch: 155, train time every whole data:57.99s
epoch: 155, total time:10162.50s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 156, train time every whole data:58.02s
epoch: 156, total time:10227.65s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1431s
epoch: 157, train time every whole data:58.01s
epoch: 157, total time:10292.81s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1384s
epoch: 158, train time every whole data:58.00s
epoch: 158, total time:10357.95s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1369s
epoch: 159, train time every whole data:58.00s
epoch: 159, total time:10423.08s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 160, train time every whole data:57.99s
epoch: 160, total time:10488.21s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1385s
epoch: 161, train time every whole data:58.00s
epoch: 161, total time:10553.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1385s
epoch: 162, train time every whole data:57.99s
epoch: 162, total time:10618.48s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1380s
epoch: 163, train time every whole data:57.98s
epoch: 163, total time:10683.60s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1404s
epoch: 164, train time every whole data:58.02s
epoch: 164, total time:10748.76s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1416s
epoch: 165, train time every whole data:57.99s
epoch: 165, total time:10813.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1385s
epoch: 166, train time every whole data:57.99s
epoch: 166, total time:10879.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1355s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_167.params
epoch: 167, train time every whole data:58.03s
epoch: 167, total time:10944.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1426s
epoch: 168, train time every whole data:58.01s
epoch: 168, total time:11009.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1422s
epoch: 169, train time every whole data:58.02s
epoch: 169, total time:11074.53s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 170, train time every whole data:57.99s
epoch: 170, total time:11139.65s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1426s
epoch: 171, train time every whole data:58.00s
epoch: 171, total time:11204.80s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1374s
epoch: 172, train time every whole data:57.99s
epoch: 172, total time:11269.93s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 173, train time every whole data:58.03s
epoch: 173, total time:11335.10s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1428s
epoch: 174, train time every whole data:58.01s
epoch: 174, total time:11400.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 175, train time every whole data:58.01s
epoch: 175, total time:11465.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 176, train time every whole data:57.99s
epoch: 176, total time:11530.55s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 177, train time every whole data:58.02s
epoch: 177, total time:11595.71s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 178, train time every whole data:57.99s
epoch: 178, total time:11660.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1383s
epoch: 179, train time every whole data:58.01s
epoch: 179, total time:11725.98s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1424s
epoch: 180, train time every whole data:58.00s
epoch: 180, total time:11791.13s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1420s
epoch: 181, train time every whole data:58.01s
epoch: 181, total time:11856.28s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1372s
epoch: 182, train time every whole data:58.01s
epoch: 182, total time:11921.43s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1387s
epoch: 183, train time every whole data:58.00s
epoch: 183, total time:11986.56s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1384s
epoch: 184, train time every whole data:57.99s
epoch: 184, total time:12051.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 185, train time every whole data:57.99s
epoch: 185, total time:12116.83s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1411s
epoch: 186, train time every whole data:58.01s
epoch: 186, total time:12181.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1423s
epoch: 187, train time every whole data:58.02s
epoch: 187, total time:12247.15s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1414s
epoch: 188, train time every whole data:58.01s
epoch: 188, total time:12312.30s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1385s
epoch: 189, train time every whole data:58.01s
epoch: 189, total time:12377.45s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1379s
epoch: 190, train time every whole data:58.00s
epoch: 190, total time:12442.59s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1372s
epoch: 191, train time every whole data:58.03s
epoch: 191, total time:12507.77s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1368s
epoch: 192, train time every whole data:58.00s
epoch: 192, total time:12572.91s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1364s
epoch: 193, train time every whole data:58.02s
epoch: 193, total time:12638.07s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1404s
epoch: 194, train time every whole data:58.03s
epoch: 194, total time:12703.25s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1416s
epoch: 195, train time every whole data:58.01s
epoch: 195, total time:12768.41s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1409s
epoch: 196, train time every whole data:58.01s
epoch: 196, total time:12833.56s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1410s
epoch: 197, train time every whole data:58.00s
epoch: 197, total time:12898.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1409s
epoch: 198, train time every whole data:58.00s
epoch: 198, total time:12963.85s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1360s
epoch: 199, train time every whole data:57.99s
epoch: 199, total time:13028.98s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 200, train time every whole data:58.02s
epoch: 200, total time:13094.14s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1416s
epoch: 201, train time every whole data:58.00s
epoch: 201, total time:13159.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1434s
epoch: 202, train time every whole data:58.00s
epoch: 202, total time:13224.43s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1381s
epoch: 203, train time every whole data:58.01s
epoch: 203, total time:13289.59s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1435s
epoch: 204, train time every whole data:58.00s
epoch: 204, total time:13354.74s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1393s
epoch: 205, train time every whole data:58.03s
epoch: 205, total time:13419.91s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 206, train time every whole data:58.00s
epoch: 206, total time:13485.05s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 207, train time every whole data:58.02s
epoch: 207, total time:13550.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 208, train time every whole data:57.99s
epoch: 208, total time:13615.34s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1414s
epoch: 209, train time every whole data:58.02s
epoch: 209, total time:13680.50s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1375s
epoch: 210, train time every whole data:57.99s
epoch: 210, total time:13745.64s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1362s
epoch: 211, train time every whole data:57.97s
epoch: 211, total time:13810.75s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1405s
epoch: 212, train time every whole data:58.00s
epoch: 212, total time:13875.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1378s
epoch: 213, train time every whole data:58.02s
epoch: 213, total time:13941.05s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
epoch: 214, train time every whole data:58.01s
epoch: 214, total time:14006.20s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1371s
epoch: 215, train time every whole data:58.00s
epoch: 215, total time:14071.34s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 216, train time every whole data:58.02s
epoch: 216, total time:14136.50s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1420s
epoch: 217, train time every whole data:57.98s
epoch: 217, total time:14201.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1359s
epoch: 218, train time every whole data:58.00s
epoch: 218, total time:14266.77s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1378s
epoch: 219, train time every whole data:58.01s
epoch: 219, total time:14331.92s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1425s
epoch: 220, train time every whole data:58.01s
epoch: 220, total time:14397.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
epoch: 221, train time every whole data:57.99s
epoch: 221, total time:14462.21s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1369s
epoch: 222, train time every whole data:57.98s
epoch: 222, total time:14527.33s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1374s
epoch: 223, train time every whole data:58.01s
epoch: 223, total time:14592.48s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1380s
epoch: 224, train time every whole data:58.01s
epoch: 224, total time:14657.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1423s
epoch: 225, train time every whole data:57.99s
epoch: 225, total time:14722.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1422s
epoch: 226, train time every whole data:57.97s
epoch: 226, total time:14787.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1382s
epoch: 227, train time every whole data:58.00s
epoch: 227, total time:14853.02s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1417s
epoch: 228, train time every whole data:58.03s
epoch: 228, total time:14918.19s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 229, train time every whole data:58.01s
epoch: 229, total time:14983.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1430s
epoch: 230, train time every whole data:58.00s
epoch: 230, total time:15048.49s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1413s
epoch: 231, train time every whole data:58.01s
epoch: 231, total time:15113.64s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1412s
epoch: 232, train time every whole data:58.02s
epoch: 232, total time:15178.81s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1363s
epoch: 233, train time every whole data:58.03s
epoch: 233, total time:15243.97s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1367s
epoch: 234, train time every whole data:58.01s
epoch: 234, total time:15309.12s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1360s
epoch: 235, train time every whole data:58.00s
epoch: 235, total time:15374.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1422s
epoch: 236, train time every whole data:58.01s
epoch: 236, total time:15439.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1428s
epoch: 237, train time every whole data:58.02s
epoch: 237, total time:15504.58s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1429s
epoch: 238, train time every whole data:58.00s
epoch: 238, total time:15569.72s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1415s
epoch: 239, train time every whole data:58.03s
epoch: 239, total time:15634.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1368s
epoch: 240, train time every whole data:58.02s
epoch: 240, total time:15700.05s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1424s
epoch: 241, train time every whole data:58.02s
epoch: 241, total time:15765.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1440s
epoch: 242, train time every whole data:58.03s
epoch: 242, total time:15830.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 243, train time every whole data:58.00s
epoch: 243, total time:15895.53s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1429s
epoch: 244, train time every whole data:57.99s
epoch: 244, total time:15960.67s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1432s
epoch: 245, train time every whole data:58.01s
epoch: 245, total time:16025.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1421s
epoch: 246, train time every whole data:58.00s
epoch: 246, total time:16090.97s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1419s
epoch: 247, train time every whole data:58.00s
epoch: 247, total time:16156.12s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 248, train time every whole data:58.05s
epoch: 248, total time:16221.31s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1421s
epoch: 249, train time every whole data:58.01s
epoch: 249, total time:16286.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1374s
epoch: 250, train time every whole data:58.00s
epoch: 250, total time:16351.60s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1355s
epoch: 251, train time every whole data:58.01s
epoch: 251, total time:16416.75s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 252, train time every whole data:58.00s
epoch: 252, total time:16481.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1362s
epoch: 253, train time every whole data:58.02s
epoch: 253, total time:16547.05s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1359s
epoch: 254, train time every whole data:58.02s
epoch: 254, total time:16612.20s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1386s
epoch: 255, train time every whole data:58.03s
epoch: 255, total time:16677.37s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1385s
epoch: 256, train time every whole data:58.06s
epoch: 256, total time:16742.57s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1352s
epoch: 257, train time every whole data:58.02s
epoch: 257, total time:16807.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1340s
epoch: 258, train time every whole data:58.05s
epoch: 258, total time:16872.92s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 259, train time every whole data:58.04s
epoch: 259, total time:16938.09s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1389s
epoch: 260, train time every whole data:58.04s
epoch: 260, total time:17003.27s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1497s
epoch: 261, train time every whole data:58.04s
epoch: 261, total time:17068.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1371s
epoch: 262, train time every whole data:58.02s
epoch: 262, total time:17133.62s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1349s
epoch: 263, train time every whole data:58.04s
epoch: 263, total time:17198.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1396s
epoch: 264, train time every whole data:58.04s
epoch: 264, total time:17263.98s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 265, train time every whole data:58.03s
epoch: 265, total time:17329.14s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1373s
epoch: 266, train time every whole data:58.00s
epoch: 266, total time:17394.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1360s
epoch: 267, train time every whole data:58.02s
epoch: 267, total time:17459.44s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1371s
epoch: 268, train time every whole data:58.00s
epoch: 268, total time:17524.58s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1367s
epoch: 269, train time every whole data:58.01s
epoch: 269, total time:17589.73s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1429s
epoch: 270, train time every whole data:58.02s
epoch: 270, total time:17654.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1373s
epoch: 271, train time every whole data:58.02s
epoch: 271, total time:17720.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1429s
epoch: 272, train time every whole data:58.02s
epoch: 272, total time:17785.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 273, train time every whole data:58.01s
epoch: 273, total time:17850.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1413s
epoch: 274, train time every whole data:58.00s
epoch: 274, total time:17915.50s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1377s
epoch: 275, train time every whole data:58.00s
epoch: 275, total time:17980.64s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1411s
epoch: 276, train time every whole data:58.01s
epoch: 276, total time:18045.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1370s
epoch: 277, train time every whole data:58.00s
epoch: 277, total time:18110.93s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1420s
epoch: 278, train time every whole data:58.00s
epoch: 278, total time:18176.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 279, train time every whole data:58.03s
epoch: 279, total time:18241.25s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 280, train time every whole data:58.00s
epoch: 280, total time:18306.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1401s
epoch: 281, train time every whole data:58.00s
epoch: 281, total time:18371.54s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1376s
epoch: 282, train time every whole data:57.98s
epoch: 282, total time:18436.66s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1365s
epoch: 283, train time every whole data:58.01s
epoch: 283, total time:18501.81s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1375s
epoch: 284, train time every whole data:58.02s
epoch: 284, total time:18566.96s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 285, train time every whole data:58.03s
epoch: 285, total time:18632.13s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1356s
epoch: 286, train time every whole data:58.00s
epoch: 286, total time:18697.27s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1367s
epoch: 287, train time every whole data:57.99s
epoch: 287, total time:18762.40s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1371s
epoch: 288, train time every whole data:58.00s
epoch: 288, total time:18827.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1375s
epoch: 289, train time every whole data:58.02s
epoch: 289, total time:18892.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1369s
epoch: 290, train time every whole data:58.01s
epoch: 290, total time:18957.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 291, train time every whole data:58.01s
epoch: 291, total time:19022.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1403s
epoch: 292, train time every whole data:58.03s
epoch: 292, total time:19088.16s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1406s
epoch: 293, train time every whole data:58.04s
epoch: 293, total time:19153.34s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1398s
epoch: 294, train time every whole data:58.06s
epoch: 294, total time:19218.55s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1357s
epoch: 295, train time every whole data:58.06s
epoch: 295, total time:19283.74s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1360s
epoch: 296, train time every whole data:58.06s
epoch: 296, total time:19348.94s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1370s
epoch: 297, train time every whole data:58.08s
epoch: 297, total time:19414.15s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1417s
epoch: 298, train time every whole data:58.08s
epoch: 298, total time:19479.37s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1364s
epoch: 299, train time every whole data:58.05s
epoch: 299, total time:19544.56s
best epoch: 167
apply the best val model on the test data set ...
load weight from: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_167.params
predicting testing set batch 1 / 18, time: 0.41s
test time on whole data:7.15s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 167, predict 0 points
MAE: 10.22
RMSE: 16.84
MAPE: 24.06
current epoch: 167, predict 1 points
MAE: 10.61
RMSE: 18.29
MAPE: 23.99
current epoch: 167, predict 2 points
MAE: 10.82
RMSE: 18.96
MAPE: 23.92
current epoch: 167, predict 3 points
MAE: 11.13
RMSE: 19.73
MAPE: 24.12
current epoch: 167, predict 4 points
MAE: 11.43
RMSE: 20.39
MAPE: 24.60
current epoch: 167, predict 5 points
MAE: 11.59
RMSE: 20.39
MAPE: 25.35
current epoch: 167, predict 6 points
MAE: 11.91
RMSE: 21.27
MAPE: 26.19
current epoch: 167, predict 7 points
MAE: 12.25
RMSE: 22.30
MAPE: 26.98
current epoch: 167, predict 8 points
MAE: 12.43
RMSE: 22.44
MAPE: 27.69
current epoch: 167, predict 9 points
MAE: 12.62
RMSE: 22.67
MAPE: 28.67
current epoch: 167, predict 10 points
MAE: 12.92
RMSE: 23.21
MAPE: 30.40
current epoch: 167, predict 11 points
MAE: 13.43
RMSE: 24.26
MAPE: 32.93
all MAE: 11.78
all RMSE: 21.00
all MAPE: 26.53
[10.220822, 16.836801203193538, 24.057537317276, 10.612676, 18.286475114661673, 23.992177844047546, 10.8244295, 18.960367729387364, 23.92280548810959, 11.133562, 19.729841930376843, 24.118433892726898, 11.428666, 20.391228140026136, 24.60283488035202, 11.590826, 20.39157534902205, 25.348079204559326, 11.906233, 21.266185385939355, 26.188945770263672, 12.245621, 22.295473414252164, 26.983466744422913, 12.433674, 22.439336759996173, 27.689599990844727, 12.620962, 22.672476678353178, 28.673502802848816, 12.92316, 23.211830227278504, 30.397647619247437, 13.425891, 24.259154803844154, 32.925233244895935, 11.780544, 21.00090097583613, 26.531904935836792]
fine tune the model ... 
epoch: 300, train time every whole data:167.21s
epoch: 300, total time:19719.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1425s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_300.params
epoch: 301, train time every whole data:167.28s
epoch: 301, total time:19893.47s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1429s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_301.params
epoch: 302, train time every whole data:167.26s
epoch: 302, total time:20067.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 303, train time every whole data:167.11s
epoch: 303, total time:20242.14s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_303.params
epoch: 304, train time every whole data:167.18s
epoch: 304, total time:20416.47s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1411s
epoch: 305, train time every whole data:167.32s
epoch: 305, total time:20590.94s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1406s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_305.params
epoch: 306, train time every whole data:167.09s
epoch: 306, total time:20765.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1435s
epoch: 307, train time every whole data:167.18s
epoch: 307, total time:20939.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 308, train time every whole data:166.89s
epoch: 308, total time:21113.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1398s
epoch: 309, train time every whole data:167.02s
epoch: 309, total time:21287.71s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1435s
epoch: 310, train time every whole data:166.99s
epoch: 310, total time:21461.84s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1420s
epoch: 311, train time every whole data:166.73s
epoch: 311, total time:21635.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1389s
epoch: 312, train time every whole data:167.04s
epoch: 312, total time:21809.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1391s
epoch: 313, train time every whole data:166.83s
epoch: 313, total time:21983.87s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1398s
epoch: 314, train time every whole data:166.67s
epoch: 314, total time:22157.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1367s
epoch: 315, train time every whole data:165.72s
epoch: 315, total time:22330.55s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1361s
epoch: 316, train time every whole data:165.28s
epoch: 316, total time:22502.96s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1394s
epoch: 317, train time every whole data:165.38s
epoch: 317, total time:22675.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 318, train time every whole data:165.41s
epoch: 318, total time:22848.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1399s
epoch: 319, train time every whole data:165.57s
epoch: 319, total time:23020.75s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1389s
epoch: 320, train time every whole data:165.70s
epoch: 320, total time:23193.59s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1388s
epoch: 321, train time every whole data:165.45s
epoch: 321, total time:23366.17s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1381s
epoch: 322, train time every whole data:165.60s
epoch: 322, total time:23538.91s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1348s
epoch: 323, train time every whole data:165.64s
epoch: 323, total time:23711.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1394s
epoch: 324, train time every whole data:165.52s
epoch: 324, total time:23884.35s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 325, train time every whole data:165.42s
epoch: 325, total time:24056.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1319s
epoch: 326, train time every whole data:165.34s
epoch: 326, total time:24229.37s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1325s
epoch: 327, train time every whole data:165.15s
epoch: 327, total time:24401.66s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1340s
epoch: 328, train time every whole data:165.33s
epoch: 328, total time:24574.13s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1376s
epoch: 329, train time every whole data:165.40s
epoch: 329, total time:24746.67s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1384s
epoch: 330, train time every whole data:165.36s
epoch: 330, total time:24919.17s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 331, train time every whole data:165.45s
epoch: 331, total time:25091.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 332, train time every whole data:165.59s
epoch: 332, total time:25264.49s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1407s
epoch: 333, train time every whole data:165.35s
epoch: 333, total time:25436.98s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
epoch: 334, train time every whole data:165.50s
epoch: 334, total time:25609.62s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 335, train time every whole data:165.33s
epoch: 335, total time:25782.09s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1318s
epoch: 336, train time every whole data:165.52s
epoch: 336, total time:25954.74s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1350s
epoch: 337, train time every whole data:165.31s
epoch: 337, total time:26127.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1347s
epoch: 338, train time every whole data:165.48s
epoch: 338, total time:26299.80s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1378s
epoch: 339, train time every whole data:168.21s
epoch: 339, total time:26475.15s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1470s
epoch: 340, train time every whole data:168.51s
epoch: 340, total time:26650.81s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1475s
epoch: 341, train time every whole data:168.64s
epoch: 341, total time:26826.60s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1508s
epoch: 342, train time every whole data:168.60s
epoch: 342, total time:27002.35s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1393s
epoch: 343, train time every whole data:168.54s
epoch: 343, total time:27178.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1381s
epoch: 344, train time every whole data:168.70s
epoch: 344, total time:27353.87s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1374s
epoch: 345, train time every whole data:168.69s
epoch: 345, total time:27529.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
epoch: 346, train time every whole data:168.58s
epoch: 346, total time:27705.42s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1344s
epoch: 347, train time every whole data:168.44s
epoch: 347, total time:27881.00s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1384s
epoch: 348, train time every whole data:168.37s
epoch: 348, total time:28056.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1385s
epoch: 349, train time every whole data:168.36s
epoch: 349, total time:28232.01s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
epoch: 350, train time every whole data:168.23s
epoch: 350, total time:28407.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1370s
epoch: 351, train time every whole data:168.38s
epoch: 351, total time:28582.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1346s
epoch: 352, train time every whole data:168.61s
epoch: 352, total time:28758.65s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 353, train time every whole data:168.23s
epoch: 353, total time:28934.02s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1363s
epoch: 354, train time every whole data:168.52s
epoch: 354, total time:29109.68s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1394s
epoch: 355, train time every whole data:168.34s
epoch: 355, total time:29285.16s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 356, train time every whole data:168.47s
epoch: 356, total time:29460.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1339s
epoch: 357, train time every whole data:168.17s
epoch: 357, total time:29636.07s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
epoch: 358, train time every whole data:168.55s
epoch: 358, total time:29811.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
epoch: 359, train time every whole data:168.41s
epoch: 359, total time:29987.31s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 360, train time every whole data:169.24s
epoch: 360, total time:30163.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1399s
epoch: 361, train time every whole data:168.72s
epoch: 361, total time:30339.55s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1390s
epoch: 362, train time every whole data:168.99s
epoch: 362, total time:30515.68s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1403s
epoch: 363, train time every whole data:168.49s
epoch: 363, total time:30691.31s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1368s
epoch: 364, train time every whole data:168.80s
epoch: 364, total time:30867.25s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1436s
epoch: 365, train time every whole data:169.08s
epoch: 365, total time:31043.47s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1397s
epoch: 366, train time every whole data:168.48s
epoch: 366, total time:31219.09s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1352s
epoch: 367, train time every whole data:168.83s
epoch: 367, total time:31395.05s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1410s
epoch: 368, train time every whole data:168.91s
epoch: 368, total time:31571.11s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1379s
epoch: 369, train time every whole data:169.07s
epoch: 369, total time:31747.31s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1393s
epoch: 370, train time every whole data:168.63s
epoch: 370, total time:31923.09s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1350s
epoch: 371, train time every whole data:168.62s
epoch: 371, total time:32098.84s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 372, train time every whole data:169.32s
epoch: 372, total time:32275.31s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1397s
epoch: 373, train time every whole data:168.73s
epoch: 373, total time:32451.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 374, train time every whole data:169.52s
epoch: 374, total time:32627.84s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1438s
epoch: 375, train time every whole data:170.30s
epoch: 375, total time:32805.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1424s
epoch: 376, train time every whole data:170.27s
epoch: 376, total time:32982.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1401s
epoch: 377, train time every whole data:170.02s
epoch: 377, total time:33159.87s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1422s
epoch: 378, train time every whole data:170.53s
epoch: 378, total time:33337.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1397s
epoch: 379, train time every whole data:169.09s
epoch: 379, total time:33513.77s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1365s
epoch: 380, train time every whole data:168.66s
epoch: 380, total time:33689.57s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1393s
epoch: 381, train time every whole data:168.99s
epoch: 381, total time:33865.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1389s
epoch: 382, train time every whole data:168.86s
epoch: 382, total time:34041.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1393s
epoch: 383, train time every whole data:168.88s
epoch: 383, total time:34217.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1363s
epoch: 384, train time every whole data:168.76s
epoch: 384, total time:34393.61s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 385, train time every whole data:169.07s
epoch: 385, total time:34569.83s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1360s
epoch: 386, train time every whole data:168.63s
epoch: 386, total time:34745.60s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1344s
epoch: 387, train time every whole data:168.89s
epoch: 387, total time:34921.62s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1356s
epoch: 388, train time every whole data:169.13s
epoch: 388, total time:35097.88s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1350s
epoch: 389, train time every whole data:168.97s
epoch: 389, total time:35273.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1366s
epoch: 390, train time every whole data:168.99s
epoch: 390, total time:35450.12s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1388s
epoch: 391, train time every whole data:168.75s
epoch: 391, total time:35626.01s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1391s
epoch: 392, train time every whole data:168.53s
epoch: 392, total time:35801.68s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1341s
epoch: 393, train time every whole data:169.26s
epoch: 393, total time:35978.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 394, train time every whole data:169.01s
epoch: 394, total time:36154.23s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
epoch: 395, train time every whole data:168.73s
epoch: 395, total time:36330.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1362s
epoch: 396, train time every whole data:168.69s
epoch: 396, total time:36505.92s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1328s
epoch: 397, train time every whole data:168.49s
epoch: 397, total time:36681.55s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1326s
epoch: 398, train time every whole data:167.52s
epoch: 398, total time:36856.20s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1348s
epoch: 399, train time every whole data:167.62s
epoch: 399, total time:37030.96s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1321s
best epoch: 305
apply the best val model on the test data set ...
load weight from: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_305.params
predicting testing set batch 1 / 18, time: 0.40s
test time on whole data:7.14s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 305, predict 0 points
MAE: 10.13
RMSE: 16.89
MAPE: 22.64
current epoch: 305, predict 1 points
MAE: 10.57
RMSE: 18.33
MAPE: 22.96
current epoch: 305, predict 2 points
MAE: 10.75
RMSE: 18.76
MAPE: 23.20
current epoch: 305, predict 3 points
MAE: 10.92
RMSE: 19.22
MAPE: 23.47
current epoch: 305, predict 4 points
MAE: 11.02
RMSE: 19.45
MAPE: 23.68
current epoch: 305, predict 5 points
MAE: 11.09
RMSE: 19.55
MAPE: 24.04
current epoch: 305, predict 6 points
MAE: 11.35
RMSE: 20.15
MAPE: 24.56
current epoch: 305, predict 7 points
MAE: 11.53
RMSE: 20.62
MAPE: 24.93
current epoch: 305, predict 8 points
MAE: 11.66
RMSE: 20.64
MAPE: 25.32
current epoch: 305, predict 9 points
MAE: 11.82
RMSE: 20.93
MAPE: 25.78
current epoch: 305, predict 10 points
MAE: 11.95
RMSE: 21.17
MAPE: 26.47
current epoch: 305, predict 11 points
MAE: 12.14
RMSE: 21.65
MAPE: 27.34
all MAE: 11.24
all RMSE: 19.82
all MAPE: 24.51
[10.130292, 16.88904218994523, 22.636394202709198, 10.574644, 18.326142629099813, 22.96396642923355, 10.753903, 18.76415643972655, 23.203960061073303, 10.924849, 19.22037753525295, 23.474551737308502, 11.015877, 19.45444900112825, 23.675064742565155, 11.088872, 19.55150043944438, 24.038022756576538, 11.348665, 20.1526295803775, 24.55720454454422, 11.531923, 20.623901337925478, 24.932843446731567, 11.655045, 20.640611693315165, 25.319939851760864, 11.816037, 20.93200866654718, 25.781095027923584, 11.950351, 21.166673715344956, 26.47285759449005, 12.138046, 21.654295377609987, 27.337178587913513, 11.244041, 19.82409367263498, 24.509762227535248]
