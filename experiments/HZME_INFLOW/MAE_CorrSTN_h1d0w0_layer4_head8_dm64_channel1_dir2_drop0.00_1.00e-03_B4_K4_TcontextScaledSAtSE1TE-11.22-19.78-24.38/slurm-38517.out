Sun Nov 14 08:34:37 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 418.165.02   Driver Version: 418.165.02   CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  Off  | 00000000:5A:00.0 Off |                    0 |
| N/A   40C    P0    59W / 250W |   2160MiB / 32480MiB |     50%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE...  Off  | 00000000:5E:00.0 Off |                    0 |
| N/A   41C    P0   139W / 250W |   2160MiB / 32480MiB |     97%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-PCIE...  Off  | 00000000:62:00.0 Off |                    0 |
| N/A   33C    P0    57W / 250W |   2134MiB / 32480MiB |     52%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-PCIE...  Off  | 00000000:66:00.0 Off |                    0 |
| N/A   30C    P0    33W / 250W |   7157MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-PCIE...  Off  | 00000000:B5:00.0 Off |                    0 |
| N/A   26C    P0    23W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-PCIE...  Off  | 00000000:B9:00.0 Off |                    0 |
| N/A   29C    P0    26W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-PCIE...  Off  | 00000000:BD:00.0 Off |                    0 |
| N/A   29C    P0    24W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-PCIE...  Off  | 00000000:C1:00.0 Off |                    0 |
| N/A   27C    P0    22W / 250W |     11MiB / 32480MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     51112      C   python                                      2149MiB |
|    1     51475      C   python                                      2149MiB |
|    2     51739      C   python                                      2123MiB |
|    3     18905      C   python                                      7145MiB |
+-----------------------------------------------------------------------------+
CUDA: True cuda:0
Read configuration file: /data/home/u18112042/CorrSTN/configurations/HZME_INFLOW.conf
total training epoch, fine tune epoch: 300 , 100
batch_size: 4
attention_top_k: 4
folder_dir: MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
load file: /data/home/u18112042/CorrSTN/data/HZME_INFLOW/HZME_INFLOW_r1_d0_w0.npz
ori length: 4479 , percent: 1.0 , scale: 4479
train: torch.Size([3323, 80, 1, 12]) torch.Size([3323, 80, 12]) torch.Size([3323, 80, 12])
val: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
test: torch.Size([1128, 80, 1, 12]) torch.Size([1128, 80, 12]) torch.Size([1128, 80, 12])
TemporalPositionalEncoding max_len: 12
w_index: []
d_index: []
h_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
en_lookup_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
EncoderDecoder(
  (encoder): Encoder(
    (layers): ModuleList(
      (0): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_q1d_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadAttentionAwareTemporalContex_qc_kc(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (conv1Ds_aware_temporal_context): ModuleList(
            (0): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
            (1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          )
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (src_attn): MultiHeadAttentionAwareTemporalContex_qc_k1d(
          (linears): ModuleList(
            (0): Linear(in_features=64, out_features=64, bias=True)
            (1): Linear(in_features=64, out_features=64, bias=True)
          )
          (query_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 2))
          (key_conv1Ds_aware_temporal_context): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))
          (dropout): Dropout(p=0.0, inplace=False)
          (attn_ic): Attention_IC(
            (DAT): DynamicAttentionLayer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (feed_forward_gcn): PositionWiseGCNFeedForward(
          (gcn): spatialAttentionScaledGCN(
            (Theta): Linear(in_features=64, out_features=64, bias=False)
            (SAt): Spatial_Attention_layer(
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (sublayer): ModuleList(
          (0): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (1): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SublayerConnection(
            (dropout): Dropout(p=0.0, inplace=False)
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
  )
  (src_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (trg_embed): Sequential(
    (0): Linear(in_features=1, out_features=64, bias=True)
    (1): TemporalPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (2): SpatialPositionalEncoding(
      (dropout): Dropout(p=0.0, inplace=False)
      (embedding): Embedding(80, 64)
      (gcn_smooth_layers): ModuleList(
        (0): GCN(
          (Theta): Linear(in_features=64, out_features=64, bias=False)
        )
      )
    )
  )
  (prediction_generator): Linear(in_features=64, out_features=1, bias=True)
)
create params directory ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE
Net's state_dict:
encoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
encoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
encoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
encoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
encoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
encoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
encoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
encoder.norm.weight 	 torch.Size([64])
encoder.norm.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.0.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.0.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.0.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.0.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.0.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.0.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.0.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.1.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.1.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.1.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.1.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.1.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.1.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.1.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.2.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.2.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.2.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.2.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.2.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.2.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.2.sublayer.2.norm.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.self_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.0.bias 	 torch.Size([64])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.self_attn.conv1Ds_aware_temporal_context.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.0.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.0.bias 	 torch.Size([64])
decoder.layers.3.src_attn.linears.1.weight 	 torch.Size([64, 64])
decoder.layers.3.src_attn.linears.1.bias 	 torch.Size([64])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.query_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.weight 	 torch.Size([64, 64, 1, 3])
decoder.layers.3.src_attn.key_conv1Ds_aware_temporal_context.bias 	 torch.Size([64])
decoder.layers.3.feed_forward_gcn.gcn.alpha 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.beta 	 torch.Size([1])
decoder.layers.3.feed_forward_gcn.gcn.Theta.weight 	 torch.Size([64, 64])
decoder.layers.3.sublayer.0.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.0.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.1.norm.bias 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.weight 	 torch.Size([64])
decoder.layers.3.sublayer.2.norm.bias 	 torch.Size([64])
decoder.norm.weight 	 torch.Size([64])
decoder.norm.bias 	 torch.Size([64])
src_embed.0.weight 	 torch.Size([64, 1])
src_embed.0.bias 	 torch.Size([64])
src_embed.1.pe 	 torch.Size([1, 1, 12, 64])
src_embed.2.embedding.weight 	 torch.Size([80, 64])
src_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
src_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
trg_embed.0.weight 	 torch.Size([64, 1])
trg_embed.0.bias 	 torch.Size([64])
trg_embed.1.pe 	 torch.Size([1, 1, 12, 64])
trg_embed.2.embedding.weight 	 torch.Size([80, 64])
trg_embed.2.gcn_smooth_layers.0.alpha 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.beta 	 torch.Size([1])
trg_embed.2.gcn_smooth_layers.0.Theta.weight 	 torch.Size([64, 64])
prediction_generator.weight 	 torch.Size([1, 64])
prediction_generator.bias 	 torch.Size([1])
Net's total params: 452181
Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177]}]
validation batch 1 / 18, loss: 0.07
validation cost time: 7.7181s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_0.params
epoch: 0, train time every whole data:58.28s
epoch: 0, total time:66.01s
validation batch 1 / 18, loss: 0.08
validation cost time: 7.1441s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_1.params
epoch: 1, train time every whole data:58.37s
epoch: 1, total time:131.54s
validation batch 1 / 18, loss: 0.10
validation cost time: 7.1375s
epoch: 2, train time every whole data:58.20s
epoch: 2, total time:196.87s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1452s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_3.params
epoch: 3, train time every whole data:58.19s
epoch: 3, total time:262.22s
validation batch 1 / 18, loss: 0.05
validation cost time: 7.1376s
epoch: 4, train time every whole data:58.22s
epoch: 4, total time:327.58s
validation batch 1 / 18, loss: 0.06
validation cost time: 7.1341s
epoch: 5, train time every whole data:58.22s
epoch: 5, total time:392.93s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1385s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_6.params
epoch: 6, train time every whole data:58.21s
epoch: 6, total time:458.29s
validation batch 1 / 18, loss: 0.07
validation cost time: 7.1396s
epoch: 7, train time every whole data:58.19s
epoch: 7, total time:523.63s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1353s
epoch: 8, train time every whole data:58.23s
epoch: 8, total time:589.00s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1342s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_9.params
epoch: 9, train time every whole data:58.26s
epoch: 9, total time:654.40s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1393s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_10.params
epoch: 10, train time every whole data:58.21s
epoch: 10, total time:719.76s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1344s
epoch: 11, train time every whole data:58.28s
epoch: 11, total time:785.18s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1350s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_12.params
epoch: 12, train time every whole data:58.24s
epoch: 12, total time:850.56s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1355s
epoch: 13, train time every whole data:58.24s
epoch: 13, total time:915.94s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1408s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_14.params
epoch: 14, train time every whole data:58.27s
epoch: 14, total time:981.37s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1410s
epoch: 15, train time every whole data:58.26s
epoch: 15, total time:1046.77s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1407s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_16.params
epoch: 16, train time every whole data:58.24s
epoch: 16, total time:1112.16s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1415s
epoch: 17, train time every whole data:58.27s
epoch: 17, total time:1177.57s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1393s
epoch: 18, train time every whole data:58.24s
epoch: 18, total time:1242.95s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1386s
epoch: 19, train time every whole data:58.22s
epoch: 19, total time:1308.31s
validation batch 1 / 18, loss: 0.05
validation cost time: 7.1403s
epoch: 20, train time every whole data:58.22s
epoch: 20, total time:1373.67s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1403s
epoch: 21, train time every whole data:58.24s
epoch: 21, total time:1439.06s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1337s
epoch: 22, train time every whole data:58.27s
epoch: 22, total time:1504.46s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1343s
epoch: 23, train time every whole data:58.26s
epoch: 23, total time:1569.86s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1336s
epoch: 24, train time every whole data:58.24s
epoch: 24, total time:1635.24s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1396s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_25.params
epoch: 25, train time every whole data:58.26s
epoch: 25, total time:1700.65s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1330s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_26.params
epoch: 26, train time every whole data:58.24s
epoch: 26, total time:1766.04s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1392s
epoch: 27, train time every whole data:58.28s
epoch: 27, total time:1831.45s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1344s
epoch: 28, train time every whole data:58.23s
epoch: 28, total time:1896.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1392s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_29.params
epoch: 29, train time every whole data:58.26s
epoch: 29, total time:1962.23s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1359s
epoch: 30, train time every whole data:58.24s
epoch: 30, total time:2027.61s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1356s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_31.params
epoch: 31, train time every whole data:58.25s
epoch: 31, total time:2093.00s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 32, train time every whole data:58.24s
epoch: 32, total time:2158.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1408s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_33.params
epoch: 33, train time every whole data:58.27s
epoch: 33, total time:2223.81s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1344s
epoch: 34, train time every whole data:58.27s
epoch: 34, total time:2289.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1343s
epoch: 35, train time every whole data:58.25s
epoch: 35, total time:2354.60s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 36, train time every whole data:58.21s
epoch: 36, total time:2419.96s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 37, train time every whole data:58.25s
epoch: 37, total time:2485.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1348s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_38.params
epoch: 38, train time every whole data:58.22s
epoch: 38, total time:2550.72s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1358s
epoch: 39, train time every whole data:58.23s
epoch: 39, total time:2616.09s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 40, train time every whole data:58.23s
epoch: 40, total time:2681.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_41.params
epoch: 41, train time every whole data:58.25s
epoch: 41, total time:2746.87s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1331s
epoch: 42, train time every whole data:58.20s
epoch: 42, total time:2812.20s
validation batch 1 / 18, loss: 0.04
validation cost time: 7.1335s
epoch: 43, train time every whole data:58.22s
epoch: 43, total time:2877.56s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1337s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_44.params
epoch: 44, train time every whole data:58.25s
epoch: 44, total time:2942.95s
validation batch 1 / 18, loss: 0.03
validation cost time: 7.1399s
epoch: 45, train time every whole data:58.26s
epoch: 45, total time:3008.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 46, train time every whole data:58.27s
epoch: 46, total time:3073.77s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1353s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_47.params
epoch: 47, train time every whole data:58.23s
epoch: 47, total time:3139.14s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 48, train time every whole data:58.24s
epoch: 48, total time:3204.52s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1339s
epoch: 49, train time every whole data:58.23s
epoch: 49, total time:3269.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1406s
epoch: 50, train time every whole data:58.20s
epoch: 50, total time:3335.23s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1346s
epoch: 51, train time every whole data:58.26s
epoch: 51, total time:3400.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_52.params
epoch: 52, train time every whole data:58.24s
epoch: 52, total time:3466.03s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1357s
epoch: 53, train time every whole data:58.25s
epoch: 53, total time:3531.42s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1421s
epoch: 54, train time every whole data:58.26s
epoch: 54, total time:3596.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1401s
epoch: 55, train time every whole data:58.25s
epoch: 55, total time:3662.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
epoch: 56, train time every whole data:58.21s
epoch: 56, total time:3727.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1348s
epoch: 57, train time every whole data:58.24s
epoch: 57, total time:3792.94s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1352s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_58.params
epoch: 58, train time every whole data:58.20s
epoch: 58, total time:3858.29s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1352s
epoch: 59, train time every whole data:58.25s
epoch: 59, total time:3923.67s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1347s
epoch: 60, train time every whole data:58.22s
epoch: 60, total time:3989.02s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1398s
epoch: 61, train time every whole data:58.24s
epoch: 61, total time:4054.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_62.params
epoch: 62, train time every whole data:58.21s
epoch: 62, total time:4119.77s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1418s
epoch: 63, train time every whole data:58.25s
epoch: 63, total time:4185.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1407s
epoch: 64, train time every whole data:58.25s
epoch: 64, total time:4250.55s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 65, train time every whole data:58.22s
epoch: 65, total time:4315.91s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1408s
epoch: 66, train time every whole data:58.22s
epoch: 66, total time:4381.28s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1407s
epoch: 67, train time every whole data:58.21s
epoch: 67, total time:4446.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1352s
epoch: 68, train time every whole data:58.26s
epoch: 68, total time:4512.03s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1355s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_69.params
epoch: 69, train time every whole data:58.24s
epoch: 69, total time:4577.42s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1350s
epoch: 70, train time every whole data:58.25s
epoch: 70, total time:4642.81s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 71, train time every whole data:58.25s
epoch: 71, total time:4708.20s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1357s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_72.params
epoch: 72, train time every whole data:58.22s
epoch: 72, total time:4773.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1403s
epoch: 73, train time every whole data:58.24s
epoch: 73, total time:4838.95s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1352s
epoch: 74, train time every whole data:58.25s
epoch: 74, total time:4904.34s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1412s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_75.params
epoch: 75, train time every whole data:58.24s
epoch: 75, total time:4969.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1346s
epoch: 76, train time every whole data:58.23s
epoch: 76, total time:5035.10s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 77, train time every whole data:58.25s
epoch: 77, total time:5100.49s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1351s
epoch: 78, train time every whole data:58.26s
epoch: 78, total time:5165.89s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1383s
epoch: 79, train time every whole data:58.22s
epoch: 79, total time:5231.25s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1338s
epoch: 80, train time every whole data:58.25s
epoch: 80, total time:5296.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1350s
epoch: 81, train time every whole data:58.23s
epoch: 81, total time:5362.00s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1392s
epoch: 82, train time every whole data:58.25s
epoch: 82, total time:5427.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 83, train time every whole data:58.25s
epoch: 83, total time:5492.78s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1336s
epoch: 84, train time every whole data:58.23s
epoch: 84, total time:5558.14s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1397s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_85.params
epoch: 85, train time every whole data:58.22s
epoch: 85, total time:5623.52s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1393s
epoch: 86, train time every whole data:58.27s
epoch: 86, total time:5688.92s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1328s
epoch: 87, train time every whole data:58.25s
epoch: 87, total time:5754.31s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1347s
epoch: 88, train time every whole data:58.24s
epoch: 88, total time:5819.68s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1358s
epoch: 89, train time every whole data:58.25s
epoch: 89, total time:5885.07s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 90, train time every whole data:58.25s
epoch: 90, total time:5950.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1398s
epoch: 91, train time every whole data:58.26s
epoch: 91, total time:6015.86s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1345s
epoch: 92, train time every whole data:58.22s
epoch: 92, total time:6081.21s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 93, train time every whole data:58.24s
epoch: 93, total time:6146.59s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1387s
epoch: 94, train time every whole data:58.27s
epoch: 94, total time:6212.00s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1398s
epoch: 95, train time every whole data:58.23s
epoch: 95, total time:6277.37s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1391s
epoch: 96, train time every whole data:58.21s
epoch: 96, total time:6342.72s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1354s
epoch: 97, train time every whole data:58.23s
epoch: 97, total time:6408.09s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 98, train time every whole data:58.25s
epoch: 98, total time:6473.48s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1429s
epoch: 99, train time every whole data:58.23s
epoch: 99, total time:6538.86s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1406s
epoch: 100, train time every whole data:58.25s
epoch: 100, total time:6604.25s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1343s
epoch: 101, train time every whole data:58.23s
epoch: 101, total time:6669.61s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 102, train time every whole data:58.25s
epoch: 102, total time:6735.01s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1351s
epoch: 103, train time every whole data:58.27s
epoch: 103, total time:6800.42s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1355s
epoch: 104, train time every whole data:58.24s
epoch: 104, total time:6865.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 105, train time every whole data:58.25s
epoch: 105, total time:6931.18s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1361s
epoch: 106, train time every whole data:58.26s
epoch: 106, total time:6996.58s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1480s
epoch: 107, train time every whole data:58.26s
epoch: 107, total time:7061.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1540s
epoch: 108, train time every whole data:58.26s
epoch: 108, total time:7127.41s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1546s
epoch: 109, train time every whole data:58.26s
epoch: 109, total time:7192.82s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1540s
epoch: 110, train time every whole data:58.26s
epoch: 110, total time:7258.24s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1485s
epoch: 111, train time every whole data:58.26s
epoch: 111, total time:7323.65s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1506s
epoch: 112, train time every whole data:58.26s
epoch: 112, total time:7389.07s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1545s
epoch: 113, train time every whole data:58.25s
epoch: 113, total time:7454.47s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1499s
epoch: 114, train time every whole data:58.22s
epoch: 114, total time:7519.84s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1358s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_115.params
epoch: 115, train time every whole data:58.23s
epoch: 115, total time:7585.23s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1441s
epoch: 116, train time every whole data:58.26s
epoch: 116, total time:7650.64s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 117, train time every whole data:58.23s
epoch: 117, total time:7716.01s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1397s
epoch: 118, train time every whole data:58.26s
epoch: 118, total time:7781.41s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1549s
epoch: 119, train time every whole data:58.28s
epoch: 119, total time:7846.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1530s
epoch: 120, train time every whole data:58.26s
epoch: 120, total time:7912.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1482s
epoch: 121, train time every whole data:58.26s
epoch: 121, total time:7977.67s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1552s
epoch: 122, train time every whole data:58.24s
epoch: 122, total time:8043.07s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1528s
epoch: 123, train time every whole data:58.23s
epoch: 123, total time:8108.46s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1379s
epoch: 124, train time every whole data:58.23s
epoch: 124, total time:8173.82s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1394s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_125.params
epoch: 125, train time every whole data:58.24s
epoch: 125, total time:8239.22s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1406s
epoch: 126, train time every whole data:58.27s
epoch: 126, total time:8304.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1351s
epoch: 127, train time every whole data:58.26s
epoch: 127, total time:8370.03s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1343s
epoch: 128, train time every whole data:58.27s
epoch: 128, total time:8435.43s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1339s
epoch: 129, train time every whole data:58.22s
epoch: 129, total time:8500.78s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 130, train time every whole data:58.21s
epoch: 130, total time:8566.13s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1353s
epoch: 131, train time every whole data:58.24s
epoch: 131, total time:8631.51s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1404s
epoch: 132, train time every whole data:58.27s
epoch: 132, total time:8696.93s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1390s
epoch: 133, train time every whole data:58.22s
epoch: 133, total time:8762.28s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 134, train time every whole data:58.24s
epoch: 134, total time:8827.67s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1381s
epoch: 135, train time every whole data:58.23s
epoch: 135, total time:8893.03s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1353s
epoch: 136, train time every whole data:58.23s
epoch: 136, total time:8958.40s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1399s
epoch: 137, train time every whole data:58.24s
epoch: 137, total time:9023.79s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1389s
epoch: 138, train time every whole data:58.24s
epoch: 138, total time:9089.17s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 139, train time every whole data:58.25s
epoch: 139, total time:9154.56s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1341s
epoch: 140, train time every whole data:58.24s
epoch: 140, total time:9219.93s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1341s
epoch: 141, train time every whole data:58.24s
epoch: 141, total time:9285.31s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1350s
epoch: 142, train time every whole data:58.23s
epoch: 142, total time:9350.68s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1347s
epoch: 143, train time every whole data:58.23s
epoch: 143, total time:9416.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1371s
epoch: 144, train time every whole data:58.25s
epoch: 144, total time:9481.44s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1329s
epoch: 145, train time every whole data:58.24s
epoch: 145, total time:9546.81s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 146, train time every whole data:58.27s
epoch: 146, total time:9612.22s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 147, train time every whole data:58.26s
epoch: 147, total time:9677.61s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 148, train time every whole data:58.24s
epoch: 148, total time:9742.99s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1409s
epoch: 149, train time every whole data:58.22s
epoch: 149, total time:9808.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1344s
epoch: 150, train time every whole data:58.24s
epoch: 150, total time:9873.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1351s
epoch: 151, train time every whole data:58.24s
epoch: 151, total time:9939.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1402s
epoch: 152, train time every whole data:58.24s
epoch: 152, total time:10004.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 153, train time every whole data:58.21s
epoch: 153, total time:10069.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 154, train time every whole data:58.25s
epoch: 154, total time:10135.23s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1416s
epoch: 155, train time every whole data:58.24s
epoch: 155, total time:10200.62s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
epoch: 156, train time every whole data:58.24s
epoch: 156, total time:10266.01s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
epoch: 157, train time every whole data:58.24s
epoch: 157, total time:10331.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1405s
epoch: 158, train time every whole data:58.22s
epoch: 158, total time:10396.75s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1417s
epoch: 159, train time every whole data:58.25s
epoch: 159, total time:10462.15s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1340s
epoch: 160, train time every whole data:58.23s
epoch: 160, total time:10527.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 161, train time every whole data:58.25s
epoch: 161, total time:10592.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1347s
epoch: 162, train time every whole data:58.22s
epoch: 162, total time:10658.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1335s
epoch: 163, train time every whole data:58.23s
epoch: 163, total time:10723.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1354s
epoch: 164, train time every whole data:58.24s
epoch: 164, total time:10789.00s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 165, train time every whole data:58.21s
epoch: 165, total time:10854.35s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1384s
epoch: 166, train time every whole data:58.24s
epoch: 166, total time:10919.73s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 167, train time every whole data:58.28s
epoch: 167, total time:10985.16s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1338s
epoch: 168, train time every whole data:58.24s
epoch: 168, total time:11050.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1339s
epoch: 169, train time every whole data:58.26s
epoch: 169, total time:11115.93s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1399s
epoch: 170, train time every whole data:58.26s
epoch: 170, total time:11181.33s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1398s
epoch: 171, train time every whole data:58.23s
epoch: 171, total time:11246.70s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 172, train time every whole data:58.25s
epoch: 172, total time:11312.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1344s
epoch: 173, train time every whole data:58.25s
epoch: 173, total time:11377.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1342s
epoch: 174, train time every whole data:58.25s
epoch: 174, total time:11442.86s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 175, train time every whole data:58.23s
epoch: 175, total time:11508.23s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1345s
epoch: 176, train time every whole data:58.26s
epoch: 176, total time:11573.63s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1341s
epoch: 177, train time every whole data:58.22s
epoch: 177, total time:11638.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 178, train time every whole data:58.28s
epoch: 178, total time:11704.41s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1341s
epoch: 179, train time every whole data:58.25s
epoch: 179, total time:11769.79s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1343s
epoch: 180, train time every whole data:58.26s
epoch: 180, total time:11835.18s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 181, train time every whole data:58.27s
epoch: 181, total time:11900.59s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1342s
epoch: 182, train time every whole data:58.25s
epoch: 182, total time:11965.98s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 183, train time every whole data:58.26s
epoch: 183, total time:12031.38s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1345s
epoch: 184, train time every whole data:58.27s
epoch: 184, total time:12096.79s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1388s
epoch: 185, train time every whole data:58.26s
epoch: 185, total time:12162.19s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 186, train time every whole data:58.24s
epoch: 186, total time:12227.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1343s
epoch: 187, train time every whole data:58.23s
epoch: 187, total time:12292.94s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1375s
epoch: 188, train time every whole data:58.26s
epoch: 188, total time:12358.34s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1329s
epoch: 189, train time every whole data:58.24s
epoch: 189, total time:12423.71s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 190, train time every whole data:58.26s
epoch: 190, total time:12489.11s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1329s
epoch: 191, train time every whole data:58.26s
epoch: 191, total time:12554.50s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1397s
epoch: 192, train time every whole data:58.27s
epoch: 192, total time:12619.91s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 193, train time every whole data:58.24s
epoch: 193, total time:12685.29s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1380s
epoch: 194, train time every whole data:58.25s
epoch: 194, total time:12750.68s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1330s
epoch: 195, train time every whole data:58.25s
epoch: 195, total time:12816.06s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1384s
epoch: 196, train time every whole data:58.26s
epoch: 196, total time:12881.46s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 197, train time every whole data:58.24s
epoch: 197, total time:12946.84s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1336s
epoch: 198, train time every whole data:58.25s
epoch: 198, total time:13012.22s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1393s
epoch: 199, train time every whole data:58.23s
epoch: 199, total time:13077.59s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1342s
epoch: 200, train time every whole data:58.23s
epoch: 200, total time:13142.95s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 201, train time every whole data:58.27s
epoch: 201, total time:13208.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1398s
epoch: 202, train time every whole data:58.23s
epoch: 202, total time:13273.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1410s
epoch: 203, train time every whole data:58.23s
epoch: 203, total time:13339.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1352s
epoch: 204, train time every whole data:58.22s
epoch: 204, total time:13404.46s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1358s
epoch: 205, train time every whole data:58.20s
epoch: 205, total time:13469.80s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 206, train time every whole data:58.25s
epoch: 206, total time:13535.18s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1351s
epoch: 207, train time every whole data:58.22s
epoch: 207, total time:13600.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 208, train time every whole data:58.23s
epoch: 208, total time:13665.90s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1385s
epoch: 209, train time every whole data:58.24s
epoch: 209, total time:13731.29s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1389s
epoch: 210, train time every whole data:58.24s
epoch: 210, total time:13796.66s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
epoch: 211, train time every whole data:58.23s
epoch: 211, total time:13862.03s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1344s
epoch: 212, train time every whole data:58.24s
epoch: 212, total time:13927.40s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1336s
epoch: 213, train time every whole data:58.22s
epoch: 213, total time:13992.76s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1355s
epoch: 214, train time every whole data:58.23s
epoch: 214, total time:14058.13s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 215, train time every whole data:58.21s
epoch: 215, total time:14123.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1349s
epoch: 216, train time every whole data:58.24s
epoch: 216, total time:14188.86s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1421s
epoch: 217, train time every whole data:58.25s
epoch: 217, total time:14254.25s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1397s
epoch: 218, train time every whole data:58.26s
epoch: 218, total time:14319.65s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1405s
epoch: 219, train time every whole data:58.21s
epoch: 219, total time:14385.01s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1399s
epoch: 220, train time every whole data:58.23s
epoch: 220, total time:14450.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1344s
epoch: 221, train time every whole data:58.21s
epoch: 221, total time:14515.73s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1339s
epoch: 222, train time every whole data:58.26s
epoch: 222, total time:14581.12s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1393s
epoch: 223, train time every whole data:58.24s
epoch: 223, total time:14646.50s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1391s
epoch: 224, train time every whole data:58.22s
epoch: 224, total time:14711.85s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1402s
epoch: 225, train time every whole data:58.23s
epoch: 225, total time:14777.23s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1335s
epoch: 226, train time every whole data:58.24s
epoch: 226, total time:14842.60s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1398s
epoch: 227, train time every whole data:58.23s
epoch: 227, total time:14907.97s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1346s
epoch: 228, train time every whole data:58.26s
epoch: 228, total time:14973.37s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 229, train time every whole data:58.23s
epoch: 229, total time:15038.74s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 230, train time every whole data:58.24s
epoch: 230, total time:15104.12s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1358s
epoch: 231, train time every whole data:58.23s
epoch: 231, total time:15169.49s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1348s
epoch: 232, train time every whole data:58.26s
epoch: 232, total time:15234.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1347s
epoch: 233, train time every whole data:58.25s
epoch: 233, total time:15300.27s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1349s
epoch: 234, train time every whole data:58.22s
epoch: 234, total time:15365.62s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1346s
epoch: 235, train time every whole data:58.27s
epoch: 235, total time:15431.02s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 236, train time every whole data:58.24s
epoch: 236, total time:15496.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1356s
epoch: 237, train time every whole data:58.25s
epoch: 237, total time:15561.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1350s
epoch: 238, train time every whole data:58.21s
epoch: 238, total time:15627.14s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1349s
epoch: 239, train time every whole data:58.23s
epoch: 239, total time:15692.51s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1405s
epoch: 240, train time every whole data:58.22s
epoch: 240, total time:15757.87s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1406s
epoch: 241, train time every whole data:58.26s
epoch: 241, total time:15823.27s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 242, train time every whole data:58.26s
epoch: 242, total time:15888.67s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1405s
epoch: 243, train time every whole data:58.23s
epoch: 243, total time:15954.04s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 244, train time every whole data:58.26s
epoch: 244, total time:16019.45s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 245, train time every whole data:58.24s
epoch: 245, total time:16084.82s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1385s
epoch: 246, train time every whole data:58.24s
epoch: 246, total time:16150.20s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1381s
epoch: 247, train time every whole data:58.25s
epoch: 247, total time:16215.59s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1328s
epoch: 248, train time every whole data:58.28s
epoch: 248, total time:16281.01s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1381s
epoch: 249, train time every whole data:58.26s
epoch: 249, total time:16346.41s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1403s
epoch: 250, train time every whole data:58.24s
epoch: 250, total time:16411.79s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1344s
epoch: 251, train time every whole data:58.26s
epoch: 251, total time:16477.19s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1350s
epoch: 252, train time every whole data:58.26s
epoch: 252, total time:16542.58s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1411s
epoch: 253, train time every whole data:58.24s
epoch: 253, total time:16607.96s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1533s
epoch: 254, train time every whole data:58.27s
epoch: 254, total time:16673.39s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1526s
epoch: 255, train time every whole data:58.29s
epoch: 255, total time:16738.83s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1477s
epoch: 256, train time every whole data:58.25s
epoch: 256, total time:16804.23s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1345s
epoch: 257, train time every whole data:58.28s
epoch: 257, total time:16869.64s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 258, train time every whole data:58.26s
epoch: 258, total time:16935.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1396s
epoch: 259, train time every whole data:58.28s
epoch: 259, total time:17000.46s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1522s
epoch: 260, train time every whole data:58.28s
epoch: 260, total time:17065.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1470s
epoch: 261, train time every whole data:58.26s
epoch: 261, total time:17131.30s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1489s
epoch: 262, train time every whole data:58.27s
epoch: 262, total time:17196.72s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1485s
epoch: 263, train time every whole data:58.26s
epoch: 263, total time:17262.13s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1537s
epoch: 264, train time every whole data:58.24s
epoch: 264, total time:17327.53s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1535s
epoch: 265, train time every whole data:58.26s
epoch: 265, total time:17392.94s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1484s
epoch: 266, train time every whole data:58.26s
epoch: 266, total time:17458.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1523s
epoch: 267, train time every whole data:58.25s
epoch: 267, total time:17523.77s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1512s
epoch: 268, train time every whole data:58.23s
epoch: 268, total time:17589.15s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1334s
epoch: 269, train time every whole data:58.22s
epoch: 269, total time:17654.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1368s
epoch: 270, train time every whole data:58.23s
epoch: 270, total time:17719.88s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1400s
epoch: 271, train time every whole data:58.24s
epoch: 271, total time:17785.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1488s
epoch: 272, train time every whole data:58.26s
epoch: 272, total time:17850.67s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1491s
epoch: 273, train time every whole data:58.23s
epoch: 273, total time:17916.05s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1494s
epoch: 274, train time every whole data:58.26s
epoch: 274, total time:17981.46s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1415s
epoch: 275, train time every whole data:58.24s
epoch: 275, total time:18046.84s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1344s
epoch: 276, train time every whole data:58.23s
epoch: 276, total time:18112.22s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1407s
epoch: 277, train time every whole data:58.21s
epoch: 277, total time:18177.57s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1354s
epoch: 278, train time every whole data:58.22s
epoch: 278, total time:18242.93s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1346s
epoch: 279, train time every whole data:58.22s
epoch: 279, total time:18308.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1351s
epoch: 280, train time every whole data:58.26s
epoch: 280, total time:18373.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1406s
epoch: 281, train time every whole data:58.26s
epoch: 281, total time:18439.09s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1402s
epoch: 282, train time every whole data:58.26s
epoch: 282, total time:18504.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1338s
epoch: 283, train time every whole data:58.25s
epoch: 283, total time:18569.87s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 284, train time every whole data:58.25s
epoch: 284, total time:18635.26s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1394s
epoch: 285, train time every whole data:58.24s
epoch: 285, total time:18700.64s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1334s
epoch: 286, train time every whole data:58.23s
epoch: 286, total time:18766.00s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1404s
epoch: 287, train time every whole data:58.22s
epoch: 287, total time:18831.37s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1349s
epoch: 288, train time every whole data:58.23s
epoch: 288, total time:18896.73s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1411s
epoch: 289, train time every whole data:58.25s
epoch: 289, total time:18962.12s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1405s
epoch: 290, train time every whole data:58.22s
epoch: 290, total time:19027.49s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1340s
epoch: 291, train time every whole data:58.17s
epoch: 291, total time:19092.80s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 292, train time every whole data:58.13s
epoch: 292, total time:19158.06s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1395s
epoch: 293, train time every whole data:58.17s
epoch: 293, total time:19223.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 294, train time every whole data:58.22s
epoch: 294, total time:19288.74s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1343s
epoch: 295, train time every whole data:58.19s
epoch: 295, total time:19354.06s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1340s
epoch: 296, train time every whole data:58.16s
epoch: 296, total time:19419.36s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1403s
epoch: 297, train time every whole data:58.17s
epoch: 297, total time:19484.68s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1378s
epoch: 298, train time every whole data:58.20s
epoch: 298, total time:19550.01s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1360s
epoch: 299, train time every whole data:58.19s
epoch: 299, total time:19615.34s
best epoch: 125
apply the best val model on the test data set ...
load weight from: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_125.params
predicting testing set batch 1 / 18, time: 0.40s
test time on whole data:7.14s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 125, predict 0 points
MAE: 10.20
RMSE: 16.68
MAPE: 24.76
current epoch: 125, predict 1 points
MAE: 10.50
RMSE: 17.83
MAPE: 24.83
current epoch: 125, predict 2 points
MAE: 10.66
RMSE: 18.45
MAPE: 24.12
current epoch: 125, predict 3 points
MAE: 10.87
RMSE: 19.20
MAPE: 24.19
current epoch: 125, predict 4 points
MAE: 11.07
RMSE: 19.82
MAPE: 24.35
current epoch: 125, predict 5 points
MAE: 11.18
RMSE: 20.08
MAPE: 24.66
current epoch: 125, predict 6 points
MAE: 11.44
RMSE: 20.68
MAPE: 25.18
current epoch: 125, predict 7 points
MAE: 11.63
RMSE: 21.03
MAPE: 25.79
current epoch: 125, predict 8 points
MAE: 11.82
RMSE: 21.33
MAPE: 26.62
current epoch: 125, predict 9 points
MAE: 12.17
RMSE: 22.20
MAPE: 27.82
current epoch: 125, predict 10 points
MAE: 12.72
RMSE: 23.73
MAPE: 29.51
current epoch: 125, predict 11 points
MAE: 13.30
RMSE: 25.17
MAPE: 31.51
all MAE: 11.46
all RMSE: 20.65
all MAPE: 26.08
[10.200987, 16.684175881760407, 24.758116900920868, 10.502965, 17.828006031866426, 24.831420183181763, 10.661885, 18.44854178106379, 24.11583662033081, 10.866128, 19.196506436719158, 24.191519618034363, 11.071811, 19.821491114690783, 24.35210347175598, 11.183889, 20.079451865203673, 24.658451974391937, 11.43886, 20.68325550065726, 25.178879499435425, 11.634641, 21.026343398204517, 25.78926980495453, 11.820743, 21.326097373856726, 26.617667078971863, 12.173874, 22.199596449474736, 27.819544076919556, 12.71987, 23.731005973857282, 29.505446553230286, 13.298002, 25.174200214610842, 31.506022810935974, 11.464473, 20.64695431321795, 26.078122854232788]
fine tune the model ... 
epoch: 300, train time every whole data:167.12s
epoch: 300, total time:19789.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1474s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_300.params
epoch: 301, train time every whole data:166.93s
epoch: 301, total time:19963.82s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1324s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_301.params
epoch: 302, train time every whole data:166.85s
epoch: 302, total time:20137.81s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1320s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_302.params
epoch: 303, train time every whole data:166.95s
epoch: 303, total time:20311.91s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1376s
epoch: 304, train time every whole data:166.94s
epoch: 304, total time:20485.99s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1320s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_304.params
epoch: 305, train time every whole data:166.28s
epoch: 305, total time:20659.42s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1297s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_305.params
epoch: 306, train time every whole data:165.72s
epoch: 306, total time:20832.28s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1349s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_306.params
epoch: 307, train time every whole data:165.96s
epoch: 307, total time:21005.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1347s
epoch: 308, train time every whole data:165.66s
epoch: 308, total time:21178.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1289s
epoch: 309, train time every whole data:165.77s
epoch: 309, total time:21351.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1334s
epoch: 310, train time every whole data:165.75s
epoch: 310, total time:21523.97s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1287s
epoch: 311, train time every whole data:165.85s
epoch: 311, total time:21696.96s
validation batch 1 / 18, loss: 0.02
validation cost time: 7.1302s
epoch: 312, train time every whole data:165.80s
epoch: 312, total time:21869.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1316s
epoch: 313, train time every whole data:165.80s
epoch: 313, total time:22042.82s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1308s
epoch: 314, train time every whole data:165.74s
epoch: 314, total time:22215.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1359s
epoch: 315, train time every whole data:165.91s
epoch: 315, total time:22388.74s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1295s
epoch: 316, train time every whole data:165.76s
epoch: 316, total time:22561.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1356s
epoch: 317, train time every whole data:165.88s
epoch: 317, total time:22734.65s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1336s
epoch: 318, train time every whole data:166.01s
epoch: 318, total time:22907.80s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1345s
save parameters to file: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_318.params
epoch: 319, train time every whole data:165.69s
epoch: 319, total time:23080.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1329s
epoch: 320, train time every whole data:165.73s
epoch: 320, total time:23253.50s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1293s
epoch: 321, train time every whole data:165.66s
epoch: 321, total time:23426.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1297s
epoch: 322, train time every whole data:165.87s
epoch: 322, total time:23599.29s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1346s
epoch: 323, train time every whole data:165.84s
epoch: 323, total time:23772.26s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1353s
epoch: 324, train time every whole data:165.74s
epoch: 324, total time:23945.14s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1289s
epoch: 325, train time every whole data:165.83s
epoch: 325, total time:24118.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1355s
epoch: 326, train time every whole data:165.82s
epoch: 326, total time:24291.06s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1370s
epoch: 327, train time every whole data:165.82s
epoch: 327, total time:24464.02s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1452s
epoch: 328, train time every whole data:165.91s
epoch: 328, total time:24637.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1332s
epoch: 329, train time every whole data:165.77s
epoch: 329, total time:24809.98s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1451s
epoch: 330, train time every whole data:165.85s
epoch: 330, total time:24982.98s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1458s
epoch: 331, train time every whole data:165.69s
epoch: 331, total time:25155.82s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1493s
epoch: 332, train time every whole data:165.65s
epoch: 332, total time:25328.62s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1457s
epoch: 333, train time every whole data:165.74s
epoch: 333, total time:25501.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1439s
epoch: 334, train time every whole data:165.89s
epoch: 334, total time:25674.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1448s
epoch: 335, train time every whole data:165.78s
epoch: 335, total time:25847.47s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1507s
epoch: 336, train time every whole data:165.78s
epoch: 336, total time:26020.40s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 337, train time every whole data:165.87s
epoch: 337, total time:26193.41s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1278s
epoch: 338, train time every whole data:165.90s
epoch: 338, total time:26366.44s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1329s
epoch: 339, train time every whole data:168.90s
epoch: 339, total time:26542.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1537s
epoch: 340, train time every whole data:168.79s
epoch: 340, total time:26718.42s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1588s
epoch: 341, train time every whole data:168.60s
epoch: 341, total time:26894.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1429s
epoch: 342, train time every whole data:169.13s
epoch: 342, total time:27070.45s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 343, train time every whole data:168.83s
epoch: 343, total time:27246.43s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1378s
epoch: 344, train time every whole data:168.81s
epoch: 344, total time:27422.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 345, train time every whole data:168.74s
epoch: 345, total time:27598.26s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1437s
epoch: 346, train time every whole data:168.81s
epoch: 346, total time:27774.22s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1384s
epoch: 347, train time every whole data:168.77s
epoch: 347, total time:27950.13s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1459s
epoch: 348, train time every whole data:168.84s
epoch: 348, total time:28126.11s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 349, train time every whole data:168.44s
epoch: 349, total time:28301.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1376s
epoch: 350, train time every whole data:168.66s
epoch: 350, total time:28477.50s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1384s
epoch: 351, train time every whole data:168.37s
epoch: 351, total time:28653.00s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 352, train time every whole data:168.62s
epoch: 352, total time:28828.77s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1392s
epoch: 353, train time every whole data:168.48s
epoch: 353, total time:29004.39s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1434s
epoch: 354, train time every whole data:168.55s
epoch: 354, total time:29180.08s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1431s
epoch: 355, train time every whole data:168.51s
epoch: 355, total time:29355.74s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1390s
epoch: 356, train time every whole data:168.71s
epoch: 356, total time:29531.58s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1386s
epoch: 357, train time every whole data:168.71s
epoch: 357, total time:29707.43s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1382s
epoch: 358, train time every whole data:168.50s
epoch: 358, total time:29883.06s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1379s
epoch: 359, train time every whole data:168.44s
epoch: 359, total time:30058.64s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 360, train time every whole data:169.15s
epoch: 360, total time:30234.93s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1452s
epoch: 361, train time every whole data:169.19s
epoch: 361, total time:30411.27s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1433s
epoch: 362, train time every whole data:169.65s
epoch: 362, total time:30588.06s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1436s
epoch: 363, train time every whole data:168.83s
epoch: 363, total time:30764.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1401s
epoch: 364, train time every whole data:169.52s
epoch: 364, total time:30940.70s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1407s
epoch: 365, train time every whole data:168.71s
epoch: 365, total time:31116.55s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1398s
epoch: 366, train time every whole data:169.26s
epoch: 366, total time:31292.96s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1400s
epoch: 367, train time every whole data:169.38s
epoch: 367, total time:31469.48s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1457s
epoch: 368, train time every whole data:168.98s
epoch: 368, total time:31645.61s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1445s
epoch: 369, train time every whole data:169.47s
epoch: 369, total time:31822.22s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1449s
epoch: 370, train time every whole data:169.19s
epoch: 370, total time:31998.56s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1399s
epoch: 371, train time every whole data:169.00s
epoch: 371, total time:32174.69s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1479s
epoch: 372, train time every whole data:169.79s
epoch: 372, total time:32351.63s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1383s
epoch: 373, train time every whole data:169.42s
epoch: 373, total time:32528.19s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1444s
epoch: 374, train time every whole data:170.55s
epoch: 374, total time:32705.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1493s
epoch: 375, train time every whole data:170.14s
epoch: 375, total time:32883.18s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1436s
epoch: 376, train time every whole data:170.46s
epoch: 376, total time:33060.79s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1501s
epoch: 377, train time every whole data:170.78s
epoch: 377, total time:33238.72s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1437s
epoch: 378, train time every whole data:169.89s
epoch: 378, total time:33415.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1445s
epoch: 379, train time every whole data:169.26s
epoch: 379, total time:33592.16s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1407s
epoch: 380, train time every whole data:169.59s
epoch: 380, total time:33768.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1441s
epoch: 381, train time every whole data:168.85s
epoch: 381, total time:33944.89s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1455s
epoch: 382, train time every whole data:169.24s
epoch: 382, total time:34121.28s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1454s
epoch: 383, train time every whole data:169.70s
epoch: 383, total time:34298.13s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1439s
epoch: 384, train time every whole data:169.10s
epoch: 384, total time:34474.38s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1380s
epoch: 385, train time every whole data:169.73s
epoch: 385, total time:34651.24s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1457s
epoch: 386, train time every whole data:169.23s
epoch: 386, total time:34827.62s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1375s
epoch: 387, train time every whole data:169.34s
epoch: 387, total time:35004.10s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1489s
epoch: 388, train time every whole data:169.51s
epoch: 388, total time:35180.76s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1443s
epoch: 389, train time every whole data:169.32s
epoch: 389, total time:35357.23s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1444s
epoch: 390, train time every whole data:169.49s
epoch: 390, total time:35533.86s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1395s
epoch: 391, train time every whole data:169.01s
epoch: 391, total time:35710.01s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1451s
epoch: 392, train time every whole data:169.27s
epoch: 392, total time:35886.43s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1473s
epoch: 393, train time every whole data:169.46s
epoch: 393, total time:36063.04s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1453s
epoch: 394, train time every whole data:169.40s
epoch: 394, total time:36239.59s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1451s
epoch: 395, train time every whole data:169.78s
epoch: 395, total time:36416.51s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1430s
epoch: 396, train time every whole data:168.21s
epoch: 396, total time:36591.86s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1438s
epoch: 397, train time every whole data:168.58s
epoch: 397, total time:36767.59s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1508s
epoch: 398, train time every whole data:168.16s
epoch: 398, total time:36942.90s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1501s
epoch: 399, train time every whole data:167.49s
epoch: 399, total time:37117.54s
validation batch 1 / 18, loss: 0.01
validation cost time: 7.1500s
best epoch: 318
apply the best val model on the test data set ...
load weight from: ./experiments/HZME_INFLOW/MAE_ASTGNN_h1d0w0_layer4_head8_dm64_channel1_dir2_drop0.00_1.00e-03_B4_K4_TcontextScaledSAtSE1TE/epoch_318.params
predicting testing set batch 1 / 18, time: 0.40s
test time on whole data:7.15s
input: (1128, 80, 12, 1)
prediction: (1128, 80, 12, 1)
data_target_tensor: (1128, 80, 12)
current epoch: 318, predict 0 points
MAE: 10.13
RMSE: 16.83
MAPE: 22.54
current epoch: 318, predict 1 points
MAE: 10.53
RMSE: 18.05
MAPE: 22.85
current epoch: 318, predict 2 points
MAE: 10.67
RMSE: 18.39
MAPE: 23.09
current epoch: 318, predict 3 points
MAE: 10.80
RMSE: 18.68
MAPE: 23.38
current epoch: 318, predict 4 points
MAE: 10.98
RMSE: 19.23
MAPE: 23.68
current epoch: 318, predict 5 points
MAE: 11.12
RMSE: 19.57
MAPE: 24.01
current epoch: 318, predict 6 points
MAE: 11.40
RMSE: 20.37
MAPE: 24.44
current epoch: 318, predict 7 points
MAE: 11.65
RMSE: 20.98
MAPE: 24.85
current epoch: 318, predict 8 points
MAE: 11.68
RMSE: 20.78
MAPE: 25.20
current epoch: 318, predict 9 points
MAE: 11.78
RMSE: 21.09
MAPE: 25.65
current epoch: 318, predict 10 points
MAE: 11.84
RMSE: 21.04
MAPE: 26.19
current epoch: 318, predict 11 points
MAE: 12.08
RMSE: 21.70
MAPE: 26.91
all MAE: 11.22
all RMSE: 19.78
all MAPE: 24.38
[10.128336, 16.831266572181313, 22.53807932138443, 10.530198, 18.047639323641473, 22.853900492191315, 10.670076, 18.391018275850204, 23.090556263923645, 10.795798, 18.67894168706643, 23.382815718650818, 10.976015, 19.227997330654492, 23.676712810993195, 11.12117, 19.57433606966937, 24.014070630073547, 11.401167, 20.37436342707653, 24.436450004577637, 11.647261, 20.980480750206027, 24.84784871339798, 11.684732, 20.783378503541822, 25.19948184490204, 11.784525, 21.08626458619968, 25.653886795043945, 11.843073, 21.040896602426056, 26.194390654563904, 12.083512, 21.697935028971866, 26.913952827453613, 11.2221575, 19.778790699217115, 24.37835931777954]
